[{"path":"https://joshuawiley.com/JWileymisc/articles/diagnostics-vignette.html","id":"univariate-diagnostics","dir":"Articles","previous_headings":"","what":"Univariate Diagnostics","title":"Diagnostics","text":"testDistribution() function can used evaluate whether variable comes specific, known parametric distribution. default, outliers “extreme values” shown. can used directly data output plotted. plot includes empirical density, density assumed parametric distribution, rug plot showing actual values, many data points, Quantile-Quantile plot (QQ Plot). QQ Plot rotated save space, removing diagonal rotating horizontal, call QQ Deviates plot. One unique feature density plot x axis. follows Tufte’s principles presenting data. make x axis informative, “range frame”, meaning plotted range actual data. Secondly, breaks five number summary data. five numbers : Minimum (0th percentile) Lower quartile (25th percentile) Median (50th percentile) Upper quartile (75th percentile) Maximum (100th percentile) plots use breaks evenly spaced. convey information data. Using five number summary breaks effectively like boxplot specific values provided can immediately read values min max , median, etc.  possible extreme values automatically identified either based theoretical distribution empirically identified (e.g., top bottom XX percent classified extreme). say .10 (10%) data points “extreme” just illustrate. Extreme values shown black non extreme values shown light grey, rug plot QQ plot. Although 10% higher typically chosen, given small dataset, necessary extreme values ends distribution illustration.  Extreme values taken empirical percentiles can chosen well.  Many distributions beyond normal possible. can compared visually based log likelihoods. compare results normal gamma distribution. log likelihood values show mpg variable better fit gamma distribution normal, although quite close.","code":"test <- testDistribution(mtcars$mpg, \"normal\") head(test$Data) #>            X    Y OriginalOrder isEV YDeviates #> 1:  7.313777 10.4            15   No 3.0862233 #> 2: 10.148901 10.4            16   No 0.2510990 #> 3: 11.680210 13.3            24   No 1.6197895 #> 4: 12.795066 14.3             7   No 1.5049335 #> 5: 13.698771 14.7            17   No 1.0012292 #> 6: 14.474288 15.0            31   No 0.5257124 table(test$Data$isEV) #>  #>  No Yes  #>  32   0  plot(test) test <- testDistribution(mtcars$mpg, \"normal\",                          extremevalues = \"theoretical\",                          ev.perc = .10) ## view the data with extreme values head(test$Data) #>            X    Y OriginalOrder isEV YDeviates #> 1:  7.313777 10.4            15  Yes 3.0862233 #> 2: 10.148901 10.4            16  Yes 0.2510990 #> 3: 11.680210 13.3            24   No 1.6197895 #> 4: 12.795066 14.3             7   No 1.5049335 #> 5: 13.698771 14.7            17   No 1.0012292 #> 6: 14.474288 15.0            31   No 0.5257124  ## count how many extreme values there are table(test$Data$isEV) #>  #>  No Yes  #>  26   6  ## plot the distribution plot(test) ## show which values are extreme test$Data[isEV == \"Yes\"] #>            X    Y OriginalOrder isEV YDeviates #> 1:  7.313777 10.4            15  Yes  3.086223 #> 2: 10.148901 10.4            16  Yes  0.251099 #> 3: 27.386184 30.4            19  Yes  3.013816 #> 4: 28.501040 30.4            28  Yes  1.898960 #> 5: 30.032349 32.4            18  Yes  2.367651 #> 6: 32.867473 33.9            20  Yes  1.032527  ## view extreme values on mpg in the original dataset ## by use the original order, the original rows to select ## the correct rows from the original dataset mtcars[test$Data[isEV == \"Yes\", OriginalOrder], ] #>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 test <- testDistribution(mtcars$mpg, \"normal\",                          extremevalues = \"empirical\",                          ev.perc = .10) head(test$Data) #>            X    Y OriginalOrder isEV YDeviates #> 1:  7.313777 10.4            15  Yes 3.0862233 #> 2: 10.148901 10.4            16  Yes 0.2510990 #> 3: 11.680210 13.3            24  Yes 1.6197895 #> 4: 12.795066 14.3             7  Yes 1.5049335 #> 5: 13.698771 14.7            17   No 1.0012292 #> 6: 14.474288 15.0            31   No 0.5257124 table(test$Data$isEV) #>  #>  No Yes  #>  24   8  plot(test) testN <- testDistribution(mtcars$mpg, \"normal\",                           extremevalues = \"theoretical\",                           ev.perc = .05) testG <- testDistribution(mtcars$mpg, \"gamma\",                           extremevalues = \"theoretical\",                           ev.perc = .05)  ## compare the log likelihood assuming a normal or gamma distribution testN$Distribution$LL #> 'log Lik.' -102.3778 (df=2) testG$Distribution$LL #> 'log Lik.' -100.9208 (df=2)  plot(testN) plot(testG)"},{"path":"https://joshuawiley.com/JWileymisc/articles/diagnostics-vignette.html","id":"model-diagnostics","dir":"Articles","previous_headings":"","what":"Model Diagnostics","title":"Diagnostics","text":"JWileymisc features support standard parametric model diagnostics. generic function modelDiagnostics() method implemented linear models. code follows, use modelDiagnostics() function calculate diagnostics plotted using matching plot() method. result plot standardized residuals expected (normal) distribution, QQ deviates plot saw testDistribution(). Together, provide information whether model assumption normality likely met, . addition, block dots black rug lines indicate relatively extreme residual values. label top left outcome variable name. Another plot scatter plot predicted values (x axis) standardized residuals (y axis). five number summary used x y axis. assess whether systematic trends residuals, loess line added solid blue line. assess heterogeneity/heteroscedasticity residuals, quantile regression lines added dashed blue lines. lines 10th 90th percentile distribution. Depending model data, quantile regression lines may use smoothing splines allow non-linear patterns. assumption residual variance homogenous, expect two lines approximately parallel flat, equal distance , across range predicted values. Note uncommon decide 5 percent values extreme. high value chosen illustrate . common values practice ev.perc = .001, ev.perc = .005 ev.perc = .01, capture 0.1%, 0.5%, 1% values, respectively. However, small dataset, give many “extreme values” illustration, higher value used.  Finally, given extreme values, may want identify exclude . can view extreme values. extract effect type outcome score associated . index shows index, residuals extreme values occurred. Note may match original data missing values. cases, easiest approach remove missing values model variables first, fit model calculate diagnostics. Using extreme values index, can exclude re-fit model see changes. can show summary coefficients model much change. values removed, new values may extreme. Although additional passes common, can done. following code, conduct new diagnostics model extreme values first model removed.","code":"m <- lm(mpg ~ hp * factor(cyl), data = mtcars)  md <- modelDiagnostics(m, ev.perc = .05) #> Warning in .local(x, ...): singularity problem #> Warning in rq.fit.sfn(x, y, tau = tau, rhs = rhs, control = control, ...): tiny diagonals replaced with Inf when calling blkfct #> Warning in .local(x, ...): singularity problem #> Warning in rq.fit.sfn(x, y, tau = tau, rhs = rhs, control = control, ...): tiny diagonals replaced with Inf when calling blkfct  plot(md, ncol = 1) ## show extreme values md$extremeValues #>     mpg Index EffectType #> 1: 24.4     8  Residuals #> 2: 10.4    15  Residuals #> 3: 33.9    20  Residuals #> 4: 30.4    28  Residuals  ## show extreme values in overall dataset mtcars[md$extremeValues$Index, 1:4] #>                     mpg cyl  disp  hp #> Merc 240D          24.4   4 146.7  62 #> Cadillac Fleetwood 10.4   8 472.0 205 #> Toyota Corolla     33.9   4  71.1  65 #> Lotus Europa       30.4   4  95.1 113 ## exclude extreme values m2 <- lm(mpg ~ hp * factor(cyl), data = mtcars[-md$extremeValues$Index, ])  ## show a summary of coefficients from both models ## and the percent change round(data.frame(   M1 = coef(m),   M2 = coef(m2),   PercentChange = coef(m2) / coef(m) * 100 - 100), 2) ## diagnostics after removing outliers from first model md2 <- modelDiagnostics(m2, ev.perc = .05) #> Warning in .local(x, ...): singularity problem #> Warning in rq.fit.sfn(x, y, tau = tau, rhs = rhs, control = control, ...): tiny diagonals replaced with Inf when calling blkfct #> Warning in .local(x, ...): singularity problem #> Warning in rq.fit.sfn(x, y, tau = tau, rhs = rhs, control = control, ...): tiny diagonals replaced with Inf when calling blkfct  plot(md2, ask = FALSE, ncol = 1) ## show (new) extreme values md2$extremeValues #>     mpg Index EffectType #> 1: 10.4    14  Residuals #> 2: 32.4    16  Residuals #> 3: 19.2    22  Residuals"},{"path":"https://joshuawiley.com/JWileymisc/articles/exploratory-vignette.html","id":"descriptive-statistics","dir":"Articles","previous_headings":"","what":"Descriptive Statistics","title":"Exploratory and Descriptive Statistics and Plots","text":"egltable() function calculates basic descriptive statistics. Example descriptive statistics table. strict argument can used variables categorical coded factors. case, vs two levels: 0 1 frequency percentage shown instead mean standard deviation. Example descriptive statistics table automatic categorical variables. egltable() also allows descriptive statistics broken another variable using g argument. separates results group also calculates bivariate tests differences groups effect sizes. example, t-tests continuous variables two groups chi-square tests categorical variables. two groups, ANOVAs used. Example descriptive statistics table group. skewed continuous variables, non-parametric statistics tests may appropriate. can generated using parametric argument. chi-square tests small cell sizes, simulated p-values also can generated. Example descriptive statistics table group.","code":"egltable(c(\"mpg\", \"hp\", \"qsec\", \"wt\", \"vs\"),          data = mtcars) egltable(c(\"mpg\", \"hp\", \"qsec\", \"wt\", \"vs\"),          data = mtcars, strict=FALSE) egltable(c(\"mpg\", \"hp\", \"qsec\", \"wt\", \"vs\"),    g = \"am\", data = mtcars, strict = FALSE) egltable(c(\"mpg\", \"hp\", \"qsec\", \"wt\", \"vs\"),           g = \"am\", data = mtcars, strict = FALSE,          parametric = FALSE)"},{"path":"https://joshuawiley.com/JWileymisc/articles/exploratory-vignette.html","id":"paired-data","dir":"Articles","previous_headings":"Descriptive Statistics","what":"Paired Data","title":"Exploratory and Descriptive Statistics and Plots","text":"already seen compare descriptives across groups groups independent. egltable() also supports using groups test paired samples. use , variable passed grouping argument, g must exactly two levels must also pass variable unique ID per unit specify paired =  TRUE. default continuous, paired data, mean standard deviations presented paired samples t-test used. pseudo Cohen’s d effect size calculated mean change score divided standard deviation change score. missing data, possible mean difference different difference means means calculated available data, effect size can calculated complete cases. Example parametric descriptive statistics paired data. want make parametric assumptions continuous variables, can set parametric = FALSE. case descriptives medians paired Wilcoxon test used. dataset ties warning generated ties zeroes. warning generally ignorable, central hypothesis tests, may warrant testing using, example, simulations precise case ties. Example non parametric descriptive statistics paired data. can also work categorical paired data. following code creates categorical variable, tertiles chick weights measured time. chick weight dataset many time points, just use two. special code needed work categorical variables. egltable() recognises categorical variables uses McNemar’s test, chi-square diagonals, tests whether people (chicks case) change groups equally time preferentially move one direction. case, significant result suggests time chicks’ weights change preferentially one way descriptive statistics show us increase weight tertile time 0 time 20. Continuous categorical paired data.","code":"## example with paired data egltable(   vars = \"extra\",   g = \"group\",   data = sleep,   idvar = \"ID\",   paired = TRUE) egltable(   vars = \"extra\",   g = \"group\",   data = sleep,   idvar = \"ID\",   paired = TRUE,   parametric = FALSE) #> Warning in wilcox.test.default(widedat$dv2, widedat$dv1, paired = TRUE): cannot #> compute exact p-value with ties #> Warning in wilcox.test.default(widedat$dv2, widedat$dv1, paired = TRUE): cannot #> compute exact p-value with zeroes ## paired categorical data example ## using data on chick weights to create categorical data tmp <- subset(ChickWeight, Time %in% c(0, 20)) tmp$WeightTertile <- cut(tmp$weight,   breaks = quantile(tmp$weight, c(0, 1/3, 2/3, 1), na.rm = TRUE),   include.lowest = TRUE) egltable(c(\"weight\", \"WeightTertile\"), g = \"Time\",   data = tmp,   idvar = \"Chick\", paired = TRUE)"},{"path":"https://joshuawiley.com/JWileymisc/articles/exploratory-vignette.html","id":"correlation-summaries","dir":"Articles","previous_headings":"","what":"Correlation Summaries","title":"Exploratory and Descriptive Statistics and Plots","text":"continuous variables, correlation matrices commonly examined. especially true structural equation models path analyses. SEMSummary() function provides simple way generate various options. formula interface, similar lm() regression models. Missing data can handled using listwise deletion, pairwise present data, full information maximum likelihood (FIML). assumptions met, FIML less biased uses available data, default. correlations can nicely formatted table. Example correlation table. Plot methods exist SEMSummary() objects. default, diagonal correlations diagonal p-values. However, type argument can set (see ?corplot) get values either correlations p-values. default, another useful feature hierarchical clustering used group similar variables together clusters, provided useful sorting data many “default” correlation matrices. specific order desired, can use order = \"asis\" option keep variable order written SEMSummary().","code":"m <- SEMSummary(~ mpg + hp + qsec + wt, data = mtcars)  corTab <- APAStyler(m, type = \"cor\", stars = TRUE) #>         N  M      SD    1.  2.       3.       4.       #> 1. mpg  32  20.09  6.03  -  -0.78***  0.42*   -0.87*** #> 2. hp   32 146.69 68.56      -       -0.71***  0.66*** #> 3. qsec 32  17.85  1.79               -       -0.17    #> 4. wt   32   3.22  0.98                        -       #>  #> Percentage of coverage for each pairwise covariance or correlation #>  #>      mpg hp qsec wt #> mpg  1   1  1    1  #> hp       1  1    1  #> qsec        1    1  #> wt               1 plot(m) +   ggtitle(\"Order by hierarchical clustering\") plot(m, order = \"asis\") +   ggtitle(\"Order as written\") plot(m, type = \"p\") +   ggtitle(\"Numbers are p-values\")"},{"path":"https://joshuawiley.com/JWileymisc/articles/exploratory-vignette.html","id":"grouped-correlations","dir":"Articles","previous_headings":"Correlation Summaries","what":"Grouped Correlations","title":"Exploratory and Descriptive Statistics and Plots","text":"Correlations also can broken group. results separated species automaticaly used title graph.","code":"mg <- SEMSummary(~ Sepal.Length + Petal.Length +                   Sepal.Width + Petal.Width | Species,                  data = iris)  plot(mg) #> $`1` #>  #> $`2` #>  #> attr(,\"class\") #> [1] \"list\"      \"ggarrange\""},{"path":"https://joshuawiley.com/JWileymisc/articles/exploratory-vignette.html","id":"likert-scale-plots","dir":"Articles","previous_headings":"","what":"Likert Scale Plots","title":"Exploratory and Descriptive Statistics and Plots","text":"much psychological consumer/market research, likert rating scales used. example, rating question/item “Strongly DISagree” “Strongly Agree” rating satisfaction “” “Satisfied” adjectives capture mood/affect “” “Extremely”. Likert plots aim show results clearly aid interpretation presenting anchors well. following code creates simulated data, summarizes , adds necessary labels/anchors, creates nice plot.","code":"## simulate some likert style data set.seed(1234) d <- data.table(   Happy = sample(1:5, 200, TRUE, c(.1, .2, .4, .2, .1)),   Cheerful = sample(1:5, 200, TRUE, c(.1, .2, .2, .4, .1)),   Peaceful = sample(1:5, 200, TRUE, c(.1, .1, .2, .4, .2)),   Sad = sample(1:5, 200, TRUE, c(.1, .3, .3, .2, .1)),   Hopeless = sample(1:5, 200, TRUE, c(.3, .3, .2, .2, 0)),     Angry = sample(1:5, 200, TRUE, c(.4, .3, .2, .08, .02)))  dmeans <- melt(d, measure.vars = names(d))[,   .(Mean = mean(value, na.rm = TRUE)), by = variable]  dmeans[, Low := paste0(variable, \"\\nNot at all\")] dmeans[, High := paste0(variable, \"\\nExtremely\")] dmeans[, variable := as.integer(factor(variable))]  ## view the summarised data print(dmeans) #>    variable  Mean                  Low                High #> 1:        1 2.945    Happy\\nNot at all    Happy\\nExtremely #> 2:        2 3.060 Cheerful\\nNot at all Cheerful\\nExtremely #> 3:        3 3.555 Peaceful\\nNot at all Peaceful\\nExtremely #> 4:        4 2.870      Sad\\nNot at all      Sad\\nExtremely #> 5:        5 2.280 Hopeless\\nNot at all Hopeless\\nExtremely #> 6:        6 1.880    Angry\\nNot at all    Angry\\nExtremely  gglikert(\"Mean\", \"variable\", \"Low\", \"High\", data = dmeans,          xlim = c(1, 5),          title = \"Average Affect Ratings\") ## create a grouping variable dg <- cbind(d, Group = ifelse(                  d$Happy > mean(d$Happy, na.rm = TRUE),                  \"General Population\", \"Depressed\"))  dgmeans <- melt(dg, measure.vars = names(d), id.vars = \"Group\")[,   .(Mean = mean(value, na.rm = TRUE)), by = .(variable, Group)]  dgmeans[, Low := paste0(variable, \"\\nNot at all\")] dgmeans[, High := paste0(variable, \"\\nExtremely\")] dgmeans[, variable := as.integer(factor(variable))]  ## view the summarised data print(dgmeans) #>     variable              Group     Mean                  Low #>  1:        1 General Population 3.510791    Happy\\nNot at all #>  2:        1          Depressed 1.655738    Happy\\nNot at all #>  3:        2 General Population 3.043165 Cheerful\\nNot at all #>  4:        2          Depressed 3.098361 Cheerful\\nNot at all #>  5:        3 General Population 3.633094 Peaceful\\nNot at all #>  6:        3          Depressed 3.377049 Peaceful\\nNot at all #>  7:        4 General Population 2.906475      Sad\\nNot at all #>  8:        4          Depressed 2.786885      Sad\\nNot at all #>  9:        5 General Population 2.309353 Hopeless\\nNot at all #> 10:        5          Depressed 2.213115 Hopeless\\nNot at all #> 11:        6 General Population 1.834532    Angry\\nNot at all #> 12:        6          Depressed 1.983607    Angry\\nNot at all #>                    High #>  1:    Happy\\nExtremely #>  2:    Happy\\nExtremely #>  3: Cheerful\\nExtremely #>  4: Cheerful\\nExtremely #>  5: Peaceful\\nExtremely #>  6: Peaceful\\nExtremely #>  7:      Sad\\nExtremely #>  8:      Sad\\nExtremely #>  9: Hopeless\\nExtremely #> 10: Hopeless\\nExtremely #> 11:    Angry\\nExtremely #> 12:    Angry\\nExtremely  gglikert(\"Mean\", \"variable\", \"Low\", \"High\",          colour = \"Group\",          data = dgmeans,          xlim = c(1, 5),          title = \"Average Affect Ratings\") +   scale_colour_manual(     values = c(\"Depressed\" = \"black\",                \"General Population\" = \"grey70\"))"},{"path":"https://joshuawiley.com/JWileymisc/articles/model-test-vignette.html","id":"model-performance","dir":"Articles","previous_headings":"","what":"Model Performance","title":"Model Performance and Tests","text":"modelPerformance() generic function can used calculate performance metrics model. JWileymisc implements methods lm class objects. output named list, data table containing results. linear models, current performance metrics include: AIC (Akaike Information Criterion) BIC (Bayesian Information Criterion) LL (Log Likelihood) LLDF (degrees freedom log likelihood) Sigma (residual standard deviation) R2 (\\(R^2\\) variance accounted sample) F2 (Cohen’s \\(f^2\\) effect size, calculated \\(\\frac{R^{2}}{1 - R^{2}}\\)) AdjR2 (Sample size adjusted \\(R^2\\), better estimate population variance accounted ) F (model F test) FNumDF (numerator degrees freedom model F test) FDenDF (denominator degrees freedom model F test) P (p value model F test) certain metrics desired, can found extracting “Performance” list element correct column data table. Another function, modelTest() generic providing comprehensive series tests model. Currently methods implemented lm class models vglm class models VGAM package multinomial family. modelTest() model tests can also used interactions.","code":"mtcars$cyl <- factor(mtcars$cyl) m <- stats::lm(mpg ~ hp + cyl, data = mtcars)  mp <- modelPerformance(m) print(mp) #> $Performance #>    Model N_Obs      AIC      BIC        LL LLDF    Sigma        R2       F2 #> 1:    lm    32 169.8964 177.2251 -79.94822    5 3.146243 0.7538578 3.062692 #>        AdjR2        F FNumDF FDenDF           P #> 1: 0.7274854 28.58513      3     28 1.13969e-08 #>  #> attr(,\"class\") #> [1] \"modelPerformance.lm\" \"modelPerformance\" ## Cohen's f^2 effect size mp$Performance[, F2] #> [1] 3.062692 mt <- modelTest(m) print(mt) #> $FixedEffects #>           Term         Est           LL           UL         Pval #> 1: (Intercept) 28.65011816  25.39768395 31.902552374 5.921199e-17 #> 2:          hp -0.02403883  -0.05560048  0.007522814 1.299540e-01 #> 3:        cyl6 -5.96765508  -9.32556307 -2.609747083 1.092089e-03 #> 4:        cyl8 -8.52085075 -13.28559928 -3.756102224 1.028617e-03 #>  #> $RandomEffects #> [1] NA #>  #> $EffectSizes #>    Term N_Obs         AIC        BIC       LL LLDF       Sigma         R2 #> 1:   hp     0  -0.6675031  0.7982328 1.333752    1 -0.07685536 0.02139775 #> 2:  cyl     0 -11.3421811 -8.4107093 7.671091    2 -0.71671885 0.15142046 #>            F2     AdjR2        F FNumDF FDenDF           P  Type #> 1: 0.08693246 0.0134764 2.434109      1     28 0.129954045 Fixed #> 2: 0.61517476 0.1383002 8.612447      2     28 0.001215981 Fixed #>  #> $OverallModel #> $Performance #>    Model N_Obs      AIC      BIC        LL LLDF    Sigma        R2       F2 #> 1:    lm    32 169.8964 177.2251 -79.94822    5 3.146243 0.7538578 3.062692 #>        AdjR2        F FNumDF FDenDF           P #> 1: 0.7274854 28.58513      3     28 1.13969e-08 #>  #> attr(,\"class\") #> [1] \"modelPerformance.lm\" \"modelPerformance\"    #>  #> attr(,\"class\") #> [1] \"modelTest.lm\" \"modelTest\" APAStyler(mt) #>                 Term                      Est          Type #>  1:      (Intercept) 28.65*** [ 25.40, 31.90] Fixed Effects #>  2:               hp    -0.02 [ -0.06,  0.01] Fixed Effects #>  3:             cyl6  -5.97** [ -9.33, -2.61] Fixed Effects #>  4:             cyl8  -8.52** [-13.29, -3.76] Fixed Effects #>  5: N (Observations)                       32 Overall Model #>  6:        logLik DF                        5 Overall Model #>  7:           logLik                   -79.95 Overall Model #>  8:              AIC                   169.90 Overall Model #>  9:              BIC                   177.23 Overall Model #> 10:               F2                     3.06 Overall Model #> 11:               R2                     0.75 Overall Model #> 12:           Adj R2                     0.73 Overall Model #> 13:               hp      f2 = 0.09, p = .130  Effect Sizes #> 14:              cyl      f2 = 0.62, p = .001  Effect Sizes m2 <- stats::lm(mpg ~ hp * cyl, data = mtcars)  APAStyler(modelTest(m2)) #>                 Term                       Est          Type #>  1:      (Intercept)  35.98*** [ 27.99, 43.98] Fixed Effects #>  2:               hp    -0.11* [ -0.21, -0.02] Fixed Effects #>  3:             cyl6   -15.31* [-30.59, -0.03] Fixed Effects #>  4:             cyl8  -17.90** [-28.71, -7.09] Fixed Effects #>  5:          hp:cyl6      0.11 [ -0.04,  0.25] Fixed Effects #>  6:          hp:cyl8      0.10 [  0.00,  0.20] Fixed Effects #>  7: N (Observations)                        32 Overall Model #>  8:        logLik DF                         7 Overall Model #>  9:           logLik                    -77.54 Overall Model #> 10:              AIC                    169.08 Overall Model #> 11:              BIC                    179.34 Overall Model #> 12:               F2                      3.72 Overall Model #> 13:               R2                      0.79 Overall Model #> 14:           Adj R2                      0.75 Overall Model #> 15:               hp       f2 = 0.23, p = .021  Effect Sizes #> 16:              cyl       f2 = 0.47, p = .007  Effect Sizes #> 17:           hp:cyl       f2 = 0.16, p = .142  Effect Sizes"},{"path":"https://joshuawiley.com/JWileymisc/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Joshua F. Wiley. Author, maintainer.","code":""},{"path":"https://joshuawiley.com/JWileymisc/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wiley J (2023). JWileymisc: Miscellaneous Utilities Functions. https://joshuawiley.com/JWileymisc/, https://github.com/JWiley/JWileymisc.","code":"@Manual{,   title = {JWileymisc: Miscellaneous Utilities and Functions},   author = {Joshua F. Wiley},   year = {2023},   note = {https://joshuawiley.com/JWileymisc/, https://github.com/JWiley/JWileymisc}, }"},{"path":"https://joshuawiley.com/JWileymisc/index.html","id":"jwileymisc","dir":"","previous_headings":"","what":"JWileymisc","title":"JWileymisc","text":"R package general utility convenience functions. general functions help using exploring SEM style data. Others specific. package grown work, often automate repetitive tasks. See Vignettes, listed “Articles” menu item description examples using interesting functions package.","code":""},{"path":"https://joshuawiley.com/JWileymisc/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"JWileymisc","text":"get latest development version, use: get version CRAN:","code":"#install.packages(\"devtools\")  devtools::install_github(\"JWiley/JWileymisc\") install.packages(\"JWileymisc\")"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.SEMSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"A generic function for pretty printing in (semi) APA Style — APAStyler.SEMSummary","title":"A generic function for pretty printing in (semi) APA Style — APAStyler.SEMSummary","text":"generic function pretty printing (semi) APA Style","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.SEMSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A generic function for pretty printing in (semi) APA Style — APAStyler.SEMSummary","text":"","code":"# S3 method for SEMSummary APAStyler(   object,   digits = 2,   type = c(\"cov\", \"cor\", \"both\"),   stars = FALSE,   file = ifelse(.Platform$OS.type == \"windows\", \"clipboard\", FALSE),   sep = \"\\t\",   print = TRUE,   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.SEMSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A generic function for pretty printing in (semi) APA Style — APAStyler.SEMSummary","text":"object SEMSummary object digits number digits round results . Defaults 2. type character vector giving print. Defaults ‘cov’, covariances. options ‘cor’ ‘’. stars logical value whether include significance values stars (*** p < .001, ** p < .01, * p < .05). file optional argument indicating whether output written file. sep Character separator table . Defaults tabs. print logical argument, whether print results screen. distinct saving file. Defaults TRUE back compatibility. ... Additional argiuments passed write.table.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.SEMSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A generic function for pretty printing in (semi) APA Style — APAStyler.SEMSummary","text":"","code":"m <- SEMSummary(~., data = mtcars) APAStyler(m, type = \"cor\", stars = FALSE, file = FALSE) #>          N  M      SD     1.  2.    3.    4.    5.    6.    7.    8.    9.    #> 1. mpg   32  20.09   6.03  -  -0.85 -0.85 -0.78  0.68 -0.87  0.42  0.66  0.60 #> 2. cyl   32   6.19   1.79      -     0.90  0.83 -0.70  0.78 -0.59 -0.81 -0.52 #> 3. disp  32 230.72 123.94            -     0.79 -0.71  0.89 -0.43 -0.71 -0.59 #> 4. hp    32 146.69  68.56                  -    -0.45  0.66 -0.71 -0.72 -0.24 #> 5. drat  32   3.60   0.53                        -    -0.71  0.09  0.44  0.71 #> 6. wt    32   3.22   0.98                              -    -0.17 -0.55 -0.69 #> 7. qsec  32  17.85   1.79                                    -     0.74 -0.23 #> 8. vs    32   0.44   0.50                                          -     0.17 #> 9. am    32   0.41   0.50                                                -    #> 10. gear 32   3.69   0.74                                                     #> 11. carb 32   2.81   1.62                                                     #>          10.   11.   #> 1. mpg    0.48 -0.55 #> 2. cyl   -0.49  0.53 #> 3. disp  -0.56  0.39 #> 4. hp    -0.13  0.75 #> 5. drat   0.70 -0.09 #> 6. wt    -0.58  0.43 #> 7. qsec  -0.21 -0.66 #> 8. vs     0.21 -0.57 #> 9. am     0.79  0.06 #> 10. gear  -     0.27 #> 11. carb        -    #>  #> Percentage of coverage for each pairwise covariance or correlation #>  #>      mpg cyl disp hp drat wt qsec vs am gear carb #> mpg  1   1   1    1  1    1  1    1  1  1    1    #> cyl      1   1    1  1    1  1    1  1  1    1    #> disp         1    1  1    1  1    1  1  1    1    #> hp                1  1    1  1    1  1  1    1    #> drat                 1    1  1    1  1  1    1    #> wt                        1  1    1  1  1    1    #> qsec                         1    1  1  1    1    #> vs                                1  1  1    1    #> am                                   1  1    1    #> gear                                    1    1    #> carb                                         1    APAStyler(m, type = \"cov\", stars = FALSE, file = FALSE) #>          N  M      SD     1.  2.       3.       4.       5.       6.       #> 1. mpg   32  20.09   6.03  -     -9.17  -633.10  -320.73     2.20    -5.12 #> 2. cyl   32   6.19   1.79      -         199.66   101.93    -0.67     1.37 #> 3. disp  32 230.72 123.94               -        6721.16   -47.06   107.68 #> 4. hp    32 146.69  68.56                        -         -16.45    44.19 #> 5. drat  32   3.60   0.53                                 -          -0.37 #> 6. wt    32   3.22   0.98                                          -       #> 7. qsec  32  17.85   1.79                                                  #> 8. vs    32   0.44   0.50                                                  #> 9. am    32   0.41   0.50                                                  #> 10. gear 32   3.69   0.74                                                  #> 11. carb 32   2.81   1.62                                                  #>          7.       8.       9.       10.      11.      #> 1. mpg       4.51     2.02     1.80     2.14    -5.36 #> 2. cyl      -1.89    -0.73    -0.47    -0.65     1.52 #> 3. disp    -96.05   -44.38   -36.56   -50.80    79.07 #> 4. hp      -86.77   -24.99    -8.32    -6.36    83.04 #> 5. drat      0.09     0.12     0.19     0.28    -0.08 #> 6. wt       -0.31    -0.27    -0.34    -0.42     0.68 #> 7. qsec   -           0.67    -0.20    -0.28    -1.89 #> 8. vs              -           0.04     0.08    -0.46 #> 9. am                       -           0.29     0.05 #> 10. gear                             -           0.33 #> 11. carb                                      -       #>  #> Percentage of coverage for each pairwise covariance or correlation #>  #>      mpg cyl disp hp drat wt qsec vs am gear carb #> mpg  1   1   1    1  1    1  1    1  1  1    1    #> cyl      1   1    1  1    1  1    1  1  1    1    #> disp         1    1  1    1  1    1  1  1    1    #> hp                1  1    1  1    1  1  1    1    #> drat                 1    1  1    1  1  1    1    #> wt                        1  1    1  1  1    1    #> qsec                         1    1  1  1    1    #> vs                                1  1  1    1    #> am                                   1  1    1    #> gear                                    1    1    #> carb                                         1    APAStyler(m, type = \"both\", stars = FALSE, file = FALSE) #>          N  M      SD     1.    2.       3.       4.       5.       6.       #> 1. mpg   32  20.09   6.03  -       -9.17  -633.10  -320.73     2.20    -5.12 #> 2. cyl   32   6.19   1.79 -0.85  -         199.66   101.93    -0.67     1.37 #> 3. disp  32 230.72 123.94 -0.85  0.90     -        6721.16   -47.06   107.68 #> 4. hp    32 146.69  68.56 -0.78  0.83     0.79     -         -16.45    44.19 #> 5. drat  32   3.60   0.53  0.68 -0.70    -0.71    -0.45     -          -0.37 #> 6. wt    32   3.22   0.98 -0.87  0.78     0.89     0.66    -0.71     -       #> 7. qsec  32  17.85   1.79  0.42 -0.59    -0.43    -0.71     0.09    -0.17    #> 8. vs    32   0.44   0.50  0.66 -0.81    -0.71    -0.72     0.44    -0.55    #> 9. am    32   0.41   0.50  0.60 -0.52    -0.59    -0.24     0.71    -0.69    #> 10. gear 32   3.69   0.74  0.48 -0.49    -0.56    -0.13     0.70    -0.58    #> 11. carb 32   2.81   1.62 -0.55  0.53     0.39     0.75    -0.09     0.43    #>          7.       8.       9.       10.      11.      #> 1. mpg       4.51     2.02     1.80     2.14    -5.36 #> 2. cyl      -1.89    -0.73    -0.47    -0.65     1.52 #> 3. disp    -96.05   -44.38   -36.56   -50.80    79.07 #> 4. hp      -86.77   -24.99    -8.32    -6.36    83.04 #> 5. drat      0.09     0.12     0.19     0.28    -0.08 #> 6. wt       -0.31    -0.27    -0.34    -0.42     0.68 #> 7. qsec   -           0.67    -0.20    -0.28    -1.89 #> 8. vs     0.74     -           0.04     0.08    -0.46 #> 9. am    -0.23     0.17     -           0.29     0.05 #> 10. gear -0.21     0.21     0.79     -           0.33 #> 11. carb -0.66    -0.57     0.06     0.27     -       #>  #> Percentage of coverage for each pairwise covariance or correlation #>  #>      mpg cyl disp hp drat wt qsec vs am gear carb #> mpg  1   1   1    1  1    1  1    1  1  1    1    #> cyl      1   1    1  1    1  1    1  1  1    1    #> disp         1    1  1    1  1    1  1  1    1    #> hp                1  1    1  1    1  1  1    1    #> drat                 1    1  1    1  1  1    1    #> wt                        1  1    1  1  1    1    #> qsec                         1    1  1  1    1    #> vs                                1  1  1    1    #> am                                   1  1    1    #> gear                                    1    1    #> carb                                         1    APAStyler(m, type = \"cor\", stars = TRUE, file = FALSE) #>          N  M      SD     1.  2.       3.       4.       5.       6.       #> 1. mpg   32  20.09   6.03  -  -0.85*** -0.85*** -0.78***  0.68*** -0.87*** #> 2. cyl   32   6.19   1.79      -        0.90***  0.83*** -0.70***  0.78*** #> 3. disp  32 230.72 123.94               -        0.79*** -0.71***  0.89*** #> 4. hp    32 146.69  68.56                        -       -0.45**   0.66*** #> 5. drat  32   3.60   0.53                                 -       -0.71*** #> 6. wt    32   3.22   0.98                                          -       #> 7. qsec  32  17.85   1.79                                                  #> 8. vs    32   0.44   0.50                                                  #> 9. am    32   0.41   0.50                                                  #> 10. gear 32   3.69   0.74                                                  #> 11. carb 32   2.81   1.62                                                  #>          7.       8.       9.       10.      11.      #> 1. mpg    0.42*    0.66***  0.60***  0.48**  -0.55**  #> 2. cyl   -0.59*** -0.81*** -0.52**  -0.49**   0.53**  #> 3. disp  -0.43*   -0.71*** -0.59*** -0.56***  0.39*   #> 4. hp    -0.71*** -0.72*** -0.24    -0.13     0.75*** #> 5. drat   0.09     0.44*    0.71***  0.70*** -0.09    #> 6. wt    -0.17    -0.55*** -0.69*** -0.58***  0.43*   #> 7. qsec   -        0.74*** -0.23    -0.21    -0.66*** #> 8. vs              -        0.17     0.21    -0.57*** #> 9. am                       -        0.79***  0.06    #> 10. gear                             -        0.27    #> 11. carb                                      -       #>  #> Percentage of coverage for each pairwise covariance or correlation #>  #>      mpg cyl disp hp drat wt qsec vs am gear carb #> mpg  1   1   1    1  1    1  1    1  1  1    1    #> cyl      1   1    1  1    1  1    1  1  1    1    #> disp         1    1  1    1  1    1  1  1    1    #> hp                1  1    1  1    1  1  1    1    #> drat                 1    1  1    1  1  1    1    #> wt                        1  1    1  1  1    1    #> qsec                         1    1  1  1    1    #> vs                                1  1  1    1    #> am                                   1  1    1    #> gear                                    1    1    #> carb                                         1    APAStyler(m, type = \"cov\", stars = TRUE, file = FALSE) #>          N  M      SD     1.  2.          3.          4.          5.          #> 1. mpg   32  20.09   6.03  -     -9.17***  -633.10***  -320.73***     2.20*** #> 2. cyl   32   6.19   1.79      -            199.66***   101.93***    -0.67*** #> 3. disp  32 230.72 123.94                  -           6721.16***   -47.06*** #> 4. hp    32 146.69  68.56                              -            -16.45**  #> 5. drat  32   3.60   0.53                                          -          #> 6. wt    32   3.22   0.98                                                     #> 7. qsec  32  17.85   1.79                                                     #> 8. vs    32   0.44   0.50                                                     #> 9. am    32   0.41   0.50                                                     #> 10. gear 32   3.69   0.74                                                     #> 11. carb 32   2.81   1.62                                                     #>          6.          7.          8.          9.          10.         #> 1. mpg      -5.12***     4.51*       2.02***     1.80***     2.14**  #> 2. cyl       1.37***    -1.89***    -0.73***    -0.47**     -0.65**  #> 3. disp    107.68***   -96.05*     -44.38***   -36.56***   -50.80*** #> 4. hp       44.19***   -86.77***   -24.99***    -8.32       -6.36    #> 5. drat     -0.37***     0.09        0.12*       0.19***     0.28*** #> 6. wt     -             -0.31       -0.27***    -0.34***    -0.42*** #> 7. qsec               -              0.67***    -0.20       -0.28    #> 8. vs                             -              0.04        0.08    #> 9. am                                         -              0.29*** #> 10. gear                                                  -          #> 11. carb                                                             #>          11.         #> 1. mpg      -5.36**  #> 2. cyl       1.52**  #> 3. disp     79.07*   #> 4. hp       83.04*** #> 5. drat     -0.08    #> 6. wt        0.68*   #> 7. qsec     -1.89*** #> 8. vs       -0.46*** #> 9. am        0.05    #> 10. gear     0.33    #> 11. carb  -          #>  #> Percentage of coverage for each pairwise covariance or correlation #>  #>      mpg cyl disp hp drat wt qsec vs am gear carb #> mpg  1   1   1    1  1    1  1    1  1  1    1    #> cyl      1   1    1  1    1  1    1  1  1    1    #> disp         1    1  1    1  1    1  1  1    1    #> hp                1  1    1  1    1  1  1    1    #> drat                 1    1  1    1  1  1    1    #> wt                        1  1    1  1  1    1    #> qsec                         1    1  1  1    1    #> vs                                1  1  1    1    #> am                                   1  1    1    #> gear                                    1    1    #> carb                                         1    APAStyler(m, type = \"both\", stars = TRUE, file = FALSE) #>          N  M      SD     1.       2.          3.          4.          #> 1. mpg   32  20.09   6.03  -          -9.17***  -633.10***  -320.73*** #> 2. cyl   32   6.19   1.79 -0.85***  -            199.66***   101.93*** #> 3. disp  32 230.72 123.94 -0.85***  0.90***     -           6721.16*** #> 4. hp    32 146.69  68.56 -0.78***  0.83***     0.79***     -          #> 5. drat  32   3.60   0.53  0.68*** -0.70***    -0.71***    -0.45**     #> 6. wt    32   3.22   0.98 -0.87***  0.78***     0.89***     0.66***    #> 7. qsec  32  17.85   1.79  0.42*   -0.59***    -0.43*      -0.71***    #> 8. vs    32   0.44   0.50  0.66*** -0.81***    -0.71***    -0.72***    #> 9. am    32   0.41   0.50  0.60*** -0.52**     -0.59***    -0.24       #> 10. gear 32   3.69   0.74  0.48**  -0.49**     -0.56***    -0.13       #> 11. carb 32   2.81   1.62 -0.55**   0.53**      0.39*       0.75***    #>          5.          6.          7.          8.          9.          #> 1. mpg       2.20***    -5.12***     4.51*       2.02***     1.80*** #> 2. cyl      -0.67***     1.37***    -1.89***    -0.73***    -0.47**  #> 3. disp    -47.06***   107.68***   -96.05*     -44.38***   -36.56*** #> 4. hp      -16.45**     44.19***   -86.77***   -24.99***    -8.32    #> 5. drat   -             -0.37***     0.09        0.12*       0.19*** #> 6. wt    -0.71***     -             -0.31       -0.27***    -0.34*** #> 7. qsec   0.09       -0.17        -              0.67***    -0.20    #> 8. vs     0.44*      -0.55***     0.74***     -              0.04    #> 9. am     0.71***    -0.69***    -0.23        0.17        -          #> 10. gear  0.70***    -0.58***    -0.21        0.21        0.79***    #> 11. carb -0.09        0.43*      -0.66***    -0.57***     0.06       #>          10.         11.         #> 1. mpg       2.14**     -5.36**  #> 2. cyl      -0.65**      1.52**  #> 3. disp    -50.80***    79.07*   #> 4. hp       -6.36       83.04*** #> 5. drat      0.28***    -0.08    #> 6. wt       -0.42***     0.68*   #> 7. qsec     -0.28       -1.89*** #> 8. vs        0.08       -0.46*** #> 9. am        0.29***     0.05    #> 10. gear  -              0.33    #> 11. carb  0.27        -          #>  #> Percentage of coverage for each pairwise covariance or correlation #>  #>      mpg cyl disp hp drat wt qsec vs am gear carb #> mpg  1   1   1    1  1    1  1    1  1  1    1    #> cyl      1   1    1  1    1  1    1  1  1    1    #> disp         1    1  1    1  1    1  1  1    1    #> hp                1  1    1  1    1  1  1    1    #> drat                 1    1  1    1  1  1    1    #> wt                        1  1    1  1  1    1    #> qsec                         1    1  1  1    1    #> vs                                1  1  1    1    #> am                                   1  1    1    #> gear                                    1    1    #> carb                                         1"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.html","id":null,"dir":"Reference","previous_headings":"","what":"A generic function for pretty printing in (semi) APA Style — APAStyler","title":"A generic function for pretty printing in (semi) APA Style — APAStyler","text":"generic function pretty printing (semi) APA Style","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A generic function for pretty printing in (semi) APA Style — APAStyler","text":"","code":"APAStyler(object, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A generic function for pretty printing in (semi) APA Style — APAStyler","text":"object object class matching one methods ... Additional argiuments passed methods.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.list.html","id":null,"dir":"Reference","previous_headings":"","what":"APAStyler method for lists — APAStyler.list","title":"APAStyler method for lists — APAStyler.list","text":"assumes objects list class APAStyler method exists class.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"APAStyler method for lists — APAStyler.list","text":"","code":"# S3 method for list APAStyler(object, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"APAStyler method for lists — APAStyler.list","text":"object list case, element another known class. ... Additional arguments.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"APAStyler method for lists — APAStyler.list","text":"Styled results.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"APAStyler method for lists — APAStyler.list","text":"","code":"if (FALSE) { m1 <- lm(mpg ~ qsec * hp, data = mtcars) m2 <- lm(mpg ~ qsec + hp, data = mtcars) m3 <- lm(mpg ~ am + vs, data = mtcars) mt1 <- modelTest(m1) mt2 <- modelTest(m2) mt3 <- modelTest(m3)  ## styling regression models APAStyler(list(m1, m2))  ## modelTest objects get merged APAStyler(list(mt1, mt2))  ## the models can be named by passing a named list ## including \"special\" characters using backticks, like spaces APAStyler(list(Full = mt1, Reduced = mt2)) APAStyler(list(Full = mt1, Reduced = mt2, `Alternate Model` = mt3))  ## you can customize the way output is presented APAStyler(list(mt1, mt2), format = list(   FixedEffects = \"%s, %s\\n(%s, %s)\",   EffectSizes = \"Cohen's f2 = %s (%s)\"))  ## clean up rm(m1, m2, m3, mt1, mt2, mt3) }"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"APAStyler method for linear models — APAStyler.lm","title":"APAStyler method for linear models — APAStyler.lm","text":"APAStyler method linear models","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"APAStyler method for linear models — APAStyler.lm","text":"","code":"# S3 method for lm APAStyler(object, digits = 2, pdigits, file, print = TRUE, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"APAStyler method for linear models — APAStyler.lm","text":"object lm object digits number digits round results . Defaults 2. pdigits number digits use p values. Defaults digits + 1 missing. file optional argument indicating whether output written file. print logical argument, whether print results screen. distinct saving file. Defaults TRUE back compatibility. ... Additional argiuments passed write.table.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.mira.html","id":null,"dir":"Reference","previous_headings":"","what":"A generic function for pretty printing in (semi) APA Style — APAStyler.mira","title":"A generic function for pretty printing in (semi) APA Style — APAStyler.mira","text":"generic function pretty printing (semi) APA Style","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.mira.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A generic function for pretty printing in (semi) APA Style — APAStyler.mira","text":"","code":"# S3 method for mira APAStyler(object, lmobject, digits = 2, pdigits, print = TRUE, file, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.mira.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A generic function for pretty printing in (semi) APA Style — APAStyler.mira","text":"object mira object lmobject lm object degrees freedom can used conservative F tests digits number digits round results . Defaults 2. pdigits number digits use p values. Defaults digits + 1 missing. print logical argument, whether print results screen. distinct saving file. Defaults TRUE back compatibility. file optional argument indicating whether output written file. ... Additional argiuments passed write.table.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"APAStyler method for model tests from a linear model — APAStyler.modelTest.lm","title":"APAStyler method for model tests from a linear model — APAStyler.modelTest.lm","text":"APAStyler method model tests linear model","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"APAStyler method for model tests from a linear model — APAStyler.modelTest.lm","text":"","code":"# S3 method for modelTest.lm APAStyler(   object,   format = list(FixedEffects = c(\"%s%s [%s, %s]\"), EffectSizes = c(\"f2 = %s, %s\")),   digits = 2,   pcontrol = list(digits = 3, stars = TRUE, includeP = FALSE, includeSign = FALSE,     dropLeadingZero = TRUE),   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"APAStyler method for model tests from a linear model — APAStyler.modelTest.lm","text":"object modelTest.lm class object, results running modelTest() function class lm object. format list giving formatting style used fixed effecvts effect sizes. digits numeric value indicating number digits print. still early implementation stages currently change parts output (default 2 decimals per APA style). pcontrol list controlling p values formatted. ... Additional arguments.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"APAStyler method for model tests from a linear model — APAStyler.modelTest.lm","text":"Styled results.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"APAStyler method for model tests from a linear model — APAStyler.modelTest.lm","text":"","code":"m1 <- lm(mpg ~ qsec * hp, data = mtcars) APAStyler(modelTest(m1)) #>                 Term                      Est          Type #>  1:      (Intercept)     8.52 [-17.15, 34.20] Fixed Effects #>  2:             qsec    1.48* [  0.08,  2.87] Fixed Effects #>  3:               hp   0.24** [  0.09,  0.39] Fixed Effects #>  4:          qsec:hp -0.02*** [ -0.03, -0.01] Fixed Effects #>  5: N (Observations)                       32 Overall Model #>  6:        logLik DF                        5 Overall Model #>  7:           logLik                   -77.75 Overall Model #>  8:              AIC                   165.50 Overall Model #>  9:              BIC                   172.83 Overall Model #> 10:               F2                     3.66 Overall Model #> 11:               R2                     0.79 Overall Model #> 12:           Adj R2                     0.76 Overall Model #> 13:             qsec      f2 = 0.17, p = .039  Effect Sizes #> 14:               hp      f2 = 0.37, p = .003  Effect Sizes #> 15:          qsec:hp      f2 = 0.69, p < .001  Effect Sizes  APAStyler(modelTest(m1), format = list(   FixedEffects = \"%s, %s\\n(%s, %s)\",   EffectSizes = \"Cohen's f2 = %s (%s)\"), pcontrol = list(digits = 4,   stars = FALSE, includeP = TRUE,   includeSign = TRUE,   dropLeadingZero = TRUE)) #>                 Term                               Est          Type #>  1:      (Intercept)  8.52, p = .5020\\n(-17.15, 34.20) Fixed Effects #>  2:             qsec  1.48, p = .0386\\n(  0.08,  2.87) Fixed Effects #>  3:               hp  0.24, p = .0034\\n(  0.09,  0.39) Fixed Effects #>  4:          qsec:hp -0.02, p = .0001\\n( -0.03, -0.01) Fixed Effects #>  5: N (Observations)                                32 Overall Model #>  6:        logLik DF                                 5 Overall Model #>  7:           logLik                            -77.75 Overall Model #>  8:              AIC                            165.50 Overall Model #>  9:              BIC                            172.83 Overall Model #> 10:               F2                              3.66 Overall Model #> 11:               R2                              0.79 Overall Model #> 12:           Adj R2                              0.76 Overall Model #> 13:             qsec     Cohen's f2 = 0.17 (p = .0386)  Effect Sizes #> 14:               hp     Cohen's f2 = 0.37 (p = .0034)  Effect Sizes #> 15:          qsec:hp     Cohen's f2 = 0.69 (p = .0001)  Effect Sizes  ## clean up rm(m1)"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.vglm.html","id":null,"dir":"Reference","previous_headings":"","what":"APAStyler method for model tests from a vglm multinomial model — APAStyler.modelTest.vglm","title":"APAStyler method for model tests from a vglm multinomial model — APAStyler.modelTest.vglm","text":"APAStyler method model tests vglm multinomial model","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.vglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"APAStyler method for model tests from a vglm multinomial model — APAStyler.modelTest.vglm","text":"","code":"# S3 method for modelTest.vglm APAStyler(   object,   format = list(FixedEffects = c(\"%s%s [%s, %s]\"), EffectSizes =     c(\"Chi-square (df=%s) = %s, %s\")),   digits = 2,   pcontrol = list(digits = 3, stars = TRUE, includeP = FALSE, includeSign = FALSE,     dropLeadingZero = TRUE),   OR = TRUE,   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.vglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"APAStyler method for model tests from a vglm multinomial model — APAStyler.modelTest.vglm","text":"object modelTest.vglm class object, results running modelTest() function class vglm object multinomial family format list giving formatting style used fixed effects effect sizes. digits numeric value indicating number digits print. still early implementation stages currently change parts output (default 2 decimals per APA style). pcontrol list controlling p values formatted. logical value whether report odds ratios 95 percent confidence intervals, TRUE, regression coefficients logit scale standard errors, FALSE. ... Additional arguments.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.vglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"APAStyler method for model tests from a vglm multinomial model — APAStyler.modelTest.vglm","text":"Styled results.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/APAStyler.modelTest.vglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"APAStyler method for model tests from a vglm multinomial model — APAStyler.modelTest.vglm","text":"","code":"mtcars$cyl <- factor(mtcars$cyl) m <- VGAM::vglm(cyl ~ qsec,   family = VGAM::multinomial(), data = mtcars) mt <- modelTest(m)  APAStyler(mt) #>    Term Names           2 vs. 1             3 vs. 1           3 vs. 2 #> 1: qsec  qsec 0.56 [0.26, 1.23] 0.28** [0.11, 0.69] 0.50 [0.23, 1.11] #>                                   Test #> 1: Chi-square (df=2) = 14.21, p < .001  APAStyler(mt, OR = FALSE) #>    Term Names              2 vs. 1                3 vs. 1              3 vs. 2 #> 1: qsec  qsec -0.58 [-1.36,  0.21] -1.27** [-2.16, -0.38] -0.69 [-1.48,  0.10] #>                                   Test #> 1: Chi-square (df=2) = 14.21, p < .001  ## clean up rm(m, mt, mtcars)  if (FALSE) { mtcars$cyl <- factor(mtcars$cyl) mtcars$am <- factor(mtcars$am) m <- VGAM::vglm(cyl ~ qsec,   family = VGAM::multinomial(), data = mtcars) APAStyler(modelTest(m))  m <- VGAM::vglm(cyl ~ scale(qsec),   family = VGAM::multinomial(), data = mtcars) APAStyler(modelTest(m))  m2 <- VGAM::vglm(cyl ~ factor(vs) * scale(qsec),   family = VGAM::multinomial(), data = mtcars) APAStyler(modelTest(m2))  m <- VGAM::vglm(Species ~ Sepal.Length,   family = VGAM::multinomial(), data = iris) APAStyler(modelTest(m))  set.seed(1234) sampdata <- data.frame(   Outcome = factor(sample(letters[1:3], 20 * 9, TRUE)),   C1 = rnorm(20 * 9),   D3 = sample(paste0(\"L\", 1:3), 20 * 9, TRUE))  m <- VGAM::vglm(Outcome ~ factor(D3),   family = VGAM::multinomial(), data = sampdata) APAStyler(modelTest(m))  m <- VGAM::vglm(Outcome ~ factor(D3) + C1,   family = VGAM::multinomial(), data = sampdata) APAStyler(modelTest(m)) }"},{"path":"https://joshuawiley.com/JWileymisc/reference/CheckVals.html","id":null,"dir":"Reference","previous_headings":"","what":"Score a set of items to create overall scale score — CheckVals","title":"Score a set of items to create overall scale score — CheckVals","text":"function creates single scale score data frame, reversing needed.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/CheckVals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Score a set of items to create overall scale score — CheckVals","text":"","code":"CheckVals(data, okay, na.rm = TRUE)"},{"path":"https://joshuawiley.com/JWileymisc/reference/CheckVals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Score a set of items to create overall scale score — CheckVals","text":"data data check okay vector okay acceptable values na.rm Logical whether remove missing values . Defaults TRUE","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/CheckVals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Score a set of items to create overall scale score — CheckVals","text":"TRUE values okay, otherwise error","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/R2.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate R2 Values — R2","title":"Calculate R2 Values — R2","text":"Generic function return variance explained (R2) estimates various models. cases true R2 values, cases may pseudo-R2 values R2 strictly defined model.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/R2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate R2 Values — R2","text":"","code":"R2(object, ...)  # S3 method for lm R2(object, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/R2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate R2 Values — R2","text":"object fitted model object. ... Additional arguments passed specific methods.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/R2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate R2 Values — R2","text":"Depends method dispatch. raw adjusted r-squared value.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/R2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate R2 Values — R2","text":"","code":"R2(lm(mpg ~ qsec * hp, data = mtcars)) #>        R2     AdjR2  #> 0.7854734 0.7624884"},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Statistics for a SEM Analysis — SEMSummary.fit","title":"Summary Statistics for a SEM Analysis — SEMSummary.fit","text":"low level fitting function, SEMSummary.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Statistics for a SEM Analysis — SEMSummary.fit","text":"","code":"SEMSummary.fit(   formula,   data,   use = c(\"fiml\", \"pairwise.complete.obs\", \"complete.obs\") )"},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Statistics for a SEM Analysis — SEMSummary.fit","text":"formula formula variables used analysis. See ‘details’ section information. data data frame, matrix, list containing variables used formula.  required argument. use character vector handle missing data. Defaults “fiml”.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Statistics for a SEM Analysis — SEMSummary.fit","text":"list S3 class “SEMSummary” names character vector containing variable names. n integer vector length variable used     (includes available missing data). nmissing integer vector number missing values variable. mu vector arithmetic means variable (complete data). stdev numeric vector standard deviations variable (complete data). Sigma numeric covariance matrix variables. sSigma numeric correlation matrix variables. coverage numeric matrix giving percentage (technically decimal)     information available pairwise covariance/correlation. pvalue two-sided p values correlation matrix. Pairwise present N     used calculate degrees freedom.","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Statistics for a SEM Analysis — SEMSummary","title":"Summary Statistics for a SEM Analysis — SEMSummary","text":"function designed calculate descriptive statistics summaries often reported raw data main analyses use structural equation modelling.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Statistics for a SEM Analysis — SEMSummary","text":"","code":"SEMSummary(   formula,   data,   use = c(\"fiml\", \"pairwise.complete.obs\", \"complete.obs\") )"},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Statistics for a SEM Analysis — SEMSummary","text":"formula formula variables used analysis. See ‘details’ section information. data data frame, matrix, list containing variables used formula.  required argument. use character vector handle missing data. Defaults “fiml”.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Statistics for a SEM Analysis — SEMSummary","text":"list S3 class “SEMSummary” names character vector containing variable names. n integer vector length variable used     (includes available missing data). nmissing integer vector number missing values variable. mu vector arithmetic means variable (complete data). stdev numeric vector standard deviations variable (complete data). Sigma numeric covariance matrix variables. sSigma numeric correlation matrix variables. coverage numeric matrix giving percentage (technically decimal)     information available pairwise covariance/correlation. pvalue two-sided p values correlation matrix. Pairwise present N     used calculate degrees freedom.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Statistics for a SEM Analysis — SEMSummary","text":"function calculates variety relevant statistics raw data used SEM analysis.  meant SEM style data, now expects variables numeric.  future may try expand handle factor variables somehow. formula data arguments required.  formula right hand side .  common way use variable names separated ‘+s’.  convenience, ‘.’ expanded mean “variables data set”.  large number variables whole datasets analyzed, can considerably easier write.  Also facilitates column indexing simply passing subset data (e.g., data[, 1:10]) using ‘.’ expansion analyze first 10 columns.  examples section demonstrate use. Also noteworthy SEMSummary really meant used .  computational workhorse, meant used styling printing method produce simple output. APAStyler methods SEMSummary output. several new ways handle missing data now including listwise deletion, pairwise deletion, using EM algorithm, default.","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/SEMSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Statistics for a SEM Analysis — SEMSummary","text":"","code":"## Example using the built in iris dataset s <- SEMSummary(~ Sepal.Length + Sepal.Width + Petal.Length, data = iris) s # show output ... not very nice #> $names #> [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" #>  #> $n #> [1] 150 #>  #> $nmissing #> Sepal.Length  Sepal.Width Petal.Length  #>            0            0            0  #>  #> $mu #> Sepal.Length  Sepal.Width Petal.Length  #>     5.843333     3.057333     3.758000  #>  #> $stdev #> Sepal.Length  Sepal.Width Petal.Length  #>    0.8280661    0.4358663    1.7652982  #>  #> $Sigma #>              Sepal.Length Sepal.Width Petal.Length #> Sepal.Length    0.6856935  -0.0424340    1.2743154 #> Sepal.Width    -0.0424340   0.1899794   -0.3296564 #> Petal.Length    1.2743154  -0.3296564    3.1162779 #>  #> $sSigma #>              Sepal.Length Sepal.Width Petal.Length #> Sepal.Length    1.0000000  -0.1175698    0.8717538 #> Sepal.Width    -0.1175698   1.0000000   -0.4284401 #> Petal.Length    0.8717538  -0.4284401    1.0000000 #>  #> $coverage #>              Sepal.Length Sepal.Width Petal.Length #> Sepal.Length            1           1            1 #> Sepal.Width             1           1            1 #> Petal.Length            1           1            1 #>  #> $pvalue #>              Sepal.Length  Sepal.Width Petal.Length #> Sepal.Length           NA 1.518983e-01 0.000000e+00 #> Sepal.Width     0.1518983           NA 4.513314e-08 #> Petal.Length    0.0000000 4.513314e-08           NA #>  #> attr(,\"class\") #> [1] \"SEMSummary\"  ## Prettier output from SEMSummary APAStyler(s) #>                 N   M    SD   1.  2.    3.    #> 1. Sepal.Length 150 5.84 0.83  -  -0.04  1.27 #> 2. Sepal.Width  150 3.06 0.44      -    -0.33 #> 3. Petal.Length 150 3.76 1.77            -    #>  #> Percentage of coverage for each pairwise covariance or correlation #>  #>              Sepal.Length Sepal.Width Petal.Length #> Sepal.Length 1            1           1            #> Sepal.Width               1           1            #> Petal.Length                          1             #### Subset the dataset and use the . expansion ####  ## summary for all variables in mtcars data set ## with 11 variables, this could be a pain to write out SEMSummary(~ ., data = mtcars) #> $names #>  [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\" #> [11] \"carb\" #>  #> $n #> [1] 32 #>  #> $nmissing #>  mpg  cyl disp   hp drat   wt qsec   vs   am gear carb  #>    0    0    0    0    0    0    0    0    0    0    0  #>  #> $mu #>        mpg        cyl       disp         hp       drat         wt       qsec  #>  20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750  #>         vs         am       gear       carb  #>   0.437500   0.406250   3.687500   2.812500  #>  #> $stdev #>         mpg         cyl        disp          hp        drat          wt  #>   6.0269481   1.7859216 123.9386938  68.5628685   0.5346787   0.9784574  #>        qsec          vs          am        gear        carb  #>   1.7869432   0.5040161   0.4989909   0.7378041   1.6152000  #>  #> $Sigma #>              mpg         cyl        disp          hp         drat          wt #> mpg    36.324103  -9.1723790  -633.09721 -320.732056   2.19506351  -5.1166847 #> cyl    -9.172379   3.1895161   199.66028  101.931452  -0.66836694   1.3673710 #> disp -633.097208 199.6602823 15360.79983 6721.158669 -47.06401915 107.6842040 #> hp   -320.732056 101.9314516  6721.15867 4700.866935 -16.45110887  44.1926613 #> drat    2.195064  -0.6683669   -47.06402  -16.451109   0.28588135  -0.3727207 #> wt     -5.116685   1.3673710   107.68420   44.192661  -0.37272073   0.9573790 #> qsec    4.509149  -1.8868548   -96.05168  -86.770081   0.08714073  -0.3054816 #> vs      2.017137  -0.7298387   -44.37762  -24.987903   0.11864919  -0.2736613 #> am      1.803931  -0.4657258   -36.56401   -8.320565   0.19015121  -0.3381048 #> gear    2.135685  -0.6491935   -50.80262   -6.358871   0.27598790  -0.4210806 #> carb   -5.363105   1.5201613    79.06875   83.036290  -0.07840726   0.6757903 #>              qsec           vs           am        gear        carb #> mpg    4.50914919   2.01713710   1.80393145   2.1356855 -5.36310484 #> cyl   -1.88685484  -0.72983871  -0.46572581  -0.6491935  1.52016129 #> disp -96.05168145 -44.37762097 -36.56401210 -50.8026210 79.06875000 #> hp   -86.77008065 -24.98790323  -8.32056452  -6.3588710 83.03629032 #> drat   0.08714073   0.11864919   0.19015121   0.2759879 -0.07840726 #> wt    -0.30548161  -0.27366129  -0.33810484  -0.4210806  0.67579032 #> qsec   3.19316613   0.67056452  -0.20495968  -0.2804032 -1.89411290 #> vs     0.67056452   0.25403226   0.04233871   0.0766129 -0.46370968 #> am    -0.20495968   0.04233871   0.24899194   0.2923387  0.04637097 #> gear  -0.28040323   0.07661290   0.29233871   0.5443548  0.32661290 #> carb  -1.89411290  -0.46370968   0.04637097   0.3266129  2.60887097 #>  #> $sSigma #>             mpg        cyl       disp         hp        drat         wt #> mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684  0.68117191 -0.8676594 #> cyl  -0.8521620  1.0000000  0.9020329  0.8324475 -0.69993811  0.7824958 #> disp -0.8475514  0.9020329  1.0000000  0.7909486 -0.71021393  0.8879799 #> hp   -0.7761684  0.8324475  0.7909486  1.0000000 -0.44875912  0.6587479 #> drat  0.6811719 -0.6999381 -0.7102139 -0.4487591  1.00000000 -0.7124406 #> wt   -0.8676594  0.7824958  0.8879799  0.6587479 -0.71244065  1.0000000 #> qsec  0.4186840 -0.5912421 -0.4336979 -0.7082234  0.09120476 -0.1747159 #> vs    0.6640389 -0.8108118 -0.7104159 -0.7230967  0.44027846 -0.5549157 #> am    0.5998324 -0.5226070 -0.5912270 -0.2432043  0.71271113 -0.6924953 #> gear  0.4802848 -0.4926866 -0.5555692 -0.1257043  0.69961013 -0.5832870 #> carb -0.5509251  0.5269883  0.3949769  0.7498125 -0.09078980  0.4276059 #>             qsec         vs          am       gear        carb #> mpg   0.41868403  0.6640389  0.59983243  0.4802848 -0.55092507 #> cyl  -0.59124207 -0.8108118 -0.52260705 -0.4926866  0.52698829 #> disp -0.43369788 -0.7104159 -0.59122704 -0.5555692  0.39497686 #> hp   -0.70822339 -0.7230967 -0.24320426 -0.1257043  0.74981247 #> drat  0.09120476  0.4402785  0.71271113  0.6996101 -0.09078980 #> wt   -0.17471588 -0.5549157 -0.69249526 -0.5832870  0.42760594 #> qsec  1.00000000  0.7445354 -0.22986086 -0.2126822 -0.65624923 #> vs    0.74453544  1.0000000  0.16834512  0.2060233 -0.56960714 #> am   -0.22986086  0.1683451  1.00000000  0.7940588  0.05753435 #> gear -0.21268223  0.2060233  0.79405876  1.0000000  0.27407284 #> carb -0.65624923 -0.5696071  0.05753435  0.2740728  1.00000000 #>  #> $coverage #>      mpg cyl disp hp drat wt qsec vs am gear carb #> mpg    1   1    1  1    1  1    1  1  1    1    1 #> cyl    1   1    1  1    1  1    1  1  1    1    1 #> disp   1   1    1  1    1  1    1  1  1    1    1 #> hp     1   1    1  1    1  1    1  1  1    1    1 #> drat   1   1    1  1    1  1    1  1  1    1    1 #> wt     1   1    1  1    1  1    1  1  1    1    1 #> qsec   1   1    1  1    1  1    1  1  1    1    1 #> vs     1   1    1  1    1  1    1  1  1    1    1 #> am     1   1    1  1    1  1    1  1  1    1    1 #> gear   1   1    1  1    1  1    1  1  1    1    1 #> carb   1   1    1  1    1  1    1  1  1    1    1 #>  #> $pvalue #>               mpg          cyl         disp           hp         drat #> mpg            NA 6.112687e-10 9.380327e-10 1.787835e-07 1.776240e-05 #> cyl  6.112687e-10           NA 1.803002e-12 3.477861e-09 8.244636e-06 #> disp 9.380327e-10 1.803002e-12           NA 7.142679e-08 5.282022e-06 #> hp   1.787835e-07 3.477861e-09 7.142679e-08           NA 9.988772e-03 #> drat 1.776240e-05 8.244636e-06 5.282022e-06 9.988772e-03           NA #> wt   1.293959e-10 1.217567e-07 1.222311e-11 4.145827e-05 4.784260e-06 #> qsec 1.708199e-02 3.660533e-04 1.314404e-02 5.766253e-06 6.195826e-01 #> vs   3.415937e-05 1.843018e-08 5.235012e-06 2.940896e-06 1.167553e-02 #> am   2.850207e-04 2.151207e-03 3.662114e-04 1.798309e-01 4.726790e-06 #> gear 5.400948e-03 4.173297e-03 9.635921e-04 4.930119e-01 8.360110e-06 #> carb 1.084446e-03 1.942340e-03 2.526789e-02 7.827810e-07 6.211834e-01 #>                wt         qsec           vs           am         gear #> mpg  1.293959e-10 1.708199e-02 3.415937e-05 2.850207e-04 5.400948e-03 #> cyl  1.217567e-07 3.660533e-04 1.843018e-08 2.151207e-03 4.173297e-03 #> disp 1.222311e-11 1.314404e-02 5.235012e-06 3.662114e-04 9.635921e-04 #> hp   4.145827e-05 5.766253e-06 2.940896e-06 1.798309e-01 4.930119e-01 #> drat 4.784260e-06 6.195826e-01 1.167553e-02 4.726790e-06 8.360110e-06 #> wt             NA 3.388683e-01 9.798492e-04 1.125440e-05 4.586601e-04 #> qsec 3.388683e-01           NA 1.029669e-06 2.056621e-01 2.425344e-01 #> vs   9.798492e-04 1.029669e-06           NA 3.570439e-01 2.579439e-01 #> am   1.125440e-05 2.056621e-01 3.570439e-01           NA 5.834043e-08 #> gear 4.586601e-04 2.425344e-01 2.579439e-01 5.834043e-08           NA #> carb 1.463861e-02 4.536949e-05 6.670496e-04 7.544526e-01 1.290291e-01 #>              carb #> mpg  1.084446e-03 #> cyl  1.942340e-03 #> disp 2.526789e-02 #> hp   7.827810e-07 #> drat 6.211834e-01 #> wt   1.463861e-02 #> qsec 4.536949e-05 #> vs   6.670496e-04 #> am   7.544526e-01 #> gear 1.290291e-01 #> carb           NA #>  #> attr(,\"class\") #> [1] \"SEMSummary\"  ## . expansion is also useful when we know column positions ## but not necessarily names SEMSummary(~ ., data = mtcars[, c(1, 2, 3, 9, 10, 11)]) #> $names #> [1] \"mpg\"  \"cyl\"  \"disp\" \"am\"   \"gear\" \"carb\" #>  #> $n #> [1] 32 #>  #> $nmissing #>  mpg  cyl disp   am gear carb  #>    0    0    0    0    0    0  #>  #> $mu #>       mpg       cyl      disp        am      gear      carb  #>  20.09062   6.18750 230.72188   0.40625   3.68750   2.81250  #>  #> $stdev #>         mpg         cyl        disp          am        gear        carb  #>   6.0269481   1.7859216 123.9386938   0.4989909   0.7378041   1.6152000  #>  #> $Sigma #>              mpg         cyl        disp           am        gear        carb #> mpg    36.324103  -9.1723790  -633.09721   1.80393145   2.1356855 -5.36310484 #> cyl    -9.172379   3.1895161   199.66028  -0.46572581  -0.6491935  1.52016129 #> disp -633.097208 199.6602823 15360.79983 -36.56401210 -50.8026210 79.06875000 #> am      1.803931  -0.4657258   -36.56401   0.24899194   0.2923387  0.04637097 #> gear    2.135685  -0.6491935   -50.80262   0.29233871   0.5443548  0.32661290 #> carb   -5.363105   1.5201613    79.06875   0.04637097   0.3266129  2.60887097 #>  #> $sSigma #>             mpg        cyl       disp          am       gear        carb #> mpg   1.0000000 -0.8521620 -0.8475514  0.59983243  0.4802848 -0.55092507 #> cyl  -0.8521620  1.0000000  0.9020329 -0.52260705 -0.4926866  0.52698829 #> disp -0.8475514  0.9020329  1.0000000 -0.59122704 -0.5555692  0.39497686 #> am    0.5998324 -0.5226070 -0.5912270  1.00000000  0.7940588  0.05753435 #> gear  0.4802848 -0.4926866 -0.5555692  0.79405876  1.0000000  0.27407284 #> carb -0.5509251  0.5269883  0.3949769  0.05753435  0.2740728  1.00000000 #>  #> $coverage #>      mpg cyl disp am gear carb #> mpg    1   1    1  1    1    1 #> cyl    1   1    1  1    1    1 #> disp   1   1    1  1    1    1 #> am     1   1    1  1    1    1 #> gear   1   1    1  1    1    1 #> carb   1   1    1  1    1    1 #>  #> $pvalue #>               mpg          cyl         disp           am         gear #> mpg            NA 6.112687e-10 9.380327e-10 2.850207e-04 5.400948e-03 #> cyl  6.112687e-10           NA 1.803002e-12 2.151207e-03 4.173297e-03 #> disp 9.380327e-10 1.803002e-12           NA 3.662114e-04 9.635921e-04 #> am   2.850207e-04 2.151207e-03 3.662114e-04           NA 5.834043e-08 #> gear 5.400948e-03 4.173297e-03 9.635921e-04 5.834043e-08           NA #> carb 1.084446e-03 1.942340e-03 2.526789e-02 7.544526e-01 1.290291e-01 #>             carb #> mpg  0.001084446 #> cyl  0.001942340 #> disp 0.025267886 #> am   0.754452554 #> gear 0.129029084 #> carb          NA #>  #> attr(,\"class\") #> [1] \"SEMSummary\"  ## clean up rm(s)  ## sample data Xmiss <- as.matrix(iris[, -5]) # make q0% missing completely at random set.seed(10) Xmiss[sample(length(Xmiss), length(Xmiss) * .10)] <- NA Xmiss <- as.data.frame(Xmiss)  SEMSummary(~ ., data = Xmiss, use = \"fiml\") #> $names #> [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  #>  #> $n #> [1] 150 #>  #> $nmissing #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>           15            8           21           16  #>  #> $mu #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>     5.859048     3.063777     3.744655     1.199088  #>  #> $stdev #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>    0.8315335    0.4326462    1.7393932    0.7630092  #>  #> $Sigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.69144798 -0.04277193     1.255775   0.5177624 #> Sepal.Width   -0.04277193  0.18718270    -0.325356  -0.1222384 #> Petal.Length   1.25577465 -0.32535602     3.025489   1.2796561 #> Petal.Width    0.51776245 -0.12223835     1.279656   0.5821831 #>  #> $sSigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    1.0000000  -0.1188902    0.8682288   0.8160580 #> Sepal.Width    -0.1188902   1.0000000   -0.4323428  -0.3702924 #> Petal.Length    0.8682288  -0.4323428    1.0000000   0.9641969 #> Petal.Width     0.8160580  -0.3702924    0.9641969   1.0000000 #>  #> $coverage #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.9000000   0.8466667    0.7733333   0.8000000 #> Sepal.Width     0.8466667   0.9466667    0.8266667   0.8400000 #> Petal.Length    0.7733333   0.8266667    0.8600000   0.7600000 #> Petal.Width     0.8000000   0.8400000    0.7600000   0.8933333 #>  #> $pvalue #>              Sepal.Length  Sepal.Width Petal.Length  Petal.Width #> Sepal.Length           NA 1.830888e-01 0.000000e+00 0.000000e+00 #> Sepal.Width     0.1830888           NA 5.321816e-07 1.973922e-05 #> Petal.Length    0.0000000 5.321816e-07           NA 0.000000e+00 #> Petal.Width     0.0000000 1.973922e-05 0.000000e+00           NA #>  #> attr(,\"class\") #> [1] \"SEMSummary\"   ## pairwise APAStyler(SEMSummary(~ ., data = Xmiss, use = \"pair\"),   type = \"cor\") #>                 N   M    SD   1.  2.    3.    4.    #> 1. Sepal.Length 135 5.89 0.81  -  -0.18  0.86  0.81 #> 2. Sepal.Width  142 3.07 0.44      -    -0.43 -0.43 #> 3. Petal.Length 129 3.82 1.74            -     0.97 #> 4. Petal.Width  134 1.19 0.77                  -    #>  #> Percentage of coverage for each pairwise covariance or correlation #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length 0.9          0.85        0.77         0.8         #> Sepal.Width               0.95        0.83         0.84        #> Petal.Length                          0.86         0.76        #> Petal.Width                                        0.89         ## same as cor() cor(Xmiss, use = \"pairwise.complete.obs\") #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    1.0000000  -0.1832230    0.8646983   0.8119316 #> Sepal.Width    -0.1832230   1.0000000   -0.4291999  -0.4293565 #> Petal.Length    0.8646983  -0.4291999    1.0000000   0.9650212 #> Petal.Width     0.8119316  -0.4293565    0.9650212   1.0000000  ## complete cases only SEMSummary(~ ., data = Xmiss, use = \"comp\") #> $names #> [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  #>  #> $n #> [1] 150 #>  #> $nmissing #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>           15            8           21           16  #>  #> $mu #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>     5.853608     3.037113     3.802062     1.229897  #>  #> $stdev #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>    0.7987049    0.4194042    1.7165845    0.7479367  #>  #> $Sigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.63792955 -0.05919781    1.1747841   0.4824431 #> Sepal.Width   -0.05919781  0.17589991   -0.3682023  -0.1415378 #> Petal.Length   1.17478415 -0.36820232    2.9466624   1.2399377 #> Petal.Width    0.48244308 -0.14153780    1.2399377   0.5594094 #>  #> $sSigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    1.0000000  -0.1767203    0.8568534   0.8075973 #> Sepal.Width    -0.1767203   1.0000000   -0.5114327  -0.4512059 #> Petal.Length    0.8568534  -0.5114327    1.0000000   0.9657613 #> Petal.Width     0.8075973  -0.4512059    0.9657613   1.0000000 #>  #> $coverage #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.9000000   0.8466667    0.7733333   0.8000000 #> Sepal.Width     0.8466667   0.9466667    0.8266667   0.8400000 #> Petal.Length    0.7733333   0.8266667    0.8600000   0.7600000 #> Petal.Width     0.8000000   0.8400000    0.7600000   0.8933333 #>  #> $pvalue #>              Sepal.Length  Sepal.Width Petal.Length  Petal.Width #> Sepal.Length           NA 4.686510e-02 0.000000e+00 0.000000e+00 #> Sepal.Width     0.0468651           NA 1.278788e-09 1.142829e-07 #> Petal.Length    0.0000000 1.278788e-09           NA 0.000000e+00 #> Petal.Width     0.0000000 1.142829e-07 0.000000e+00           NA #>  #> attr(,\"class\") #> [1] \"SEMSummary\"  ## clean up rm(Xmiss)"},{"path":"https://joshuawiley.com/JWileymisc/reference/TukeyHSDgg.html","id":null,"dir":"Reference","previous_headings":"","what":"Tukey HSD Plot — TukeyHSDgg","title":"Tukey HSD Plot — TukeyHSDgg","text":"calculates displays means, confidence intervals well groups different based Tukey's HSD. Inspired http://stackoverflow.com/questions/18771516/---function--add-aov-post-hoc-testing-results--ggplot2-boxplot","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/TukeyHSDgg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tukey HSD Plot — TukeyHSDgg","text":"","code":"TukeyHSDgg(x, y, d, ci = 0.95, idvar, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/TukeyHSDgg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tukey HSD Plot — TukeyHSDgg","text":"x categorical grouping variable name. y continuous outcome variable name. d dataset ci numeric value indicating coverage confidence interval use.  Defaults 0.95. idvar optional ID variable multilevel data ... Additional arguments passed .","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/TukeyHSDgg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tukey HSD Plot — TukeyHSDgg","text":"ggplot graph object.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/TukeyHSDgg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tukey HSD Plot — TukeyHSDgg","text":"","code":"## examples using it with single level data ## differences based on an ANOVA and follow up contrasts mtcars$cyl <- factor(mtcars$cyl) TukeyHSDgg(\"cyl\", \"mpg\", mtcars) #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to max; returning -Inf  rm(mtcars)  if (FALSE) { TukeyHSDgg(\"Species\", \"Sepal.Length\", iris)  ## example based on multilevel data ## differences based on model fit with lmer and follow up contrasts TukeyHSDgg(\"treatment\", \"decrease\", OrchardSprays, idvar = \"colpos\") }"},{"path":"https://joshuawiley.com/JWileymisc/reference/VAConverter.html","id":null,"dir":"Reference","previous_headings":"","what":"Visual Acuity Converter — VAConverter","title":"Visual Acuity Converter — VAConverter","text":"Converter character (string) input Snellen fractions, Counting Fingers (CF), Hand Motion (HM) logMAR values use statistical models.  Can handle linear interpolation passed appropriate chart measures fit default chart.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VAConverter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visual Acuity Converter — VAConverter","text":"","code":"VAConverter(   OS,   OD,   chart.values = NULL,   chart.nletters = NULL,   datatype = c(\"snellen\", \"decimal\", \"logMAR\"),   zero = 3 )"},{"path":"https://joshuawiley.com/JWileymisc/reference/VAConverter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visual Acuity Converter — VAConverter","text":"OS values converted left eye (oculus sinister). OD values converted right eye (oculus dexter) chart.values Snellen fractions chart used (interpolation necessary different default). chart.nletters number letters line chart used.  Necessary proper interpolation. datatype type data passed OS OD.  One \"Snellen\" (default), \"decimal\", \"logMAR\".  Determines transformations needed convert logMAR values. zero “zero” logMAR value.  used zero point visual acuity.  example, light perception (LP), light perception (NLP), etc.  defaults 3 (equivalent Snellen value 20/20000), may also NA.  See details.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VAConverter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visual Acuity Converter — VAConverter","text":"object class VAObject.    includes left right eye logMAR values slots  @logMAROS @logMAROD well additional   information.  information can found class   documentation.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VAConverter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Visual Acuity Converter — VAConverter","text":"VAConverter primarily designed take raw character   data various forms convert logMAR values.   Acceptable examples include: \"20/20\", \"20/80 + 3\", \"20/20 - 4\",   \"10/20\", \"CF 10\", \"HM 2\", \"CF 4\", \"NLP\", \"LP\", \"\", \"CF\", \"HM\",   etc.  Snellen values, parts present,   space components; e.g.,   fraction, +/- number CF 10.  Although   attempted make flexible general possible,   still fairly rigid requirements can parse   variety text formats numerical values.  Optionally, can   also handle decimal values (.e., results actually   dividing Snellen value 20/20 = 1). chart.values chart.nletters must length.  used interpolate values \"20/20 + 3\" interpreted reading letters \"20/20\" line \"3\" letters next best line (typically \"20/15\" can chart dependent).  functions goes 3/n distance logMAR values line.  important know values chart actually used. datatype = \"logMAR\", values passed OS OD directly assigned logMAROS logMAROD slots \"VAObject\" error returned results creation invalid object (e.g., numeric equal length). zero argument primarily included facilitate calculating averages.  example, cases may nice get sense individual's \"overall\" \"average\" logMAR value.  logMAR scale, 0 \"20/20\", alternate number needs used.  3 chosen rough default, means necessarily best choice.  interested computing average left right eyes within individuals, makes sense simply use NA rather crude \"zero\" approximation.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VAConverter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visual Acuity Converter — VAConverter","text":"","code":"## sampdat <- c(\"HM 12\", \"20/20 + 3\", \"20/50\", \"CF\", \"HM\", ##              \"20/70 - 2\", \"LP\", NA, \"Prosthetic\") ## tmp <- VAConverter(OS = sampdat, OD = rev(sampdat), datatype = \"snellen\")"},{"path":"https://joshuawiley.com/JWileymisc/reference/VAObject-class.html","id":null,"dir":"Reference","previous_headings":"","what":"An S4 class to hold visual acuity data — VAObject-class","title":"An S4 class to hold visual acuity data — VAObject-class","text":"class hold Visual Acuity data oculus sinister (OS; left eye) oculus dexter (OD; right eye)","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VAObject-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An S4 class to hold visual acuity data — VAObject-class","text":"","code":"# S4 method for VAObject,ANY,ANY,ANY [(x, i, j, ..., drop = TRUE)  # S4 method for VAObject print(x, ...)  # S4 method for VAObject show(object)  # S4 method for VAObject summary(object, weightbest = TRUE, w = c(0.75, 0.25))"},{"path":"https://joshuawiley.com/JWileymisc/reference/VAObject-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"An S4 class to hold visual acuity data — VAObject-class","text":"x object subset rows subset (optional) j columns subset (optional) ... Additional arguments passed lower functions drop missing object VAObject class object weightbest Logical whether upweight best seeing eye. Defaults TRUE. w numeric vector weights, first best seeing worst seeing eye. Defaults c(.75, .25).","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VAObject-class.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"An S4 class to hold visual acuity data — VAObject-class","text":"x[: extract method print(VAObject): print method show(VAObject): show method summary(VAObject): summary method","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VAObject-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"An S4 class to hold visual acuity data — VAObject-class","text":"originalOS original visual acuity data left (ocular sinister) eye originalOD original visual acuity data right (ocular dexter) eye logMAROS Logarithm minimum angle resolution data OS logMAROD Logarithm minimum angle resolution data OD chart.values snellen values line chart used measure visual acuity.  Used linear interpolation case partially correct line readings. chart.nletters number letters line chart used measure visual acuity.  Used linear interpolation case partially correct line readings (+2 2/4 way next line four letters, 2/6 six, etc.) zero logMAR value chosen represent \"zero\" visual acuity creating combined logMAR values eyes taking arithmetic mean.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VASummaryObject-class.html","id":null,"dir":"Reference","previous_headings":"","what":"An S4 class to hold visual acuity summary data — VASummaryObject-class","title":"An S4 class to hold visual acuity summary data — VASummaryObject-class","text":"class designed hold visual acuity summary data","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VASummaryObject-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An S4 class to hold visual acuity summary data — VASummaryObject-class","text":"","code":"# S4 method for VASummaryObject show(object)  # S4 method for VASummaryObject,missing plot(x, y, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/VASummaryObject-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"An S4 class to hold visual acuity summary data — VASummaryObject-class","text":"object object shown x VASummaryObject y missing ... Additional, unused arguments","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VASummaryObject-class.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"An S4 class to hold visual acuity summary data — VASummaryObject-class","text":"show(VASummaryObject): show method plot(x = VASummaryObject, y = missing): plot method","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/VASummaryObject-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"An S4 class to hold visual acuity summary data — VASummaryObject-class","text":"logMAR.combined Numeric values combined logarithm minimum angle resolution data eyes snellen.combined snellen values back transformed combined logMAR values mean.logMAR average logarithm minimum angle resolution data mean.snellen average combined Snellen data","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/aces_daily.html","id":null,"dir":"Reference","previous_headings":"","what":"Multilevel Daily Data Example — aces_daily","title":"Multilevel Daily Data Example — aces_daily","text":"data frame drawn daily diary study, conducted Monash University 2017 young adults old completed measures three times per day (morning, afternoon, evening) 12 days.  Thus participant contributed 36 observations dataset. protect participant confidentiality anonymity, data used simulated original data, way preserve relations among variables features raw data.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/aces_daily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multilevel Daily Data Example — aces_daily","text":"","code":"aces_daily"},{"path":"https://joshuawiley.com/JWileymisc/reference/aces_daily.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Multilevel Daily Data Example — aces_daily","text":"data frame containing 19 variables. UserID unique identifier individual SurveyDay date observation occured SurveyInteger survey coded integer (1 = morning, 2 = afternoon, 3 = evening) SurveyStartTimec11 Survey start time, centered time since 11am Female 0 1 variable, 1 = female 0 = male Age Participant age years, top coded 25 BornAUS 0 1 variable 1 = born Australia 0 = born outside Australia SES_1 Participants subjective SES, bottom coded 4 top coded 8 EDU Participants level education (1 = university graduate higher, 0 = less university graduate SOLs Self-reported sleep onset latency minutes, morning survey WASONs Self-reported number wakenings sleep onset, top coded 4, morning survey STRESS Overall stress ratings 0--10 scale, repeated 3x daily SUPPORT Overall social support ratings 0--10 scale, repeated 3x daily PosAff Positive affect ratings 1--5 scale, repeated 3x daily NegAff Negative affect ratings 1--5 scale, repeated 3x daily COPEPrb Problem focused coping 1--4 scale, repeated 1x daily evening survey COPEPrc Emotional processing coping 1--4 scale, repeated 1x daily evening survey COPEExp Emotional exprsesion coping 1--4 scale, repeated 1x daily evening survey COPEDis Mental disengagement coping 1--4 scale, repeated 1x daily evening survey","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/as.na.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerces vectors to missing — as.na","title":"Coerces vectors to missing — as.na","text":"Given vector, convert missing (NA) values, class missing matches input class. Currently supports character, logical, integer, factor, numeric, times (chron), Date, POSIXct, POSIXlt, zoo (zoo).","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/as.na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerces vectors to missing — as.na","text":"","code":"as.na(x)"},{"path":"https://joshuawiley.com/JWileymisc/reference/as.na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerces vectors to missing — as.na","text":"x vector convert missing (NA)","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/as.na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerces vectors to missing — as.na","text":"vector length input missing values class","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/as.na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerces vectors to missing — as.na","text":"","code":"str(as.na(1L:5L)) #>  int [1:5] NA NA NA NA NA str(as.na(rnorm(5))) #>  num [1:5] NA NA NA NA NA str(as.na(c(TRUE, FALSE))) #>  logi [1:2] NA NA str(as.na(as.Date(\"2017-01-01\"))) #>  Date[1:1], format: NA"},{"path":"https://joshuawiley.com/JWileymisc/reference/cd.html","id":null,"dir":"Reference","previous_headings":"","what":"Change directory — cd","title":"Change directory — cd","text":"function takes path changes current working directory path. directory specified path currently exist, created.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/cd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change directory — cd","text":"","code":"cd(base, pre, num)"},{"path":"https://joshuawiley.com/JWileymisc/reference/cd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change directory — cd","text":"base character string base path directory. required. pre optional character string prefix add base path. Non character strings coerced character class. num optional character string, prefixed pre. Non character strings coerced character class.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/cd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change directory — cd","text":"NULL, changes current working directory","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/cd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Change directory — cd","text":"function designed platform independent, although limited testing. Path creation done using file.path, existence directory checked using file.exists directory created dir.create. first argument, required.  optional arguments handy one wants create many similar directories common base.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/cd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change directory — cd","text":"","code":"if (FALSE) { # an example just using the base cd(\"~/testdir\")  # an example using the optional arguments base <- \"~/testdir\" pre <- \"test_\"  cd(base, pre, 1) cd(base, pre, 2) }"},{"path":"https://joshuawiley.com/JWileymisc/reference/compareIVs.html","id":null,"dir":"Reference","previous_headings":"","what":"Compares the effects of various independent variables on dependent variables — compareIVs","title":"Compares the effects of various independent variables on dependent variables — compareIVs","text":"Utility estimate unadjusted, covariate adjusted, multivariate adjusted unique contributions one IVs one DVs","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/compareIVs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compares the effects of various independent variables on dependent variables — compareIVs","text":"","code":"compareIVs(   dv,   type,   iv,   covariates = character(),   data,   multivariate = FALSE,   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/compareIVs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compares the effects of various independent variables on dependent variables — compareIVs","text":"dv character string vector depentent variable(s) type character string vector indicating type dependent variable(s) iv character string vector giving IV(s) covariates character string vector giving covariate(s) data data used analysis multivariate logical value whether models IVs simultaneously. ... Additional arguments passed internal function, .runIt.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/compareIVs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compares the effects of various independent variables on dependent variables — compareIVs","text":"list model results.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/compareIVs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compares the effects of various independent variables on dependent variables — compareIVs","text":"","code":"test1 <- compareIVs(   dv = c(\"mpg\", \"disp\"),   type = c(\"normal\", \"normal\"),   iv = c(\"hp\", \"qsec\"),   covariates = \"am\",   data = mtcars, multivariate = TRUE) #> Multivariate uses complete cases for all IVs and covariates #> Warning: executing %dopar% sequentially: no parallel backend registered #> Multivariate uses complete cases for all IVs and covariates test1$OverallSummary #>      dv   iv        Type           R2           D #> 1   mpg   hp  Unadjusted  0.589185253 0.602437341 #> 2   mpg   hp    Adjusted  0.428543631 0.422235690 #> 3   mpg   hp MultiUnique  0.100202250 0.101303887 #> 4   mpg qsec  Unadjusted  0.147806198 0.175296320 #> 5   mpg qsec    Adjusted  0.326783610 0.327040832 #> 6   mpg qsec MultiUnique -0.001557770 0.006109029 #> 7  disp   hp  Unadjusted  0.613119655 0.625599666 #> 8  disp   hp    Adjusted  0.452667898 0.445145204 #> 9  disp   hp MultiUnique  0.108406045 0.108532739 #> 10 disp qsec  Unadjusted  0.161030314 0.188093852 #> 11 disp qsec    Adjusted  0.342986638 0.342540154 #> 12 disp qsec MultiUnique -0.001275215 0.005927689 rm(test1)"},{"path":"https://joshuawiley.com/JWileymisc/reference/compressedrds.html","id":null,"dir":"Reference","previous_headings":"","what":"Save and read RDS functions for using multithreaded “ZSTD” or “LZ4” compression — compressed RDS","title":"Save and read RDS functions for using multithreaded “ZSTD” or “LZ4” compression — compressed RDS","text":"Save read RDS functions using multithreaded “ZSTD” “LZ4” compression","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/compressedrds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save and read RDS functions for using multithreaded “ZSTD” or “LZ4” compression — compressed RDS","text":"","code":"saveRDSfst(object, filename = \"\", compression = 100, algorithm = \"ZSTD\")  readRDSfst(filename)"},{"path":"https://joshuawiley.com/JWileymisc/reference/compressedrds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save and read RDS functions for using multithreaded “ZSTD” or “LZ4” compression — compressed RDS","text":"object R object saved. filename character string giving filename object disk (save read ) compression numeric value 0 100 indicating amount compression. Defaults 100, highest level compression. 0 gives lowest compression. algorithm character string type compression use. Defaults “ZSTD” better compression slower. option “LZ4” faster may provide less compression.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/compressedrds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save and read RDS functions for using multithreaded “ZSTD” or “LZ4” compression — compressed RDS","text":"saveRDSfst() called side effect saving file disk.   original R object using readRDSfst().","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/compressedrds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Save and read RDS functions for using multithreaded “ZSTD” or “LZ4” compression — compressed RDS","text":"default, saveRDS() multithreaded compression built . functions use “ZSTD” “LZ4” compression via fst package multithreaded compression decompression good performance. save , objects serialized, compressed, saved using saveRDS(). read , objects read using readRDS(), decompressed, unserialized. Hashing used verify results. saveRDS() performed using version = 3, work older versions R.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/compressedrds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save and read RDS functions for using multithreaded “ZSTD” or “LZ4” compression — compressed RDS","text":"","code":"saveRDSfst(mtcars, filename = file.path(tempdir(), \"mtcars.RDS\"))  saveRDSfst(mtcars, filename = file.path(tempdir(), \"mtcars.RDS\")) readRDSfst(file.path(tempdir(), \"mtcars.RDS\")) #>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2"},{"path":"https://joshuawiley.com/JWileymisc/reference/cor2cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a correlation matrix and standard deviations to a covariance matrix — cor2cov","title":"Convert a correlation matrix and standard deviations to a covariance matrix — cor2cov","text":"simple function designed convert correlation matrix (standardized covariance matrix) back covariance matrix. opposite cov2cor.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/cor2cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a correlation matrix and standard deviations to a covariance matrix — cor2cov","text":"","code":"cor2cov(V, sigma)"},{"path":"https://joshuawiley.com/JWileymisc/reference/cor2cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a correlation matrix and standard deviations to a covariance matrix — cor2cov","text":"V n x n correlation matrix.  numeric, square, symmetric. sigma n length vector standard deviations. length vector must match number columns correlation matrix.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/cor2cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a correlation matrix and standard deviations to a covariance matrix — cor2cov","text":"n x n covariance matrix","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/cor2cov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a correlation matrix and standard deviations to a covariance matrix — cor2cov","text":"","code":"# using a built in dataset cor2cov(cor(longley), sapply(longley, sd)) #>              GNP.deflator       GNP Unemployed Armed.Forces Population #> GNP.deflator    116.45762 1063.6041   625.8666     349.0254   73.50300 #> GNP            1063.60412 9879.3537  5612.4370    3088.0428  685.24094 #> Unemployed      625.86663 5612.4370  8732.2343   -1153.7876  446.27415 #> Armed.Forces    349.02537 3088.0428 -1153.7876    4843.0410  176.40981 #> Population       73.50300  685.2409   446.2742     176.4098   48.38735 #> Year             50.92333  470.9779   297.3033     138.2433   32.91740 #> Employed         36.79666  343.3302   164.9103     111.7681   23.46197 #>                   Year  Employed #> GNP.deflator  50.92333  36.79666 #> GNP          470.97790 343.33021 #> Unemployed   297.30333 164.91027 #> Armed.Forces 138.24333 111.76811 #> Population    32.91740  23.46197 #> Year          22.66667  16.24093 #> Employed      16.24093  12.33392  # should match the above covariance matarix cov(longley) #>              GNP.deflator       GNP Unemployed Armed.Forces Population #> GNP.deflator    116.45763 1063.6041   625.8666     349.0254   73.50300 #> GNP            1063.60412 9879.3537  5612.4370    3088.0428  685.24094 #> Unemployed      625.86663 5612.4370  8732.2343   -1153.7876  446.27415 #> Armed.Forces    349.02537 3088.0428 -1153.7876    4843.0410  176.40981 #> Population       73.50300  685.2409   446.2742     176.4098   48.38735 #> Year             50.92333  470.9779   297.3033     138.2433   32.91740 #> Employed         36.79666  343.3302   164.9103     111.7681   23.46197 #>                   Year  Employed #> GNP.deflator  50.92333  36.79666 #> GNP          470.97790 343.33021 #> Unemployed   297.30333 164.91027 #> Armed.Forces 138.24333 111.76811 #> Population    32.91740  23.46197 #> Year          22.66667  16.24093 #> Employed      16.24093  12.33392 all.equal(cov(longley), cor2cov(cor(longley), sapply(longley, sd))) #> [1] TRUE"},{"path":"https://joshuawiley.com/JWileymisc/reference/corOK.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a non-missing correlation matrix — corOK","title":"Return a non-missing correlation matrix — corOK","text":"Given square, symmetric matrix (correlation matrix) function tries drop fewest possible number variables return (square, symmetric) matrix missing cells.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/corOK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a non-missing correlation matrix — corOK","text":"","code":"corOK(x, maxiter = 100)"},{"path":"https://joshuawiley.com/JWileymisc/reference/corOK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a non-missing correlation matrix — corOK","text":"x square, symmetric matrix object coercable (data frame). maxiter number indicating maximum number iterations, currently sanity check. See details.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/corOK.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a non-missing correlation matrix — corOK","text":"list two elements x complete non missing matrix. keep.indices vector columns rows     original matrix kept (.e., nonmissing).","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/corOK.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return a non-missing correlation matrix — corOK","text":"assumption x square symmetric comes assumed number missing cells given column identical corresponding row.  corOK finds column missing values, drops (corresponding row), continues like manner matrix missing values.  Although intended correlation matrix, used types matrices. Note corOK uses iterative method, can slow many columns/rows need removed. intended use (correlation matrices) probably many missing.  sanity check prevent tediously long computations, maximum number iterations can set.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/corOK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return a non-missing correlation matrix — corOK","text":"","code":"cormat <- cor(iris[, -5]) # set missing cormat[cbind(c(1,2), c(2,1))] <- NA  # print cormat #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    1.0000000          NA    0.8717538   0.8179411 #> Sepal.Width            NA   1.0000000   -0.4284401  -0.3661259 #> Petal.Length    0.8717538  -0.4284401    1.0000000   0.9628654 #> Petal.Width     0.8179411  -0.3661259    0.9628654   1.0000000  # return complete corOK(cormat) #> $x #>              Sepal.Width Petal.Length Petal.Width #> Sepal.Width    1.0000000   -0.4284401  -0.3661259 #> Petal.Length  -0.4284401    1.0000000   0.9628654 #> Petal.Width   -0.3661259    0.9628654   1.0000000 #>  #> $keep.indices #> [1] 2 3 4 #>   # using maximum iterations corOK(cormat, maxiter=0) #> Warning: Maximum iterations exceeded. #> Currently kept indices will be returned. #> Try increasing maxiter or check why so many correlations are missing. #> [1] 1 2 3 4  # clean up rm(cormat)"},{"path":"https://joshuawiley.com/JWileymisc/reference/corplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Heatmap of a Correlation Matrix — corplot","title":"Heatmap of a Correlation Matrix — corplot","text":"function creates heatmap correlation matrix using ggplot2.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/corplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Heatmap of a Correlation Matrix — corplot","text":"","code":"corplot(   x,   coverage,   pvalues,   type = c(\"both\", \"cor\", \"p\", \"coverage\"),   digits = 2,   order = c(\"cluster\", \"asis\"),   ...,   control.grobs = list() )"},{"path":"https://joshuawiley.com/JWileymisc/reference/corplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Heatmap of a Correlation Matrix — corplot","text":"x correlation matrix square symmetric matrix. coverage (optional) matrix dimensions x giving proportion data present.  Particularly useful correlation matrix pairwise present. pvalues (optional) matrix dimensions x giving p values correlation. show, use plot = \"p\". type character string indicating show top heatmap. Can ‘coverage’, case bubble points show coverage; ‘p’, case p values shown; ‘cor’, case correlations shown; ‘’, case correlations p-values shown. effect coverage (pvalue) matrix passed also. Defaults cor. digits number digits round printing correlations heatmap. Text suppressed coverage matrix passed points = TRUE. order character string indicating order resulting plot. Defaults ‘cluster’ uses hierarchical clustering sensibly order variables. option ‘asis’ case matrix plotted order passed. ... Additional arguments currently passed hclust corOK. control.grobs list additional quote()d options customize ggplot2 output.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/corplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Heatmap of a Correlation Matrix — corplot","text":"Primarily called side effect creating plot.   However, ggplot2 plot object returned,   can saved, replotted, edited, etc.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/corplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Heatmap of a Correlation Matrix — corplot","text":"actual plot created using ggplot2 geom_tile. addition creating plot, variables ordered based hierarchical clustering correlation matrix.  Specifically, 1 - x used distance matrix. coverage passed, also add bubble plot area proportional proportion data present given cell.  Defaults ggplot2 set, possible use named list quote()d ggplot calls override defaults. expected typical use.  Particularly main, points, text rely internal variable names; however, labels, gradient color, area scaling can adjusted safely.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/corplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Heatmap of a Correlation Matrix — corplot","text":"","code":"# example plotting the correlation matrix from the # mtcars dataset corplot(cor(mtcars))   dat <- as.matrix(iris[, 1:4])  # randomly set 25% of the data to missing set.seed(10) dat[sample(length(dat), length(dat) * .25)] <- NA cor(dat, use = \"pair\") #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    1.0000000  -0.1541181    0.8643051   0.8308327 #> Sepal.Width    -0.1541181   1.0000000   -0.4433845  -0.4247681 #> Petal.Length    0.8643051  -0.4433845    1.0000000   0.9648311 #> Petal.Width     0.8308327  -0.4247681    0.9648311   1.0000000 cor(dat, use = \"complete\") #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    1.0000000  -0.1307569    0.8570142   0.8191163 #> Sepal.Width    -0.1307569   1.0000000   -0.4938995  -0.4366410 #> Petal.Length    0.8570142  -0.4938995    1.0000000   0.9722523 #> Petal.Width     0.8191163  -0.4366410    0.9722523   1.0000000  # create a summary of the data (including coverage matrix) sdat <- SEMSummary(~ ., data = dat, use = \"pair\") str(sdat) #> List of 9 #>  $ names   : chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>  $ n       : int 150 #>  $ nmissing: Named num [1:4] 36 36 43 35 #>   ..- attr(*, \"names\")= chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>  $ mu      : Named num [1:4] 5.88 3.09 3.81 1.21 #>   ..- attr(*, \"names\")= chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>  $ stdev   : Named num [1:4] 0.833 0.442 1.753 0.754 #>   ..- attr(*, \"names\")= chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>  $ Sigma   : num [1:4, 1:4] 0.6941 -0.0584 1.2961 0.5134 -0.0584 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>   .. ..$ : chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>  $ sSigma  : num [1:4, 1:4] 1 -0.154 0.864 0.831 -0.154 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>   .. ..$ : chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>  $ coverage: num [1:4, 1:4] 0.76 0.567 0.54 0.567 0.567 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>   .. ..$ : chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>  $ pvalue  : num [1:4, 1:4] NA 0.159 0 0 0.159 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>   .. ..$ : chr [1:4] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" #>  - attr(*, \"class\")= chr \"SEMSummary\" # using the plot method for SEMSummary (which basically just calls corplot) ## getting correlations above diagonal and p values below diagonal#' plot(sdat)   ## get correlations only plot(sdat, type = \"cor\")   ## showing coverage plot(sdat, type = \"coverage\")   # use the control.grobs argument to adjust the coverage scaling # to go from 0 to 1 rather than the range of coverage corplot(x = sdat$sSigma, coverage = sdat$coverage,   type = \"coverage\",   control.grobs = list(area = quote(scale_size_area(limits = c(0, 1)))) )   # also works with plot() on a SEMSummary plot(x = sdat, type = \"coverage\",   control.grobs = list(area = quote(scale_size_area(limits = c(0, 1)))) )   rm(dat, sdat)"},{"path":"https://joshuawiley.com/JWileymisc/reference/cramerV.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Phi or Cramer's V effect size — cramerV","title":"Calculate Phi or Cramer's V effect size — cramerV","text":"Simple function calculate effect sizes frequency tables.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/cramerV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Phi or Cramer's V effect size — cramerV","text":"","code":"cramerV(x)"},{"path":"https://joshuawiley.com/JWileymisc/reference/cramerV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Phi or Cramer's V effect size — cramerV","text":"x frequency table, xtabs().","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/cramerV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Phi or Cramer's V effect size — cramerV","text":"numeric value Phi 2 x 2 tables Cramer's V   tables larger 2 x 2.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/cramerV.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Phi or Cramer's V effect size — cramerV","text":"","code":"cramerV(xtabs(~ am + vs, data = mtcars)) #>       Phi  #> 0.1683451  cramerV(xtabs(~ cyl + vs, data = mtcars)) #> Cramer's V  #>  0.8166228  cramerV(xtabs(~ cyl + am, data = mtcars)) #> Cramer's V  #>  0.5226355"},{"path":"https://joshuawiley.com/JWileymisc/reference/diffCircular.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Circular Difference — diffCircular","title":"Calculate the Circular Difference — diffCircular","text":"Calculate Circular Difference","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/diffCircular.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Circular Difference — diffCircular","text":"","code":"diffCircular(x, y, max)"},{"path":"https://joshuawiley.com/JWileymisc/reference/diffCircular.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Circular Difference — diffCircular","text":"x Numeric integer values y Numeric integer values max theoretical maximum (e.g., degrees, 360; hours, 24; etc.).","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/diffCircular.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Circular Difference — diffCircular","text":"value circular difference. always positive defined.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/diffCircular.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the Circular Difference — diffCircular","text":"","code":"diffCircular(330, 30, max = 360) #> [1] 60 diffCircular(22, 1, max = 24) #> [1] 3 diffCircular(c(22, 23, 21, 22), c(1, 1, 23, 14), max = 24) #> [1] 3 2 2 8"},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-allmissing.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine which if any variables are all missing in a dataset — .allmissing","title":"Determine which if any variables are all missing in a dataset — .allmissing","text":"Internal function.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-allmissing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine which if any variables are all missing in a dataset — .allmissing","text":"","code":".allmissing(data)"},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-allmissing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine which if any variables are all missing in a dataset — .allmissing","text":"data dataset check variable missing / non finite / zero character vectors","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-allmissing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine which if any variables are all missing in a dataset — .allmissing","text":"FALSE variable(s) missing, else informative string message.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-allmissing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine which if any variables are all missing in a dataset — .allmissing","text":"","code":"JWileymisc:::.allmissing(mtcars) #> [1] FALSE cat(JWileymisc:::.allmissing(data.frame(a = NA, b = 1)), fill = TRUE) #> the following variable(s) were all missing/not finite/empty strings: #> a"},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-fround.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to round and format a number — .fround","title":"Function to round and format a number — .fround","text":"Function round format number","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-fround.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to round and format a number — .fround","text":"","code":".fround(x, digits)"},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-fround.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to round and format a number — .fround","text":"x data round format digits number digits used","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-fround.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to round and format a number — .fround","text":"character vector","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-quantilePercentiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal Function to Calculate Quantiles — .quantilePercentiles","title":"Internal Function to Calculate Quantiles — .quantilePercentiles","text":"Function calculates smoothing spline quantiles linear quantiles fall back. intended general use. Expected predicted residual data. Exported support related packages.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-quantilePercentiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal Function to Calculate Quantiles — .quantilePercentiles","text":"","code":".quantilePercentiles(data, LL = 0.1, UL = 0.9, na.rm = TRUE, cut = 4L)"},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-quantilePercentiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal Function to Calculate Quantiles — .quantilePercentiles","text":"data dataset predicted residual values. Assumed sort (probably parametric) model. LL lower limit prediction. Defaults .1 give 10th percentile. UL upper limit prediction. Defaults .9 give 90th percentile. na.rm logical whether remove missing values. Defaults TRUE cut integer, many unique predicted values least use quantile regression treat predicted values discrete. Defaults 4.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/dot-quantilePercentiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal Function to Calculate Quantiles — .quantilePercentiles","text":"data.table scores predicted LL UL,   possibly missing quantile regression models   converge.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/egltable.html","id":null,"dir":"Reference","previous_headings":"","what":"Function makes nice tables — egltable","title":"Function makes nice tables — egltable","text":"Give dataset list variables, just data vars.  best results, convert categorical variables factors.  Provides table estimated descriptive statistics optionally group levels.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/egltable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function makes nice tables — egltable","text":"","code":"egltable(   vars,   g,   data,   idvar,   strict = TRUE,   parametric = TRUE,   paired = FALSE,   simChisq = FALSE,   sims = 1000000L )"},{"path":"https://joshuawiley.com/JWileymisc/reference/egltable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function makes nice tables — egltable","text":"vars Either index (numeric character) variables access data argument, data described . g variable used tou group/separate data prior calculating descriptive statistics. data optional argument dataset containing variables described. idvar character string indicating variable name ID variable.  currently used, eventually support egltable supporting repeated measures data. strict Logical, whether strictly follow type variable, assume categorical number unique values less equal 3. parametric Logical whether use parametric tests case multiple groups test differences.  applies continuous variables. TRUE, default, uses one-way ANOVA, F test. FALSE, uses Kruskal-Wallis test. paired Logical whether data paired . Defaults FALSE. TRUE, grouping variable, g, must two levels idvar must specified. used paired t-test used parametric, continuous data Wilcoxon test paired  non parametric, continuous data McNemar chi square test used categorical data. simChisq Logical whether estimate p-values chi-square test categorical data multiple groups, simulation. Defaults FALSE. Useful small cells provide accurate test extreme cases, similar Fisher Exact Test generalizing large dimension tables. sims Integer number simulations used estimate p-values chi-square tests categorical variables multiple groups. Defaults one million (1e6L).","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/egltable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function makes nice tables — egltable","text":"data frame table.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/egltable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function makes nice tables — egltable","text":"","code":"egltable(iris) #>                 M (SD)/N (%) #> 1: Sepal.Length  5.84 (0.83) #> 2:  Sepal.Width  3.06 (0.44) #> 3: Petal.Length  3.76 (1.77) #> 4:  Petal.Width  1.20 (0.76) #> 5:      Species              #> 6:       setosa   50 (33.3%) #> 7:   versicolor   50 (33.3%) #> 8:    virginica   50 (33.3%) egltable(colnames(iris)[1:4], \"Species\", data = iris) #>                 setosa M (SD) versicolor M (SD) virginica M (SD) #> 1: Sepal.Length   5.01 (0.35)       5.94 (0.52)      6.59 (0.64) #> 2:  Sepal.Width   3.43 (0.38)       2.77 (0.31)      2.97 (0.32) #> 3: Petal.Length   1.46 (0.17)       4.26 (0.47)      5.55 (0.55) #> 4:  Petal.Width   0.25 (0.11)       1.33 (0.20)      2.03 (0.27) #>                                                 Test #> 1:  F(2, 147) = 119.26, p < .001, Eta-squared = 0.62 #> 2:   F(2, 147) = 49.16, p < .001, Eta-squared = 0.40 #> 3: F(2, 147) = 1180.16, p < .001, Eta-squared = 0.94 #> 4:  F(2, 147) = 960.01, p < .001, Eta-squared = 0.93 egltable(iris, parametric = FALSE) #>                 Mdn (IQR)/N (%) #> 1: Sepal.Length     5.80 (1.30) #> 2:  Sepal.Width     3.00 (0.50) #> 3: Petal.Length     4.35 (3.50) #> 4:  Petal.Width     1.30 (1.50) #> 5:      Species                 #> 6:       setosa      50 (33.3%) #> 7:   versicolor      50 (33.3%) #> 8:    virginica      50 (33.3%) egltable(colnames(iris)[1:4], \"Species\", iris,   parametric = FALSE) #>                 setosa Mdn (IQR) versicolor Mdn (IQR) virginica Mdn (IQR) #> 1: Sepal.Length      5.00 (0.40)          5.90 (0.70)         6.50 (0.67) #> 2:  Sepal.Width      3.40 (0.48)          2.80 (0.48)         3.00 (0.38) #> 3: Petal.Length      1.50 (0.18)          4.35 (0.60)         5.55 (0.78) #> 4:  Petal.Width      0.20 (0.10)          1.30 (0.30)         2.00 (0.50) #>                                        Test #> 1:  KW chi-square = 96.94, df = 2, p < .001 #> 2:  KW chi-square = 63.57, df = 2, p < .001 #> 3: KW chi-square = 130.41, df = 2, p < .001 #> 4: KW chi-square = 131.19, df = 2, p < .001 egltable(colnames(iris)[1:4], \"Species\", iris,   parametric = c(TRUE, TRUE, FALSE, FALSE)) #>                            setosa See Rows versicolor See Rows #> 1:    Sepal.Length, M (SD)     5.01 (0.35)         5.94 (0.52) #> 2:     Sepal.Width, M (SD)     3.43 (0.38)         2.77 (0.31) #> 3: Petal.Length, Mdn (IQR)     1.50 (0.18)         4.35 (0.60) #> 4:  Petal.Width, Mdn (IQR)     0.20 (0.10)         1.30 (0.30) #>    virginica See Rows                                             Test #> 1:        6.59 (0.64) F(2, 147) = 119.26, p < .001, Eta-squared = 0.62 #> 2:        2.97 (0.32)  F(2, 147) = 49.16, p < .001, Eta-squared = 0.40 #> 3:        5.55 (0.78)         KW chi-square = 130.41, df = 2, p < .001 #> 4:        2.00 (0.50)         KW chi-square = 131.19, df = 2, p < .001 egltable(colnames(iris)[1:4], \"Species\", iris,   parametric = c(TRUE, TRUE, FALSE, FALSE), simChisq=TRUE) #>                            setosa See Rows versicolor See Rows #> 1:    Sepal.Length, M (SD)     5.01 (0.35)         5.94 (0.52) #> 2:     Sepal.Width, M (SD)     3.43 (0.38)         2.77 (0.31) #> 3: Petal.Length, Mdn (IQR)     1.50 (0.18)         4.35 (0.60) #> 4:  Petal.Width, Mdn (IQR)     0.20 (0.10)         1.30 (0.30) #>    virginica See Rows                                             Test #> 1:        6.59 (0.64) F(2, 147) = 119.26, p < .001, Eta-squared = 0.62 #> 2:        2.97 (0.32)  F(2, 147) = 49.16, p < .001, Eta-squared = 0.40 #> 3:        5.55 (0.78)         KW chi-square = 130.41, df = 2, p < .001 #> 4:        2.00 (0.50)         KW chi-square = 131.19, df = 2, p < .001  diris <- data.table::as.data.table(iris) egltable(\"Sepal.Length\", g = \"Species\", data = diris) #>                 setosa M (SD) versicolor M (SD) virginica M (SD) #> 1: Sepal.Length   5.01 (0.35)       5.94 (0.52)      6.59 (0.64) #>                                                Test #> 1: F(2, 147) = 119.26, p < .001, Eta-squared = 0.62  tmp <- mtcars tmp$cyl <- factor(tmp$cyl) tmp$am <- factor(tmp$am, levels = 0:1)  egltable(c(\"mpg\", \"hp\"), \"vs\", tmp) #>              0 M (SD)      1 M (SD)                                 Test #> 1: mpg   16.62 (3.86)  24.56 (5.38) t(df=30) = -4.86, p < .001, d = 1.73 #> 2:  hp 189.72 (60.28) 91.36 (24.42)  t(df=30) = 5.73, p < .001, d = 2.04 egltable(c(\"mpg\", \"hp\"), \"am\", tmp) #>              0 M (SD)       1 M (SD)                                 Test #> 1: mpg   17.15 (3.83)   24.39 (6.17) t(df=30) = -4.11, p < .001, d = 1.48 #> 2:  hp 160.26 (53.91) 126.85 (84.06)  t(df=30) = 1.37, p = .180, d = 0.49 egltable(c(\"am\", \"cyl\"), \"vs\", tmp) #> Warning: Chi-squared approximation may be incorrect #>           0 N (%)    1 N (%) #> 1:  am                       #> 2:   0 12 (66.7%)  7 (50.0%) #> 3:   1  6 (33.3%)  7 (50.0%) #> 4: cyl                       #> 5:   4   1 (5.6%) 10 (71.4%) #> 6:   6  3 (16.7%)  4 (28.6%) #> 7:   8 14 (77.8%)   0 (0.0%) #>                                                       Test #> 1:         Chi-square = 0.91, df = 1, p = .341, Phi = 0.17 #> 2:                                                         #> 3:                                                         #> 4: Chi-square = 21.34, df = 2, p < .001, Cramer's V = 0.82 #> 5:                                                         #> 6:                                                         #> 7:                                                          tests <- with(sleep,     wilcox.test(extra[group == 1],            extra[group == 2], paired = TRUE)) #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes str(tests) #> List of 7 #>  $ statistic  : Named num 0 #>   ..- attr(*, \"names\")= chr \"V\" #>  $ parameter  : NULL #>  $ p.value    : num 0.00909 #>  $ null.value : Named num 0 #>   ..- attr(*, \"names\")= chr \"location shift\" #>  $ alternative: chr \"two.sided\" #>  $ method     : chr \"Wilcoxon signed rank test with continuity correction\" #>  $ data.name  : chr \"extra[group == 1] and extra[group == 2]\" #>  - attr(*, \"class\")= chr \"htest\"  ## example with paired data egltable(c(\"extra\"), g = \"group\", data = sleep, idvar = \"ID\", paired = TRUE) #>             1 M (SD)    2 M (SD)                               Test #> 1: extra 0.75 (1.79) 2.33 (2.00) t(df=9) = 4.06, p = .003, d = 1.28  ## what happens when ignoring pairing (p-value off) # egltable(c(\"extra\"), g = \"group\", data = sleep, idvar = \"ID\")  ## paired categorical data example ## using data on chick weights to create categorical data tmp <- subset(ChickWeight, Time %in% c(0, 20)) tmp$WeightTertile <- cut(tmp$weight,   breaks = quantile(tmp$weight, c(0, 1/3, 2/3, 1), na.rm = TRUE),   include.lowest = TRUE)  egltable(c(\"weight\", \"WeightTertile\"), g = \"Time\",   data = tmp,   idvar = \"Chick\", paired = TRUE) #>                  0 M (SD)/N (%) 20 M (SD)/N (%) #> 1:        weight   41.06 (1.13)  209.72 (66.51) #> 2: WeightTertile                                #> 3:     [39,41.7]     32 (64.0%)        0 (0.0%) #> 4:    (41.7,169]     18 (36.0%)      14 (30.4%) #> 5:     (169,361]       0 (0.0%)      32 (69.6%) #>                                              Test #> 1:           t(df=45) = 17.10, p < .001, d = 2.52 #> 2: McNemar's Chi-square = 39.00, df = 3, p < .001 #> 3:                                                #> 4:                                                #> 5:                                                 rm(tmp)"},{"path":"https://joshuawiley.com/JWileymisc/reference/empirical_pvalue.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates an empirical p-value based on the data — empirical_pvalue","title":"Calculates an empirical p-value based on the data — empirical_pvalue","text":"function takes vector statistics calculates empirical p-value, , many fall side zero.  calculates two-tailed p-value.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/empirical_pvalue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates an empirical p-value based on the data — empirical_pvalue","text":"","code":"empirical_pvalue(x, na.rm = TRUE)"},{"path":"https://joshuawiley.com/JWileymisc/reference/empirical_pvalue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates an empirical p-value based on the data — empirical_pvalue","text":"x data vector operate na.rm Logical whether remove NA values. Defaults TRUE","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/empirical_pvalue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates an empirical p-value based on the data — empirical_pvalue","text":"named vector number values falling   zero, zero, empirical p-value.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/empirical_pvalue.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculates an empirical p-value based on the data — empirical_pvalue","text":"Joshua F. Wiley <josh@elkhartgroup.com>","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/empirical_pvalue.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates an empirical p-value based on the data — empirical_pvalue","text":"","code":"empirical_pvalue(rnorm(100)) #>    <= 0     > 0 p-value  #>    45.0    55.0     0.9"},{"path":"https://joshuawiley.com/JWileymisc/reference/f.r2.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate F and p-value from the R2 — f.r2","title":"Calculate F and p-value from the R2 — f.r2","text":"Calculate F p-value R2","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/f.r2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate F and p-value from the R2 — f.r2","text":"","code":"f.r2(r2, numdf, dendf)"},{"path":"https://joshuawiley.com/JWileymisc/reference/f.r2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate F and p-value from the R2 — f.r2","text":"r2 r squareds numdf numerator degrees freedom dendf denominator degrees freedom","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/f.r2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate F and p-value from the R2 — f.r2","text":"vector","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/f.r2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate F and p-value from the R2 — f.r2","text":"","code":"JWileymisc:::f.r2(.30, 1, 99) #>            F        NumDF        DenDF            p  #> 4.242857e+01 1.000000e+00 9.900000e+01 3.071123e-09"},{"path":"https://joshuawiley.com/JWileymisc/reference/findSigRegions.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to find significant regions from an interaction — findSigRegions","title":"Function to find significant regions from an interaction — findSigRegions","text":"function uses contrast function rms find threshold significance interactions.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/findSigRegions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to find significant regions from an interaction — findSigRegions","text":"","code":"findSigRegions(   object,   l1,   l2,   name.vary,   lower,   upper,   alpha = 0.05,   starts = 50 )"},{"path":"https://joshuawiley.com/JWileymisc/reference/findSigRegions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to find significant regions from an interaction — findSigRegions","text":"object fitted rms object l1 first set values fix contrast function l2 second set values fix contrast function name.vary name model parameter vary values find threshold.  Note included l1 l2 arguments. lower lower bound search values varying value upper upper bound search values varying value alpha significance threshold, defaults .05 starts Number starting values try lower upper bounds.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/findSigRegions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to find significant regions from an interaction — findSigRegions","text":"data table notes convergence significance   thresholds ().","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/findSigRegions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to find significant regions from an interaction — findSigRegions","text":"","code":"## make me"},{"path":"https://joshuawiley.com/JWileymisc/reference/formatHtest.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to format the reuslts of a hypothesis test as text — formatHtest","title":"Function to format the reuslts of a hypothesis test as text — formatHtest","text":"Function format reuslts hypothesis test text","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatHtest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to format the reuslts of a hypothesis test as text — formatHtest","text":"","code":"formatHtest(   x,   type = c(\"t\", \"F\", \"chisq\", \"kw\", \"mh\", \"r_pearson\", \"r_kendall\", \"r_spearman\"),   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/formatHtest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to format the reuslts of a hypothesis test as text — formatHtest","text":"x htest class object type type htest. Currently one : “t”, “F”, “chisq”, “kw”, “mh”, “r_pearson”, “r_kendall”, “r_spearman” t-tests, F-tests, chi-square tests, kruskal-wallis tests, Mantel-Haenszel tests, pearson correlations, kendall tau correlation, spearman rho correlation, respectively. ... Arguments passed p-value formatting","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatHtest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to format the reuslts of a hypothesis test as text — formatHtest","text":"character string results","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatHtest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to format the reuslts of a hypothesis test as text — formatHtest","text":"","code":"formatHtest(t.test(extra ~ group, data = sleep), type = \"t\") #> [1] \"t(df = 17.78) = -1.86, p = .079\" formatHtest(anova(aov(mpg ~ factor(cyl), data = mtcars)), type = \"F\") #> [1] \"F(2, 29) = 39.70, p < .001\" formatHtest(chisq.test(c(A = 20, B = 15, C = 25)), type = \"chisq\") #> [1] \"Chi-square(df = 2) = 2.5, p = .287\" formatHtest(kruskal.test(Ozone ~ Month, data = airquality), type = \"kw\") #> [1] \"Kruskal-Wallis chi-square(df = 4) = 29.27, p < .001\" formatHtest(mantelhaen.test(UCBAdmissions), type = \"mh\") #> [1] \"Mantel-Haenszel chi-square(df = 1) = 1.43, p = .232, common odds ratio = 0.90, CI = (0.77, 1.06).\" formatHtest(cor.test(~ mpg + hp, data = mtcars, method = \"pearson\"), type = \"r_pearson\") #> [1] \"r = -0.78, CI = (-0.89, -0.59), t(df = 30) = -6.74, p < .001\" formatHtest(cor.test(~ mpg + hp, data = mtcars, method = \"kendall\"), type = \"r_kendall\") #> Warning: Cannot compute exact p-value with ties #> [1] \"tau = -0.74, z = -5.87, p < .001\" formatHtest(cor.test(~ mpg + hp, data = mtcars, method = \"spearman\"), type = \"r_spearman\") #> Warning: Cannot compute exact p-value with ties #> [1] \"rho = -0.89, S = 10337.3, p < .001\""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatMedIQR.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to format the median and IQR of a variable — formatMedIQR","title":"Function to format the median and IQR of a variable — formatMedIQR","text":"Function format median IQR variable","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatMedIQR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to format the median and IQR of a variable — formatMedIQR","text":"","code":"formatMedIQR(x, d = 2, na.rm = TRUE)"},{"path":"https://joshuawiley.com/JWileymisc/reference/formatMedIQR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to format the median and IQR of a variable — formatMedIQR","text":"x data median IQR calculated d many digits display. Defaults 2. na.rm Logical whether remove missing values. Defaults TRUE.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatMedIQR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to format the median and IQR of a variable — formatMedIQR","text":"character string results","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatMedIQR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to format the median and IQR of a variable — formatMedIQR","text":"","code":"formatMedIQR(mtcars$mpg) #> [1] \"19.20, (15.43, 22.80)\""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatPval.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to simplify formatting p-values for easy viewing / publication — formatPval","title":"Function to simplify formatting p-values for easy viewing / publication — formatPval","text":"Function simplify formatting p-values easy viewing / publication","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatPval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to simplify formatting p-values for easy viewing / publication — formatPval","text":"","code":"formatPval(   x,   d = 3,   sd,   includeP = FALSE,   includeSign = FALSE,   dropLeadingZero = TRUE )"},{"path":"https://joshuawiley.com/JWileymisc/reference/formatPval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to simplify formatting p-values for easy viewing / publication — formatPval","text":"x p values convert d number digits sd number scientific digits. Defaults d missing. includeP logical value whether include character “p” . Defaults FALSE. includeSign logical value whether include character “=” “<”. Defaults FALSE includeP = TRUE must TRUE. dropLeadingZero logical value whether drop leading zeros p-values. Defaults TRUE.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatPval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to simplify formatting p-values for easy viewing / publication — formatPval","text":"character string stars","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/formatPval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to simplify formatting p-values for easy viewing / publication — formatPval","text":"","code":"formatPval(c(.00052456, .000000124, .01035, .030489, .534946)) #> [1] \"< .001\" \"< .001\" \".010\"   \".030\"   \".535\"   formatPval(c(.00052456, .000000124, .01035, .030489, .534946), 3, 3, FALSE, TRUE) #> [1] \"< .001\" \"< .001\" \"= .010\" \"= .030\" \"= .535\" formatPval(c(.00052456, .000000124, .01035, .030489, .534946), 3, 3, TRUE, TRUE) #> [1] \"p < .001\" \"p < .001\" \"p = .010\" \"p = .030\" \"p = .535\" formatPval(c(.00052456, .000000124, .01035, .030489, .534946), 5) #> [1] \".00052\"   \"< .00001\" \".01035\"   \".03049\"   \".53495\"   formatPval(c(1, .15346, .085463, .05673, .04837, .015353462,   .0089, .00164, .0006589, .0000000053326), 3, 5) #>  [1] \"1.000\"  \".153\"   \".085\"   \".057\"   \".048\"   \".015\"   \".009\"   \".002\"   #>  [9] \"< .001\" \"< .001\" formatPval(c(1, .15346, .085463, .05673, .04837, .015353462,   .0089, .00164, .0006589, .0000000053326), 3, 5, dropLeadingZero = FALSE) #>  [1] \"1.000\"  \"0.153\"  \"0.085\"  \"0.057\"  \"0.048\"  \"0.015\"  \"0.009\"  \"0.002\"  #>  [9] \"< .001\" \"< .001\""},{"path":"https://joshuawiley.com/JWileymisc/reference/gglikert.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a plot for likert scale — gglikert","title":"Creates a plot for likert scale — gglikert","text":"Creates plot likert scale","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/gglikert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a plot for likert scale — gglikert","text":"","code":"gglikert(   x,   y,   leftLab,   rightLab,   colour,   data,   xlim,   title,   shape = 18,   size = 7 )"},{"path":"https://joshuawiley.com/JWileymisc/reference/gglikert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a plot for likert scale — gglikert","text":"x Variable plot x axis (likert scale responses averages) y variable containing index different items, integers leftLab variable anchors low end Likert scale rightLab variable anchors high end Likert scale colour character string giving name variable colouring data, like grouping variable. Alternately colour points passed geom_point data data use plotting xlim vector giving lower upper limit x axis.  possible range Likert scale, actual range. title character vector giving title plot shape number indicating point shape, passed geom_point size number indicating size points, passed geom_point","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/gglikert.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a plot for likert scale — gglikert","text":"","code":"library(JWileymisc) library(ggplot2) library(ggpubr) testdat <- data.table::data.table(   Var = 1:4,   Mean = c(1.5, 3, 2.2, 4.6),   Low = c(\"Happy\", \"Peaceful\", \"Excited\", \"Content\"),   High = c(\"Sad\", \"Angry\", \"Hopeless\", \"Anxious\"))  gglikert(\"Mean\", \"Var\", \"Low\", \"High\", data = testdat, xlim = c(1, 5),   title = \"Example Plot of Average Affect Ratings\")   testdat <- rbind(   cbind(testdat, Group = \"Young\"),   cbind(testdat, Group = \"Old\")) testdat$Mean[5:8] <- c(1.7, 2.6, 2.0, 4.4)  gglikert(\"Mean\", \"Var\", \"Low\", \"High\", colour = \"Group\",   data = testdat, xlim = c(1, 5),   title = \"Example Plot of Average Affect Ratings\")   gglikert(\"Mean\", \"Var\", \"Low\", \"High\", colour = \"Group\",   data = testdat, xlim = c(1, 5),   title = \"Example Plot of Average Affect Ratings\") + ggplot2::scale_colour_manual(values = c(\"Young\" = \"grey50\", \"Old\" = \"black\"))   ## clean up rm(testdat)"},{"path":"https://joshuawiley.com/JWileymisc/reference/hashDataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a character vector or file hash of a dataset and each variable — hashDataset","title":"Create a character vector or file hash of a dataset and each variable — hashDataset","text":"Given data.frame data.table, create character vector MD5 hash overall dataset variable. goal create secure vector / text file can tracked using version control (e.g., GitHub) without requiring commiting sensitive datasets. tracking make possible evaluate whether two datasets , sending data datasets may change time know variable(s) changed, .","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/hashDataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a character vector or file hash of a dataset and each variable — hashDataset","text":"","code":"hashDataset(x, file)"},{"path":"https://joshuawiley.com/JWileymisc/reference/hashDataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a character vector or file hash of a dataset and each variable — hashDataset","text":"x data.frame data.table hashed. file optional character string. given, assumed path/name file write character string hash , convenience. non missing, character vector returned invisibly file written. missing (default), character vector returned directly.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/hashDataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a character vector or file hash of a dataset and each variable — hashDataset","text":"(possibly invisible) character vector. Also (optionally) text file   written version character string.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/hashDataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a character vector or file hash of a dataset and each variable — hashDataset","text":"","code":"hashDataset(mtcars) #>  [1] \"dataset: 'mtcars', MD5: a63c70e73b58d0823ab3bcbd3b543d6f\"                                      #>  [2] \"'mpg' (numeric), f8e0303e137d946eec8ee06e2f152f51, 95d3087aa4b1ccb7e1ef49ba4b6ed83b (sorted)\"  #>  [3] \"'cyl' (numeric), 1b8fcb72575f2a120d77279ecf8851f9, ebfb767c78836025f7917bc845443804 (sorted)\"  #>  [4] \"'disp' (numeric), 4743a496928535c54d157d145aa114e1, 46b67296541e9f9c4c4e2b70227f9673 (sorted)\" #>  [5] \"'hp' (numeric), c1d443aac7c7e1284e2d0a5a6cbe1a98, cd2e69df37f9f864e98780c5d588c95a (sorted)\"   #>  [6] \"'drat' (numeric), 87a99a22f86d30cea74565dbad577790, f8bbcfc7e573cf1c72600683ac354d7a (sorted)\" #>  [7] \"'wt' (numeric), 2515679118871778eb21a32575973085, 67b94c293a66443abcb0427684b5ae28 (sorted)\"   #>  [8] \"'qsec' (numeric), 8632d4fe83c9a91aa2c3f5069002c870, 6875ea7f4d4a3ec56ff6fc214b69f7ff (sorted)\" #>  [9] \"'vs' (numeric), 34b3720888fd730d1dbb5d01c5d57ae3, e5a86583130d2649356bc9dc6060787d (sorted)\"   #> [10] \"'am' (numeric), 9bc5bef75a08e8812da6f8542311aaba, 3ec14454a35c411d95eedb78c176c0b4 (sorted)\"   #> [11] \"'gear' (numeric), 1415993e090fa6fd2078f6d907deb29f, 1cd9d9b506d3170cfeb79a869b29211f (sorted)\" #> [12] \"'carb' (numeric), 5b570f391814e8569d81dd5e2a9f30e0, 2acb8f5f747919d7befb9bba53dd6a68 (sorted)\"  ## if a file is specified it will write the results to the text file ## nicely formatted, along these lines  cat(hashDataset(cars), sep = \"\\n\") #> dataset: 'cars', MD5: f98a59010652c8e1ee062ed4c43f648e #> 'speed' (numeric), 4eb3e01aee9abbc01e91d22b651be559, 4eb3e01aee9abbc01e91d22b651be559 (sorted) #> 'dist' (numeric), be6c7701fccdd59b5e47c48881a2acae, 5cf4867b5bc8dc320c7aea4513d0f557 (sorted)"},{"path":"https://joshuawiley.com/JWileymisc/reference/intSigRegGraph.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to find significant regions from an interaction — intSigRegGraph","title":"Function to find significant regions from an interaction — intSigRegGraph","text":"function uses contrast function rms find threshold significance interactions.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/intSigRegGraph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to find significant regions from an interaction — intSigRegGraph","text":"","code":"intSigRegGraph(   object,   predList,   contrastList,   xvar,   varyvar,   varyvar.levels,   xlab = xvar,   ylab = \"Predicted Values\",   ratio = 1,   xlim,   ylim,   xbreaks,   xlabels = xbreaks,   scale.x = c(m = 0, s = 1),   scale.y = c(m = 0, s = 1),   starts = 50 )"},{"path":"https://joshuawiley.com/JWileymisc/reference/intSigRegGraph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to find significant regions from an interaction — intSigRegGraph","text":"object fitted rms object predList TODO contrastList TODO xvar TODO varyvar TODO varyvar.levels TODO xlab optional ylab TODO ratio TODO xlim TODO ylim TODO xbreaks TODO xlabels optional scale.x optional scale.y optional starts Number starting values try lower upper bounds.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/intSigRegGraph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to find significant regions from an interaction — intSigRegGraph","text":"data table notes convergence significance   thresholds ().","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/intSigRegGraph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to find significant regions from an interaction — intSigRegGraph","text":"","code":"## make me"},{"path":"https://joshuawiley.com/JWileymisc/reference/internalcompareIV.html","id":null,"dir":"Reference","previous_headings":"","what":"Compares the effects of various independent variables — internalcompareIV","title":"Compares the effects of various independent variables — internalcompareIV","text":"internal function designed run many models compare unique predictive effect different IVs without covariates outcome.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/internalcompareIV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compares the effects of various independent variables — internalcompareIV","text":"","code":"internalcompareIV(   dv,   type = c(\"normal\", \"binary\", \"count\"),   iv,   covariates = character(),   data,   multivariate = FALSE,   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/internalcompareIV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compares the effects of various independent variables — internalcompareIV","text":"dv character string depentent variable type character string indicating type dependent variable iv character string vector giving IV(s) covariates character string vector giving covariate(s) data data used analysis multivariate logical value whether models IVs simultaneously. ... Additional arguments passed internal function, .runIt.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/internalcompareIV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compares the effects of various independent variables — internalcompareIV","text":"list model results.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/internalcompareIV.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compares the effects of various independent variables — internalcompareIV","text":"","code":"test1 <- JWileymisc:::internalcompareIV(   dv = \"mpg\", type = \"normal\",   iv = \"hp\",   covariates = \"am\",   data = mtcars, multivariate = FALSE) test1$Summary #> NULL rm(test1)"},{"path":"https://joshuawiley.com/JWileymisc/reference/internalformulaIt.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to create a formula — internalformulaIt","title":"Internal function to create a formula — internalformulaIt","text":"function intended called users. creates formula style character string argument. note actually create formula class object. want argument, use empty string.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/internalformulaIt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to create a formula — internalformulaIt","text":"","code":"internalformulaIt(dv, iv, covariates)"},{"path":"https://joshuawiley.com/JWileymisc/reference/internalformulaIt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to create a formula — internalformulaIt","text":"dv character string dependent variable. iv character string vector independent variables covariates character string vector dependent variables","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/internalformulaIt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to create a formula — internalformulaIt","text":"character string","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/internalformulaIt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Internal function to create a formula — internalformulaIt","text":"","code":"JWileymisc:::internalformulaIt(\"mpg\", \"hp\", \"am\") #> [1] \"mpg ~ hp + am\" JWileymisc:::internalformulaIt(\"mpg\", \"hp\", \"\") #> [1] \"mpg ~ hp\" JWileymisc:::internalformulaIt(\"mpg\", \"\", \"am\") #> [1] \"mpg ~ am\""},{"path":"https://joshuawiley.com/JWileymisc/reference/internalrunIt.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to run a model using gam() — internalrunIt","title":"Internal function to run a model using gam() — internalrunIt","text":"function intended called users.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/internalrunIt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to run a model using gam() — internalrunIt","text":"","code":"internalrunIt(formula, type, data, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/internalrunIt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to run a model using gam() — internalrunIt","text":"formula character string containing formula style object. type character string indicating type dependent variable. Currently “normal”, “binary”, “count”. data data frame used analysis. ... Additional arguments passed gam.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/internalrunIt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to run a model using gam() — internalrunIt","text":"summary gam model.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/is.naz.html","id":null,"dir":"Reference","previous_headings":"","what":"Is a variable missing, non finite or zero length character? — is.naz","title":"Is a variable missing, non finite or zero length character? — is.naz","text":"Given vector, return TRUE FALSE element either missing (NA/NaN), non finite (e.g. infinite) zero length character string (character vectors).","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/is.naz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is a variable missing, non finite or zero length character? — is.naz","text":"","code":"is.naz(x)"},{"path":"https://joshuawiley.com/JWileymisc/reference/is.naz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is a variable missing, non finite or zero length character? — is.naz","text":"x vector identify missing / non finite zero length strings ","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/is.naz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is a variable missing, non finite or zero length character? — is.naz","text":"logical vector","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/is.naz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Is a variable missing, non finite or zero length character? — is.naz","text":"","code":"is.naz(c(1, NA, NaN)) #> [1] FALSE  TRUE  TRUE is.naz(c(1, NA, NaN, Inf)) #> [1] FALSE  TRUE  TRUE  TRUE is.naz(c(\"test\", \"\", NA_character_)) #> [1] FALSE  TRUE  TRUE"},{"path":"https://joshuawiley.com/JWileymisc/reference/lagk.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a lagged variable — lagk","title":"Create a lagged variable — lagk","text":"Given variable, create k lagged version, optionally grouping factor, ID.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/lagk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a lagged variable — lagk","text":"","code":"lagk(x, k = 1, by)"},{"path":"https://joshuawiley.com/JWileymisc/reference/lagk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a lagged variable — lagk","text":"x variable lag k length lag variable lag . Must sorted.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/lagk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a lagged variable — lagk","text":"vector lagged values","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/lagk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a lagged variable — lagk","text":"","code":"lagk(1:4, 1) #> [1] NA  1  2  3"},{"path":"https://joshuawiley.com/JWileymisc/reference/lm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Modified lm() to use a specified design matrix — lm2","title":"Modified lm() to use a specified design matrix — lm2","text":"function minor modification lm() function allow use pre-specified design matrix. intended public use support modelTest.lm.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/lm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modified lm() to use a specified design matrix — lm2","text":"","code":"lm2(   formula,   data,   subset,   weights,   na.action,   model = TRUE,   x = FALSE,   y = FALSE,   qr = TRUE,   singular.ok = TRUE,   contrasts = NULL,   offset,   designMatrix,   yObserved,   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/lm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modified lm() to use a specified design matrix — lm2","text":"formula object class \"formula\" although minimally used data dataset subset subset weights weights na.action Defaults na.omit model defaults TRUE x defaults FALSE y defaults FALSE qr defaults TRUE singular.ok defaults TRUE contrasts defaults NULL offset missing default designMatrix model matrix / design matrix (numeric, pre coded applicable discrete variables) yObserved observed y values ... additional arguments","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/lm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modified lm() to use a specified design matrix — lm2","text":"lm class object","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/lm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Modified lm() to use a specified design matrix — lm2","text":"","code":"mtcars$cyl <- factor(mtcars$cyl) m <- lm(mpg ~ hp * cyl, data = mtcars)  x <- model.matrix(m) y <- mtcars$mpg m2 <- JWileymisc:::lm2(mpg ~ 1 + cyl + hp:cyl, data = mtcars,   designMatrix = x[, -2, drop = FALSE],   yObserved = y)  anova(m, m2) #> Analysis of Variance Table #>  #> Model 1: mpg ~ hp * cyl #> Model 2: mpg ~ 1 + cyl + hp:cyl #>   Res.Df    RSS Df Sum of Sq      F  Pr(>F)   #> 1     26 238.47                               #> 2     27 294.20 -1   -55.739 6.0773 0.02061 * #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  rm(m, m2, x, y)"},{"path":"https://joshuawiley.com/JWileymisc/reference/meanCircular.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a Circular Mean — meanCircular","title":"Calculate a Circular Mean — meanCircular","text":"Function calculate circular mean","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/meanCircular.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a Circular Mean — meanCircular","text":"","code":"meanCircular(x, max, na.rm = TRUE)"},{"path":"https://joshuawiley.com/JWileymisc/reference/meanCircular.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a Circular Mean — meanCircular","text":"x Numeric integer values max theoretical maximum (e.g., degrees, 360) na.rm logical value indicating whether remove missing values. Defaults TRUE.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/meanCircular.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a Circular Mean — meanCircular","text":"numeric value circular mean.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/meanCircular.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a Circular Mean — meanCircular","text":"","code":"meanCircular(c(22:23, 1:2), max = 24) #> [1] 0 meanCircular(c(12, 24), max = 24) #> [1] 18 meanCircular(c(6, 7, 23), max = 24) #> [1] 4.5 meanCircular(c(6, 7, 21), max = 24) #> [1] 4.693219 meanCircular(c(6, 21), max = 24) #> [1] 1.5 meanCircular(c(6, 23), max = 24) #> [1] 2.5 meanCircular(c(.91, .96, .05, .16), max = 1) #> [1] 0.01771571 meanCircular(c(6, 7, 8, 9), max = 24) #> [1] 7.5 meanCircular(1:3, max = 24) #> [1] 2 meanCircular(21:23, max = 24) #> [1] 22 meanCircular(c(16, 17, 18, 19), max = 24) #> [1] 17.5 meanCircular(c(355, 5, 15), max = 360) #> [1] 5"},{"path":"https://joshuawiley.com/JWileymisc/reference/modelCompare.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Two Models — modelCompare","title":"Compare Two Models — modelCompare","text":"Generic function.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelCompare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Two Models — modelCompare","text":"","code":"modelCompare(model1, model2, ...)  as.modelCompare(x)  is.modelCompare(x)  # S3 method for lm modelCompare(model1, model2, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/modelCompare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Two Models — modelCompare","text":"model1 fitted model object. model2 fitted model object compare model1 ... Additional arguments passed specific methods. x object (e.g., list modelCompare object) test attempt coercing modelCompare object.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelCompare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Two Models — modelCompare","text":"Depends method dispatch.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelCompare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare Two Models — modelCompare","text":"","code":"m1 <- lm(mpg ~ qsec * hp, data = mtcars)  m2 <- lm(mpg ~ am, data = mtcars)  modelCompare(m1, m2) #> $Comparison #>         Model N_Obs       AIC       BIC        LL LLDF     Sigma        R2 #> 1:    Reduced    32 196.48438 200.88159 -95.24219    3  4.902029 0.3597989 #> 2:       Full    32 165.49722 172.82590 -77.74861    5  2.937243 0.7854734 #> 3: Difference     0 -30.98716 -28.05569  17.49358    2 -1.964786 0.4256745 #>           F2     AdjR2        F FNumDF FDenDF            P #> 1: 0.5620093 0.3384589 16.86028      1     30 2.850207e-04 #> 2: 3.6614271 0.7624884 34.17332      3     28 1.694676e-09 #> 3: 1.9842506 0.4240295 27.77951      2     28 2.250640e-07 #>  #> attr(,\"class\") #> [1] \"modelCompare.lm\" \"modelCompare\"     ## cleanup rm(m1, m2)  if (FALSE) { m3 <- lm(mpg ~ 1, data = mtcars) m4 <- lm(mpg ~ 0, data = mtcars) modelCompare(m3, m4)  ## cleanup rm(m3, m4) }"},{"path":"https://joshuawiley.com/JWileymisc/reference/modelDiagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Diagnostics Functions — modelDiagnostics","title":"Model Diagnostics Functions — modelDiagnostics","text":"set functions calculate   model diagnostics models, including constructors,   generic function, test whether object   modelDiagnostics class, methods.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelDiagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Diagnostics Functions — modelDiagnostics","text":"","code":"modelDiagnostics(object, ...)  as.modelDiagnostics(x)  is.modelDiagnostics(x)  # S3 method for lm modelDiagnostics(   object,   ev.perc = 0.001,   robust = FALSE,   distr = \"normal\",   standardized = TRUE,   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/modelDiagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Diagnostics Functions — modelDiagnostics","text":"object fitted model object, methods model.frame, resid fitted. ... Additional arguments, passed residualDiagnostics. x object test list coerce modelDiagnostics object. ev.perc real number 0 1 indicating proportion theoretical distribution beyond values considered extreme values (possible outliers). Defaults .001. robust Whether use robust mean standard deviation estimates normal distribution distr character string given assumed distribution. Passed testDistribution. Defaults “normal”. standardized logical whether use standardized residuals. Defaults TRUE generally possible may depend method.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelDiagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Diagnostics Functions — modelDiagnostics","text":"logical (.modelDiagnostics)   modelDiagnostics object (list)  .modelDiagnostics modelDiagnostics.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelDiagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Diagnostics Functions — modelDiagnostics","text":"","code":"testm <- stats::lm(mpg ~ hp * factor(cyl), data = mtcars)  md <- modelDiagnostics(testm) #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct plot(md$residualDiagnostics$testDistribution)  md$extremeValues #> Empty data.table (0 rows and 3 cols): mpg,Index,EffectType  plot(md)    md <- modelDiagnostics(testm, ev.perc = .1) #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct md$extremeValues #>     mpg Index EffectType #> 1: 24.4     8  Residuals #> 2: 10.4    15  Residuals #> 3: 10.4    16  Residuals #> 4: 32.4    18  Residuals #> 5: 33.9    20  Residuals #> 6: 21.5    21  Residuals #> 7: 30.4    28  Residuals plot(md, ncol = 2)   testdat <- data.frame(   y = c(1, 2, 2, 3, 3, NA, 9000000, 2, 2, 1),   x = c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2))  modelDiagnostics(   lm(y ~ x, data = testdat, na.action = \"na.omit\"),   ev.perc = .1)$extremeValues #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct #>        y Index EffectType #> 1: 9e+06     7  Residuals  modelDiagnostics(   lm(y ~ x, data = testdat, na.action = \"na.exclude\"),   ev.perc = .1)$extremeValues #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct #>        y Index EffectType #> 1: 9e+06     7  Residuals  ## clean up rm(testm, md, testdat)"},{"path":"https://joshuawiley.com/JWileymisc/reference/modelPerformance.html","id":null,"dir":"Reference","previous_headings":"","what":"Return Indices of Model Performance — modelPerformance","title":"Return Indices of Model Performance — modelPerformance","text":"Generic function. Generally returns things like fit indices, absolute error metrics, tests overall model significance.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelPerformance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return Indices of Model Performance — modelPerformance","text":"","code":"modelPerformance(object, ...)  as.modelPerformance(x)  is.modelPerformance(x)  # S3 method for lm modelPerformance(object, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/modelPerformance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return Indices of Model Performance — modelPerformance","text":"object fitted model object. class model determines specific method called. ... Additional arguments passed specific methods. x object (e.g., list modelPerformance object) test attempt coercing modelPerformance object.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelPerformance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return Indices of Model Performance — modelPerformance","text":"data.table results. list data.table following elements:  Model character string indicating model type, lm N_Obs number observations AIC Akaike Information Criterion BIC Bayesian Information Criterion LL log likelihood LLDF log likelihood degrees freedom Sigma Residual variability R2 sample variance explained F2 Cohen's F2 effect size R2 / (1 - R2) AdjR2 adjusted variance explained F F value overall model significance test FNumDF numerator degrees freedom F test FDenDF denominator degrees freedom F test P p-value overall model F test","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelPerformance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return Indices of Model Performance — modelPerformance","text":"lm class objects, return number observations, AIC, BIC, log likelihood, R2, overall model F test, p-value.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelPerformance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return Indices of Model Performance — modelPerformance","text":"","code":"modelPerformance(lm(mpg ~ qsec * hp, data = mtcars)) #> $Performance #>    Model N_Obs      AIC      BIC        LL LLDF    Sigma        R2       F2 #> 1:    lm    32 165.4972 172.8259 -77.74861    5 2.937243 0.7854734 3.661427 #>        AdjR2        F FNumDF FDenDF            P #> 1: 0.7624884 34.17332      3     28 1.694676e-09 #>  #> attr(,\"class\") #> [1] \"modelPerformance.lm\" \"modelPerformance\"     modelPerformance(lm(mpg ~ hp, data = mtcars)) #> $Performance #>    Model N_Obs      AIC      BIC        LL LLDF    Sigma        R2       F2 #> 1:    lm    32 181.2386 185.6358 -87.61931    3 3.862962 0.6024373 1.515327 #>        AdjR2       F FNumDF FDenDF            P #> 1: 0.5891853 45.4598      1     30 1.787835e-07 #>  #> attr(,\"class\") #> [1] \"modelPerformance.lm\" \"modelPerformance\"     if (FALSE) { modelPerformance(lm(mpg ~ 0 + hp, data = mtcars)) modelPerformance(lm(mpg ~ 1, data = mtcars)) modelPerformance(lm(mpg ~ 0, data = mtcars)) }"},{"path":"https://joshuawiley.com/JWileymisc/reference/modelTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Detailed Tests on Models — modelTest","title":"Detailed Tests on Models — modelTest","text":"TODO: make !","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detailed Tests on Models — modelTest","text":"","code":"modelTest(object, ...)  is.modelTest(x)  as.modelTest(x)  # S3 method for vglm modelTest(object, ...)  # S3 method for lm modelTest(object, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/modelTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detailed Tests on Models — modelTest","text":"object fitted model object. ... Additional arguments passed specific methods. x object (e.g., list modelTest object) test attempt coercing modelTest object.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelTest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detailed Tests on Models — modelTest","text":"Depends method dispatch. list two elements.  Results contains data table actual estimates.  Table contains nicely formatted character matrix. list two elements.  Results contains data table actual estimates.  Table contains nicely formatted character matrix.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/modelTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detailed Tests on Models — modelTest","text":"","code":"mtcars$cyl <- factor(mtcars$cyl) m <- VGAM::vglm(cyl ~ qsec,   family = VGAM::multinomial(), data = mtcars) modelTest(m) #> $FixedEffects #>    Num Names Term Ref        Est        SE        Pval        LL         UL K #> 1:   1  qsec qsec   1 -0.5795781 0.4006097 0.147969796 -1.364759  0.2056026 3 #> 2:   2  qsec qsec   1 -1.2697728 0.4560391 0.005363505 -2.163593 -0.3759525 3 #> 3:   2  qsec qsec   2 -0.6901947 0.4045653 0.088005136 -1.483128  0.1027386 3 #>    Comp  Labels #> 1:    2 2 vs. 1 #> 2:    3 3 vs. 1 #> 3:    3 3 vs. 2 #>  #> $RandomEffects #> [1] NA #>  #> $EffectSizes #>    Term    Chisq DF         Pval  Type #> 1: qsec 14.21315  2 0.0008196964 Fixed #>  #> $OverallModel #> [1] NA #>  #> attr(,\"class\") #> [1] \"modelTest.vglm\" \"modelTest\"       ## clean up rm(m, mtcars)  if (FALSE) { mtcars$cyl <- factor(mtcars$cyl) mtcars$am <- factor(mtcars$am) m <- VGAM::vglm(cyl ~ qsec,   family = VGAM::multinomial(), data = mtcars) modelTest(m)  m <- VGAM::vglm(cyl ~ scale(qsec),   family = VGAM::multinomial(), data = mtcars) modelTest(m)  m2 <- VGAM::vglm(cyl ~ factor(vs) * scale(qsec),   family = VGAM::multinomial(), data = mtcars) modelTest(m2)  m <- VGAM::vglm(Species ~ Sepal.Length,   family = VGAM::multinomial(), data = iris) modelTest(m)  set.seed(1234) sampdata <- data.frame(   Outcome = factor(sample(letters[1:3], 20 * 9, TRUE)),   C1 = rnorm(20 * 9),   D3 = sample(paste0(\"L\", 1:3), 20 * 9, TRUE))  m <- VGAM::vglm(Outcome ~ factor(D3),   family = VGAM::multinomial(), data = sampdata) modelTest(m)  m <- VGAM::vglm(Outcome ~ factor(D3) + C1,   family = VGAM::multinomial(), data = sampdata) modelTest(m) } m1 <- lm(mpg ~ qsec * hp, data = mtcars) modelTest(m1) #> $FixedEffects #>           Term         Est           LL          UL         Pval #> 1: (Intercept)  8.52461247 -17.15039253 34.19961746 0.5020186630 #> 2:        qsec  1.47683245   0.08321560  2.87044931 0.0385855703 #> 3:          hp  0.23587912   0.08515568  0.38660256 0.0033562173 #> 4:     qsec:hp -0.01949155  -0.02855763 -0.01042546 0.0001411028 #>  #> $RandomEffects #> [1] NA #>  #> $EffectSizes #>       Term N_Obs        AIC        BIC       LL LLDF      Sigma         R2 #> 1:    qsec     0  -2.977231  -1.511495 2.488615    1 -0.1823263 0.03610200 #> 2:      hp     0  -8.004306  -6.538570 5.002153    1 -0.4372429 0.07873595 #> 3: qsec:hp     0 -14.841867 -13.376131 8.420933    1 -0.8177254 0.14859655 #>           F2      AdjR2         F FNumDF FDenDF            P  Type #> 1: 0.1682869 0.03040174  4.712032      1     28 0.0385855703 Fixed #> 2: 0.3670219 0.07597596 10.276613      1     28 0.0033562173 Fixed #> 3: 0.6926720 0.15065453 19.394816      1     28 0.0001411028 Fixed #>  #> $OverallModel #> $Performance #>    Model N_Obs      AIC      BIC        LL LLDF    Sigma        R2       F2 #> 1:    lm    32 165.4972 172.8259 -77.74861    5 2.937243 0.7854734 3.661427 #>        AdjR2        F FNumDF FDenDF            P #> 1: 0.7624884 34.17332      3     28 1.694676e-09 #>  #> attr(,\"class\") #> [1] \"modelPerformance.lm\" \"modelPerformance\"    #>  #> attr(,\"class\") #> [1] \"modelTest.lm\" \"modelTest\"     mtcars$cyl <- factor(mtcars$cyl) m2 <- lm(mpg ~ cyl, data = mtcars) modelTest(m2) #> $FixedEffects #>           Term        Est        LL        UL         Pval #> 1: (Intercept)  26.663636  24.67608 28.651192 2.688358e-22 #> 2:        cyl6  -6.920779 -10.10796 -3.733599 1.194696e-04 #> 3:        cyl8 -11.563636 -14.21962 -8.907653 8.568209e-10 #>  #> $RandomEffects #> [1] NA #>  #> $EffectSizes #>    Term N_Obs       AIC       BIC       LL LLDF     Sigma        R2      F2 #> 1:  cyl     0 -38.19157 -35.26009 21.09578    2 -2.803849 0.7324601 2.73776 #>       AdjR2        F FNumDF FDenDF            P  Type #> 1: 0.714009 39.69752      2     29 4.978919e-09 Fixed #>  #> $OverallModel #> $Performance #>    Model N_Obs     AIC      BIC        LL LLDF    Sigma        R2      F2 #> 1:    lm    32 170.564 176.4269 -81.28198    4 3.223099 0.7324601 2.73776 #>       AdjR2        F FNumDF FDenDF            P #> 1: 0.714009 39.69752      2     29 4.978919e-09 #>  #> attr(,\"class\") #> [1] \"modelPerformance.lm\" \"modelPerformance\"    #>  #> attr(,\"class\") #> [1] \"modelTest.lm\" \"modelTest\"     m3 <- lm(mpg ~ hp * cyl, data = mtcars) modelTest(m3) #> $FixedEffects #>           Term          Est            LL          UL         Pval #> 1: (Intercept)  35.98302564  27.988911895 43.97713938 1.042337e-09 #> 2:          hp  -0.11277589  -0.206810088 -0.01874169 2.061364e-02 #> 3:        cyl6 -15.30917451 -30.591135429 -0.02721358 4.962243e-02 #> 4:        cyl8 -17.90295193 -28.714239963 -7.09166390 2.163657e-03 #> 5:     hp:cyl6   0.10516262  -0.035606674  0.24593191 1.367182e-01 #> 6:     hp:cyl8   0.09853177  -0.001415964  0.19847950 5.309562e-02 #>  #> $RandomEffects #> [1] NA #>  #> $EffectSizes #>      Term N_Obs        AIC       BIC       LL LLDF      Sigma         R2 #> 1:     hp     0 -4.7216325 -3.255897 3.360816    1 -0.2724898 0.04949968 #> 2:    cyl     0 -8.3406788 -5.409207 6.170339    2 -0.5104704 0.09965210 #> 3: hp:cyl     0 -0.8128535  2.118618 2.406427    2 -0.1177589 0.03437072 #>           F2      AdjR2        F FNumDF FDenDF           P  Type #> 1: 0.2337410 0.04748123 6.077266      1     26 0.020613638 Fixed #> 2: 0.4705643 0.09229362 6.117336      2     26 0.006648256 Fixed #> 3: 0.1623010 0.02001782 2.109913      2     26 0.141533090 Fixed #>  #> $OverallModel #> $Performance #>    Model N_Obs      AIC      BIC       LL LLDF    Sigma        R2       F2 #> 1:    lm    32 169.0836 179.3437 -77.5418    7 3.028484 0.7882285 3.722071 #>        AdjR2        F FNumDF FDenDF            P #> 1: 0.7475032 19.35477      5     26 5.018882e-08 #>  #> attr(,\"class\") #> [1] \"modelPerformance.lm\" \"modelPerformance\"    #>  #> attr(,\"class\") #> [1] \"modelTest.lm\" \"modelTest\"     m4 <- lm(sqrt(mpg) ~ hp * cyl, data = mtcars) modelTest(m4) #> $FixedEffects #>           Term          Est           LL            UL         Pval #> 1: (Intercept)  6.052499736  5.170711347  6.9342881254 1.070676e-13 #> 2:          hp -0.010956546 -0.021328961 -0.0005841313 3.922162e-02 #> 3:        cyl6 -1.512749623 -3.198421874  0.1729226268 7.650843e-02 #> 4:        cyl8 -1.808475093 -3.001011071 -0.6159391140 4.419878e-03 #> 5:     hp:cyl6  0.010146472 -0.005381043  0.0256739883 1.908190e-01 #> 6:     hp:cyl8  0.009178964 -0.001845741  0.0202036696 9.891437e-02 #>  #> $RandomEffects #> [1] NA #>  #> $EffectSizes #>      Term N_Obs        AIC       BIC       LL LLDF        Sigma         R2 #> 1:     hp     0 -3.3324188 -1.866683 2.666209    1 -0.022238466 0.03882660 #> 2:    cyl     0 -6.5881559 -3.656684 5.294078    2 -0.045762925 0.08397830 #> 3: hp:cyl     0  0.4535321  3.385004 1.773234    2 -0.006189775 0.02509585 #>           F2       AdjR2        F FNumDF FDenDF          P  Type #> 1: 0.1813267 0.035123021 4.714493      1     26 0.03922162 Fixed #> 2: 0.3921925 0.074740039 5.098503      2     26 0.01354906 Fixed #> 3: 0.1172017 0.009548751 1.523623      2     26 0.23674952 Fixed #>  #> $OverallModel #> $Performance #>    Model N_Obs      AIC      BIC       LL LLDF     Sigma        R2       F2 #> 1:    lm    32 27.99504 38.25519 -6.99752    7 0.3340561 0.7858748 3.670165 #>        AdjR2        F FNumDF FDenDF           P #> 1: 0.7446969 19.08486      5     26 5.77082e-08 #>  #> attr(,\"class\") #> [1] \"modelPerformance.lm\" \"modelPerformance\"    #>  #> attr(,\"class\") #> [1] \"modelTest.lm\" \"modelTest\"     m5 <- lm(mpg ~ sqrt(hp) * cyl, data = mtcars) modelTest(m5) #> $FixedEffects #>             Term        Est          LL         UL         Pval #> 1:   (Intercept)  45.320923  30.0821810 60.5596654 1.839533e-06 #> 2:      sqrt(hp)  -2.067923  -3.7442683 -0.3915773 1.757488e-02 #> 3:          cyl6 -23.458371 -54.5954487  7.6787057 1.335616e-01 #> 4:          cyl8 -23.624030 -44.7466708 -2.5013883 2.979562e-02 #> 5: sqrt(hp):cyl6   1.875526  -1.0975943  4.8486458 2.061304e-01 #> 6: sqrt(hp):cyl8   1.608904  -0.3488383  3.5666459 1.031270e-01 #>  #> $RandomEffects #> [1] NA #>  #> $EffectSizes #>            Term N_Obs        AIC        BIC       LL LLDF       Sigma #> 1:     sqrt(hp)     0 -5.0712752 -3.6055393 3.535638    1 -0.28847604 #> 2:          cyl     0 -2.5498555  0.3816163 3.274928    2 -0.20284492 #> 3: sqrt(hp):cyl     0  0.3345454  3.2660172 1.832727    2 -0.06140898 #>            R2        F2      AdjR2        F FNumDF FDenDF          P  Type #> 1: 0.05161694 0.2472952 0.05004665 6.429675      1     26 0.01757488 Fixed #> 2: 0.04740919 0.2271360 0.03471263 2.952768      2     26 0.06988678 Fixed #> 3: 0.02533174 0.1213636 0.01026974 1.577727      2     26 0.22557763 Fixed #>  #> $OverallModel #> $Performance #>    Model N_Obs      AIC      BIC        LL LLDF   Sigma       R2       F2 #> 1:    lm    32 168.6201 178.8802 -77.31003    7 3.00663 0.791274 3.790969 #>        AdjR2        F FNumDF FDenDF            P #> 1: 0.7511343 19.71304      5     26 4.179396e-08 #>  #> attr(,\"class\") #> [1] \"modelPerformance.lm\" \"modelPerformance\"    #>  #> attr(,\"class\") #> [1] \"modelTest.lm\" \"modelTest\"     ## cleanup rm(m1, m2, m3, m4, m5, mtcars)"},{"path":"https://joshuawiley.com/JWileymisc/reference/moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the first and second moments — moments","title":"Estimate the first and second moments — moments","text":"function relies lavaan package use Expectation Maximization (EM) algorithm estimate first second moments (means [co]variances) missing data.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the first and second moments — moments","text":"","code":"moments(data, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the first and second moments — moments","text":"data data frame object coercable data frame. means covariances variables estimated. ... Additional arguments passed estimate.moments.EM function lavaan. Note exported function.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the first and second moments — moments","text":"list containing esimates EM algorithm. mu named vector means. sigma covariance matrix.","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/moments.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate the first and second moments — moments","text":"Suggested Yves Rosseel author lavaan package depends","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/moments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate the first and second moments — moments","text":"","code":"# sample data Xmiss <- as.matrix(iris[, -5]) # make 25% missing completely at random set.seed(10) Xmiss[sample(length(Xmiss), length(Xmiss) * .25)] <- NA Xmiss <- as.data.frame(Xmiss)  # true means and covariance colMeans(iris[, -5]) #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>     5.843333     3.057333     3.758000     1.199333  # covariance with n - 1 divisor cov(iris[, -5]) #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.6856935  -0.0424340    1.2743154   0.5162707 #> Sepal.Width    -0.0424340   0.1899794   -0.3296564  -0.1216394 #> Petal.Length    1.2743154  -0.3296564    3.1162779   1.2956094 #> Petal.Width     0.5162707  -0.1216394    1.2956094   0.5810063  # means and covariance matrix using list wise deletion colMeans(na.omit(Xmiss)) #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>     5.900000     3.126667     3.791111     1.235556  cov(na.omit(Xmiss)) #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.77727273 -0.04704545     1.375000   0.5759091 #> Sepal.Width   -0.04704545  0.16654545    -0.366803  -0.1421061 #> Petal.Length   1.37500000 -0.36680303     3.311737   1.4110051 #> Petal.Width    0.57590909 -0.14210606     1.411005   0.6359798  # means and covariance matrix using EM moments(Xmiss) #> $sigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.66931832 -0.05424143    1.2030205   0.5097302 #> Sepal.Width   -0.05424143  0.19581274   -0.3715246  -0.1330635 #> Petal.Length   1.20302046 -0.37152456    2.9372324   1.2524655 #> Petal.Width    0.50973016 -0.13306354    1.2524655   0.5752271 #>  #> $mu #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>     5.853181     3.076239     3.695702     1.178956  #>  # clean up rm(Xmiss)"},{"path":"https://joshuawiley.com/JWileymisc/reference/naz.omit.html","id":null,"dir":"Reference","previous_headings":"","what":"Missing and Zero Character Omit — naz.omit","title":"Missing and Zero Character Omit — naz.omit","text":"Given vector, exclude missing values, number values, non finite values, character class, zero length strings.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/naz.omit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Missing and Zero Character Omit — naz.omit","text":"","code":"naz.omit(x)"},{"path":"https://joshuawiley.com/JWileymisc/reference/naz.omit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Missing and Zero Character Omit — naz.omit","text":"x vector exclude missing, non finite zero length strings ","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/naz.omit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Missing and Zero Character Omit — naz.omit","text":"vector missing/non finite/zero length strings omitted","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/naz.omit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Missing and Zero Character Omit — naz.omit","text":"","code":"## stats na.omit stats::na.omit(c(1, NA, NaN)) #> [1] 1 #> attr(,\"na.action\") #> [1] 2 3 #> attr(,\"class\") #> [1] \"omit\" stats::na.omit(c(\"test\", \"\", NA_character_)) #> [1] \"test\" \"\"     #> attr(,\"na.action\") #> [1] 3 #> attr(,\"class\") #> [1] \"omit\"  naz.omit(c(1, NA, NaN)) #> [1] 1 naz.omit(c(1L, NA)) #> [1] 1 naz.omit(c(1L, NA, Inf)) #> [1] 1 naz.omit(c(\"test\", \"\", NA_character_)) #> [1] \"test\""},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates summaries for a parameter — param_summary","title":"Calculates summaries for a parameter — param_summary","text":"function takes vector statistics calculates several summaries: mean, median, 95 empirical p-value, , many fall side zero.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates summaries for a parameter — param_summary","text":"","code":"param_summary(x, trans = function(x) x, ..., na.rm = TRUE)"},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates summaries for a parameter — param_summary","text":"x data vector operate trans function transform data. Used summaries, p-values. Defaults identity function. ... Additional arguments passed formatPval control p-value printing. na.rm Logical whether remove NA values. Defaults TRUE","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates summaries for a parameter — param_summary","text":"data frame summary statistics","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates summaries for a parameter — param_summary","text":"","code":"param_summary(rnorm(100)) #>         Mean   Median       SE     LL2.5  UL97.5 pvalue #> 1: 0.2451365 0.206726 1.104723 -1.783577 2.61219   .900"},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a data frame of summary statistics — param_summary_format","title":"Format a data frame of summary statistics — param_summary_format","text":"functions nicely formats data frame parameter summary statistics designed used param_summary() function.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a data frame of summary statistics — param_summary_format","text":"","code":"param_summary_format(d, digits = getOption(\"digits\"), pretty = FALSE)"},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a data frame of summary statistics — param_summary_format","text":"d data frame parameter summary statistics digits Number digits round printing pretty Logical value whether prettified values returned. Defaults FALSE.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format a data frame of summary statistics — param_summary_format","text":"formatted data.table summary statistics formated vector (pretty = TRUE).","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/param_summary_format.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format a data frame of summary statistics — param_summary_format","text":"","code":"set.seed(1234) xsum <- do.call(rbind, apply(matrix(rnorm(100*10), ncol = 10),   2, param_summary)) rownames(xsum) <- letters[1:10] param_summary_format(xsum) #>           Mean     Median        SE      LL2.5    UL97.5 pvalue #>  1: -0.1567617 -0.3846280 1.0044053 -1.7219858 2.0969651   .700 #>  2:  0.0412432  0.0328033 1.0321873 -2.0164916 2.0228078   .980 #>  3:  0.1546037  0.2778768 0.9601544 -1.6890724 1.9511068   .740 #>  4: -0.0081051 -0.0431601 1.0503090 -2.3309867 1.9026890   .940 #>  5: -0.0217859 -0.0085302 1.1166766 -1.9308186 2.1481116  1.000 #>  6: -0.1368770 -0.0672109 0.9289288 -2.0963626 1.4303246   .920 #>  7: -0.0878618 -0.0504099 0.9190978 -1.8120791 1.5856680   .960 #>  8: -0.0008372 -0.1044569 0.9849230 -1.7962415 1.7617463   .920 #>  9:  0.0181244 -0.0518836 0.9235805 -1.7336758 1.8020527   .940 #> 10: -0.0677146 -0.0353446 1.0413951 -2.3707526 1.9937100  1.000 param_summary_format(xsum, pretty = TRUE) #>                                               a  #>  \"-0.1567617 [-1.7219858, 2.0969651], p = .700\"  #>                                               b  #>   \"0.0412432 [-2.0164916, 2.0228078], p = .980\"  #>                                               c  #>   \"0.1546037 [-1.6890724, 1.9511068], p = .740\"  #>                                               d  #>  \"-0.0081051 [-2.3309867, 1.9026890], p = .940\"  #>                                               e  #> \"-0.0217859 [-1.9308186, 2.1481116], p = 1.000\"  #>                                               f  #>  \"-0.1368770 [-2.0963626, 1.4303246], p = .920\"  #>                                               g  #>  \"-0.0878618 [-1.8120791, 1.5856680], p = .960\"  #>                                               h  #>  \"-0.0008372 [-1.7962415, 1.7617463], p = .920\"  #>                                               i  #>   \"0.0181244 [-1.7336758, 1.8020527], p = .940\"  #>                                               j  #> \"-0.0677146 [-2.3707526, 1.9937100], p = 1.000\"   rm(xsum)"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.SEMSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots SEMSummary object — plot.SEMSummary","title":"Plots SEMSummary object — plot.SEMSummary","text":"Plots SEMSummary object","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.SEMSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots SEMSummary object — plot.SEMSummary","text":"","code":"# S3 method for SEMSummary plot(x, y, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.SEMSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots SEMSummary object — plot.SEMSummary","text":"x object class SEMSummary. y Ignored ... Additional arguments passed real workhorse, corplot.","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.SEMSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots SEMSummary object — plot.SEMSummary","text":"","code":"# default plot plot(SEMSummary(~ ., data = mtcars))   # same as default plot(SEMSummary(~ ., data = mtcars), type = \"coverage\")   # shows p values plot(SEMSummary(~ ., data = mtcars), type = \"p\")   # shows correlations plot(SEMSummary(~ ., data = mtcars), type = \"cor\")"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.SEMSummary.list.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots SEMSummary.list object — plot.SEMSummary.list","title":"Plots SEMSummary.list object — plot.SEMSummary.list","text":"Plots SEMSummary.list object","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.SEMSummary.list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots SEMSummary.list object — plot.SEMSummary.list","text":"","code":"# S3 method for SEMSummary.list plot(x, y, which, plot = TRUE, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.SEMSummary.list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots SEMSummary.list object — plot.SEMSummary.list","text":"x object class SEMSummary.list. y Ignored either numeric vector based positions, character vector giving names levels list plot. plot logical, whether actually plot results . Defaults TRUE. ... Additional arguments passed real workhorse, corplot.","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.SEMSummary.list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots SEMSummary.list object — plot.SEMSummary.list","text":"","code":"## correlation matrix by am level plot(SEMSummary(~ . | am, data = mtcars))"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.modelDiagnostics.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Diagnostics for an lm model — plot.modelDiagnostics.lm","title":"Plot Diagnostics for an lm model — plot.modelDiagnostics.lm","text":"function creates number diagnostic plots lm models.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.modelDiagnostics.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Diagnostics for an lm model — plot.modelDiagnostics.lm","text":"","code":"# S3 method for modelDiagnostics.lm plot(x, y, plot = TRUE, ask = TRUE, ncol, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.modelDiagnostics.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Diagnostics for an lm model — plot.modelDiagnostics.lm","text":"x modelDiagnostics class object lm. y Included match generic. used. plot logical value whether plot results simply return graaphical  objects. ask logical whether ask changing plots. applies interactive environments. ncol number columns use plots. Missing default means individual plots created. specified, plots put together grid. ... Included match generic. used.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.modelDiagnostics.lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Diagnostics for an lm model — plot.modelDiagnostics.lm","text":"list including plots residuals,   residuals versus fitted values","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.modelDiagnostics.lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Diagnostics for an lm model — plot.modelDiagnostics.lm","text":"","code":"testm <- stats::lm(mpg ~ hp * factor(cyl), data = mtcars)  md <- modelDiagnostics(testm, ev.perc = .1) #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct  plot(md)   plot(md, ncol = 2)   ## clean up rm(testm, md)"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.residualDiagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Residual Diagnostics Default Method — plot.residualDiagnostics","title":"Plot Residual Diagnostics Default Method — plot.residualDiagnostics","text":"function creates number diagnostic plots residuals. default method.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.residualDiagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Residual Diagnostics Default Method — plot.residualDiagnostics","text":"","code":"# S3 method for residualDiagnostics plot(x, y, plot = TRUE, ask = TRUE, ncol, ...)"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.residualDiagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Residual Diagnostics Default Method — plot.residualDiagnostics","text":"x residualDiagnostics class object. y Included match generic. used. plot logical value whether plot results simply return graphical objects. ask logical whether ask changing plots. applies interactive environments. ncol number columns use plots. Missing default means individual plots created. specified, plots put together grid. ... Included match generic. used.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.residualDiagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Residual Diagnostics Default Method — plot.residualDiagnostics","text":"list including plots residuals,   residuals versus fitted values","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.residualDiagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Residual Diagnostics Default Method — plot.residualDiagnostics","text":"","code":"testm <- stats::lm(mpg ~ hp * factor(cyl), data = mtcars) testm <- stats::lm(mpg ~ factor(cyl), data = mtcars)  md <- residualDiagnostics(testm, ev.perc = .1)  plot(md, plot = FALSE)$ResFittedPlot  plot(md, ncol = 2)   ## clean up rm(testm, md)"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.testDistribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for testDistribution objects — plot.testDistribution","title":"Plot method for testDistribution objects — plot.testDistribution","text":"Make plots testDistribution objects, including density QQ plots.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.testDistribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for testDistribution objects — plot.testDistribution","text":"","code":"# S3 method for testDistribution plot(   x,   y,   xlim = NULL,   varlab = \"X\",   plot = TRUE,   rugthreshold = 500,   seed = 1234,   factor = 1,   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.testDistribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for testDistribution objects — plot.testDistribution","text":"x list class “testDistribution”. y Included match generic. used. xlim optional vector control x limits theoretical distribution density line, useful densities become extreme boundary values help keep scale graph reasonable.  Passed stat_function. varlab character vector label use variable plot logical vector whether plot graphs. Defaults TRUE. rugthreshold Integer determining number observations beyond rug plot added. Note even threshold exceeded, rug plot still added extreme values (extreme values used present). seed random seed used make jitter added Poisson Negative Binomial distributions reproducible factor scale factor fo amount jitter added QQ Deviates plots Poisson Negative Binomial distributions. Defaults 1. results 1 * smallest distance points / 5 used. ... Additional arguments.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.testDistribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for testDistribution objects — plot.testDistribution","text":"invisible list ggplot2 objects graphs,   well information distribution (parameter estimates,   name, log likelihood (useful comparing fit different distributions   data), dataset sorted data theoretical quantiles.","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/plot.testDistribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for testDistribution objects — plot.testDistribution","text":"","code":"## evaluate mpg against a normal distribution plot(testDistribution(mtcars$mpg))   if (FALSE) {  ## example data set.seed(1234) d <- data.table::data.table(   Ynorm = rnorm(200),   Ybeta = rbeta(200, 1, 4),   Ychisq = rchisq(200, 8),   Yf = rf(200, 5, 10),   Ygamma = rgamma(200, 2, 2),   Ynbinom = rnbinom(200, mu = 4, size = 9),   Ypois = rpois(200, 4))  ## testing and graphing plot(testDistribution(d$Ybeta, \"beta\", starts = list(shape1 = 1, shape2 = 4))) plot(testDistribution(d$Ychisq, \"chisq\", starts = list(df = 8)))  ## for chi-square distribution, extreme values only on ## the right tail plot(testDistribution(d$Ychisq, \"chisq\", starts = list(df = 8),   extremevalues = \"empirical\", ev.perc = .1)) plot(testDistribution(d$Ychisq, \"chisq\", starts = list(df = 8),   extremevalues = \"theoretical\", ev.perc = .1))  plot(testDistribution(d$Yf, \"f\", starts = list(df1 = 5, df2 = 10))) plot(testDistribution(d$Ygamma, \"gamma\")) plot(testDistribution(d$Ynbinom, \"poisson\")) plot(testDistribution(d$Ynbinom, \"nbinom\")) plot(testDistribution(d$Ypois, \"poisson\"))  ## compare log likelihood of two different distributions testDistribution(d$Ygamma, \"normal\")$Distribution$LL testDistribution(d$Ygamma, \"gamma\")$Distribution$LL  plot(testDistribution(d$Ynorm, \"normal\")) plot(testDistribution(c(d$Ynorm, 10, 1000), \"normal\",   extremevalues = \"theoretical\")) plot(testDistribution(c(d$Ynorm, 10, 1000), \"normal\",   extremevalues = \"theoretical\", robust = TRUE))  plot(testDistribution(mtcars, \"mvnormal\"))  ## for multivariate normal mahalanobis distance ## which follows a chi-square distribution, extreme values only on ## the right tail plot(testDistribution(mtcars, \"mvnormal\", extremevalues = \"empirical\",   ev.perc = .1)) plot(testDistribution(mtcars, \"mvnormal\", extremevalues = \"theoretical\",   ev.perc = .1))  rm(d) ## cleanup }"},{"path":"https://joshuawiley.com/JWileymisc/reference/residualDiagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Residual Diagnostics Functions — residualDiagnostics","title":"Residual Diagnostics Functions — residualDiagnostics","text":"set functions calculate   residual diagnostics models, including constructors,   generic function, test whether object   residualDiagnostics class, methods.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/residualDiagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residual Diagnostics Functions — residualDiagnostics","text":"","code":"residualDiagnostics(object, ...)  as.residualDiagnostics(x)  is.residualDiagnostics(x)  # S3 method for lm residualDiagnostics(   object,   ev.perc = 0.001,   robust = FALSE,   distr = \"normal\",   standardized = TRUE,   cut = 4L,   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/residualDiagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residual Diagnostics Functions — residualDiagnostics","text":"object fitted model object, methods model.frame, resid fitted. ... Additional arguments, currently used. x object (e.g., list modelDiagnostics object) test attempt coercing residualDiagnostics object. ev.perc real number 0 1 indicating proportion theoretical distribution beyond values considered extreme values (possible outliers). Defaults .001. robust Whether use robust mean standard deviation estimates normal distribution distr character string given assumed distribution. Passed testDistribution. Defaults “normal”. standardized logical whether use standardized residuals. Defaults TRUE generally possible may depend method. cut integer, many unique predicted values least predicted values treated continuously, otherwise treated discrete values. Defaults 4.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/residualDiagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residual Diagnostics Functions — residualDiagnostics","text":"logical (.residualDiagnostics)   residualDiagnostics object (list)  .residualDiagnostics residualDiagnostics.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/residualDiagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Residual Diagnostics Functions — residualDiagnostics","text":"","code":"testm <- stats::lm(mpg ~ hp * factor(cyl), data = mtcars)  resm <- residualDiagnostics(testm) #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct plot(resm$testDistribution)   resm <- residualDiagnostics(testm, standardized = FALSE) #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct #> Warning: singularity problem #> Warning: tiny diagonals replaced with Inf when calling blkfct plot(resm$testDistribution)   ## clean up rm(testm, resm) if (FALSE) {  testdat <- data.frame(   y = c(1, 2, 2, 3, 3, NA, 9000000, 2, 2, 1),   x = c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2))  residualDiagnostics(   lm(y ~ x, data = testdat, na.action = \"na.omit\"),   ev.perc = .1)$Residuals  residualDiagnostics(   lm(y ~ x, data = testdat, na.action = \"na.exclude\"),   ev.perc = .1)$Residuals  residualDiagnostics(   lm(sqrt(mpg) ~ hp, data = mtcars, na.action = \"na.omit\"),   ev.perc = .1)$Residuals }"},{"path":"https://joshuawiley.com/JWileymisc/reference/roundedfivenum.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a rounded five number summary — roundedfivenum","title":"Calculate a rounded five number summary — roundedfivenum","text":"Numbers minimum, 25th percentile, median, 75th percentile, maximum, non missing data. Values returned either significant digits rounded values, whichever ends resulting fewest total digits.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/roundedfivenum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a rounded five number summary — roundedfivenum","text":"","code":"roundedfivenum(x, round = 2, sig = 3)"},{"path":"https://joshuawiley.com/JWileymisc/reference/roundedfivenum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a rounded five number summary — roundedfivenum","text":"x data summary calculated round number digits try rounding sig number significant digits try","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/roundedfivenum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a rounded five number summary — roundedfivenum","text":"rounded significant digit five number summary","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/roundedfivenum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a rounded five number summary — roundedfivenum","text":"","code":"JWileymisc:::roundedfivenum(rnorm(1000)) #> [1] -3.12 -0.62  0.01  0.67  3.17 JWileymisc:::roundedfivenum(mtcars$hp) #> [1]  52.0  96.5 123.0 180.0 335.0"},{"path":"https://joshuawiley.com/JWileymisc/reference/scoring.html","id":null,"dir":"Reference","previous_headings":"","what":"Score a set of items to create overall scale score - generic — scoring","title":"Score a set of items to create overall scale score - generic — scoring","text":"Score set items create overall scale score - generic","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/scoring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Score a set of items to create overall scale score - generic — scoring","text":"","code":"score(   data,   reverse = NULL,   limits = NULL,   mean = TRUE,   reliability = TRUE,   na.rm = TRUE,   ... )  .scoreCESD(data, okay = c(0, 1, 2, 3), reverse = c(4, 8, 12, 16), ...)  .scoreLOTR(   data,   okay = c(1, 2, 3, 4, 5),   reverse = c(2, 4, 5),   indices = list(oindex = c(1, 3, 6), pindex = c(2, 4, 5)),   ... )  .scoreMastery(data, okay = c(1, 2, 3, 4), reverse = c(1, 6), ...)  .scoreMOSSSS(   data,   okay = c(1, 2, 3, 4, 5),   indices = list(Structural = 1, Tangible = c(2, 5, 12, 15), Affectionate = c(6, 10, 20),     PositiveInteraction = c(7, 11, 18), EmotionalInformational = c(3, 9, 16, 19, 4, 8,     13, 17), Functional = 2:20),   ... )  .scorePANAS(   data,   okay = c(1, 2, 3, 4, 5),   indices = list(pos = c(1, 3, 5, 9, 10, 12, 14, 16, 17, 19), neg = c(2, 4, 6, 7, 8, 11,     13, 15, 18, 20)),   ... )  .scoreRSES(data, okay = c(0, 1, 2, 3), reverse = c(3, 5, 8, 9, 10), ...)  .scoreMOOD(   data,   indices = list(vision = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19), impact =     c(13, 14, 15, 16, 17, 20, 21)),   ... )  scaleScore(   data,   type = c(\"CESD\", \"LOTR\", \"Mastery\", \"RSES\", \"MOSSSS\", \"PANAS\"),   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/scoring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Score a set of items to create overall scale score - generic — scoring","text":"data data frame object coercable data frame. reverse vector length number columns data limits optional vector indicating lower upper possible limits (reversing) mean Logical whether calculate mean TRUE sum FALSE reliability Logical whether calculate reliability information scale. Defaults TRUE. na.rm Logical whether remove missing values . Defaults TRUE ... Additional arguments passed lower level functions okay vector okay acceptable values indices Indicates columns subscales, applicable type character string indicating scale name, type scoring use.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/scoring.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Score a set of items to create overall scale score - generic — scoring","text":"list containing results. score calculated scores. reliability Results omega function.","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/smd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Standardized Mean Difference (SMD) — smd","title":"Calculate Standardized Mean Difference (SMD) — smd","text":"Simple function calculate effect sizes mean differences.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/smd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Standardized Mean Difference (SMD) — smd","text":"","code":"smd(x, g, index = c(\"all\", \"1\", \"2\"))"},{"path":"https://joshuawiley.com/JWileymisc/reference/smd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Standardized Mean Difference (SMD) — smd","text":"x continuous variable g grouping variable, two levels index character string: “” uses pooled variance, “1” uses first factor level variance, “2” uses second factor level variance.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/smd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Standardized Mean Difference (SMD) — smd","text":"standardized mean difference.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/smd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Standardized Mean Difference (SMD) — smd","text":"","code":"smd(mtcars$mpg, mtcars$am) #>      SMD  #> 1.477947  smd(mtcars$mpg, mtcars$am, \"all\") #>      SMD  #> 1.477947  smd(mtcars$mpg, mtcars$am, \"1\") #>      SMD  #> 1.889672  smd(mtcars$mpg, mtcars$am, \"2\") #>      SMD  #> 1.174886   smd(mtcars$hp, mtcars$vs) #>      SMD  #> 2.043209   d <- data.table::as.data.table(mtcars) d[, smd(mpg, vs)] #>      SMD  #> 1.733415  rm(d)"},{"path":"https://joshuawiley.com/JWileymisc/reference/star.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to simplify converting p-values to asterisks — star","title":"Function to simplify converting p-values to asterisks — star","text":"Function simplify converting p-values asterisks","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to simplify converting p-values to asterisks — star","text":"","code":"star(x, includeMarginal = FALSE)"},{"path":"https://joshuawiley.com/JWileymisc/reference/star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to simplify converting p-values to asterisks — star","text":"x p values convert stars includeMarginal logical value whether include symbol marginally significant >.05 < .10 p-values. Defaults FALSE.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to simplify converting p-values to asterisks — star","text":"character string stars","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to simplify converting p-values to asterisks — star","text":"","code":"star(c(.0005, .001, .005, .01, .02, .05, .08, .1, .5, 1)) #>  [1] *** *** **  **  *   *"},{"path":"https://joshuawiley.com/JWileymisc/reference/styledescriptives.html","id":null,"dir":"Reference","previous_headings":"","what":"Several internal functions to style descriptive statistics — styledescriptives","title":"Several internal functions to style descriptive statistics — styledescriptives","text":"Several internal functions style descriptive statistics","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/styledescriptives.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Several internal functions to style descriptive statistics — styledescriptives","text":"n character string giving variable name (just name) x variable (actual data, just name) digits integer indicating number significant digits use. Defaults 2. includeLabel logical value, whether include type descriptive statistics label/name. applies functions. Defaults FALSE.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/styledescriptives.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Several internal functions to style descriptive statistics — styledescriptives","text":"data table results.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/styletests.html","id":null,"dir":"Reference","previous_headings":"","what":"Several internal functions to style inference tests — styletests","title":"Several internal functions to style inference tests — styletests","text":"Several internal functions style inference tests","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/styletests.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Several internal functions to style inference tests — styletests","text":"","code":".styleaov(dv, g, digits = 2L, pdigits = 3L)  .style2sttest(dv, g, digits = 2, pdigits = 3)  .stylepairedttest(dv, g, ID, digits = 2, pdigits = 3)  .stylepairedwilcox(dv, g, ID, digits = 2, pdigits = 3)  .stylepairedmcnemar(dv, g, ID, digits = 2, pdigits = 3)  .stylekruskal(dv, g, digits = 2, pdigits = 3)  .stylechisq(dv, g, digits = 2, pdigits = 3, simChisq = FALSE, sims = 10000)  .stylemsd(n, x, digits = 2, includeLabel = FALSE)  .stylemdniqr(n, x, digits = 2, includeLabel = FALSE)  .stylefreq(n, x)"},{"path":"https://joshuawiley.com/JWileymisc/reference/styletests.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Several internal functions to style inference tests — styletests","text":"dv outcome variable g grouping/predictor variable digits integer indicating number significant digits use. Defaults 2. pdigits integer indicating number digits p values. Defaults 3. simChisq logical value, whether simulate chi-square values. applies functions. Defaults FALSE. sims integer indicating number simulations conduct. applies functions. Defaults 10000, arbitrary chosen.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/styletests.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Several internal functions to style inference tests — styletests","text":"character string formatted results.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/styletests.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Several internal functions to style inference tests — styletests","text":"","code":"JWileymisc:::.styleaov(mtcars$mpg, mtcars$cyl) #> [1] \"F(1, 30) = 79.56, p < .001, Eta-squared = 0.73\"  JWileymisc:::.style2sttest(mtcars$mpg, mtcars$am) #> [1] \"t(df=30) = -4.11, p < .001, d = 1.48\"  JWileymisc:::.stylepairedttest(sleep$extra, sleep$group, sleep$ID) #> [1] \"t(df=9) = 4.06, p = .003, d = 1.28\"  JWileymisc:::.stylepairedwilcox(sleep$extra, sleep$group, sleep$ID) #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> [1] \"Wilcoxon Paired V = 45.00, p = .009\"  ## example data set.seed(1234) exdata <- data.frame(   ID = rep(1:10, 2),   Time = rep(c(\"base\", \"post\"), each = 10),   Rating = sample(c(\"good\", \"bad\"), size = 20, replace = TRUE)) JWileymisc:::.stylepairedmcnemar(exdata$Rating, exdata$Time, exdata$ID) #> [1] \"McNemar's Chi-square = 0.25, df = 1, p = .617\" rm(exdata) ## cleanup  JWileymisc:::.stylekruskal(mtcars$mpg, mtcars$am) #> [1] \"KW chi-square = 9.79, df = 1, p = .002\" JWileymisc:::.stylekruskal(mtcars$mpg, mtcars$cyl) #> [1] \"KW chi-square = 25.75, df = 2, p < .001\"  JWileymisc:::.stylechisq(mtcars$cyl, mtcars$am) #> Warning: Chi-squared approximation may be incorrect #> [1] \"Chi-square = 8.74, df = 2, p = .013, Cramer's V = 0.52\"  JWileymisc:::.stylemsd(\"Miles per Gallon\", mtcars$mpg) #>            Variable          Res #> 1: Miles per Gallon 20.09 (6.03) JWileymisc:::.stylemsd(\"Miles per Gallon\", mtcars$mpg, includeLabel = TRUE) #>                    Variable          Res #> 1: Miles per Gallon, M (SD) 20.09 (6.03)  JWileymisc:::.stylemdniqr(\"Miles per Gallon\", mtcars$mpg) #>            Variable          Res #> 1: Miles per Gallon 19.20 (7.38) JWileymisc:::.stylemdniqr(\"Miles per Gallon\", mtcars$mpg, includeLabel = TRUE) #>                       Variable          Res #> 1: Miles per Gallon, Mdn (IQR) 19.20 (7.38)  JWileymisc:::.stylefreq(\"Transmission\", mtcars$am) #>        Variable        Res #> 1: Transmission            #> 2:            0 19 (59.4%) #> 3:            1 13 (40.6%) JWileymisc:::.stylefreq(\"Transmission\", mtcars$am) #>        Variable        Res #> 1: Transmission            #> 2:            0 19 (59.4%) #> 3:            1 13 (40.6%)"},{"path":"https://joshuawiley.com/JWileymisc/reference/testDistribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Test the distribution of a variable against a specific distribution — testDistribution","title":"Test the distribution of a variable against a specific distribution — testDistribution","text":"Function designed help examine distributions. also includes option assessing multivariate normality using (squared) Mahalanobis distance. generic function, methods, constructor (.testDistribution) function check class (.testDistribution) also provided. Note use argument, several options possible. default “complete.obs”, uses cases complete data variables. Another option “pairwise.complete.obs”, uses available data variable indivdiually estimate means variances, pairwise complete observation pairs covariance. cases used estimates, possible obtain covariance matrix positive definite (e.g., correlations > +1 < -1). Finally, last option “fiml”, uses full information maximum likelihood estimates means covariance matrix.  Depending number cases, missing data patterns, variables, may quite slow computationally demanding. robust argument determines whether use robust estimates calculating densities, etc.  default FALSE, TRUE univariate multivariate normal distribution tested, robust estimates means covariance matrix (variance univariate) used based covMcd robustbase package.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/testDistribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test the distribution of a variable against a specific distribution — testDistribution","text":"","code":"testDistribution(x, ...)  as.testDistribution(x)  is.testDistribution(x)  # S3 method for default testDistribution(   x,   distr = c(\"normal\", \"beta\", \"chisq\", \"f\", \"gamma\", \"geometric\", \"nbinom\", \"poisson\",     \"uniform\", \"mvnormal\"),   na.rm = TRUE,   starts,   extremevalues = c(\"no\", \"theoretical\", \"empirical\"),   ev.perc = 0.005,   use = c(\"complete.obs\", \"pairwise.complete.obs\", \"fiml\"),   robust = FALSE,   ... )"},{"path":"https://joshuawiley.com/JWileymisc/reference/testDistribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test the distribution of a variable against a specific distribution — testDistribution","text":"x data single variable vector check distribution unless distribution “mvnormal” case data frame data table. ... Additional arguments. include mu sigma distribution multivariate normal, use passed values instead calculating mean covariances data. distr character string indicating distribution tested. Currently one : “normal”, “beta”, “chisq” (chi-squared), “f”, “gamma”, “geometric”, “nbinom” (negative binomial), “poisson”, “uniform”, “mvnormal” multivariate normal Mahalanobis distances calculated compared Chi-squared distribution degrees freedom equal number variables. na.rm logical value whether omit missing values. Defaults TRUE. starts named list starting values. required distributions. Passed fitdistr fits maximum likelihood estimates distribution parameters. extremevalues character vector whether indicate extreme values. “” nothing, “empirical” show extreme values based observed data percentiles, “theoretical” show extreme values based percentiles theoretical distribution. ev.perc Percentile use extreme values.  example .01, lowest 1 percent highest 1 percent labelled extreme values.  Defaults lowest highest 0.5 percent. use character vector indicating moments (means covariance matrix) estimated presence missing data distr = mvnormal. default use complete observations, full information maximum likelihood based functions lavaan also available.  See details. robust logical whether use robust estimation . Currently applies normally distributed data (univariate multivariate).  Also, robust = TRUE, complete observations used (.e., use = \"complete.obs\"). See details.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/testDistribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test the distribution of a variable against a specific distribution — testDistribution","text":"logical whether object class  testDistribution object class. list information distribution (parameter estimates,   name, log likelihood (useful comparing fit different distributions   data), dataset sorted data theoretical quantiles.","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/testDistribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test the distribution of a variable against a specific distribution — testDistribution","text":"","code":"## example data set.seed(1234) d <- data.table::data.table(   Ynorm = rnorm(200),   Ybeta = rbeta(200, 1, 4),   Ychisq = rchisq(200, 8),   Yf = rf(200, 5, 10),   Ygamma = rgamma(200, 2, 2),   Ynbinom = rnbinom(200, mu = 4, size = 9),   Ypois = rpois(200, 4))  ## testing and graphing testDistribution(d$Ybeta, \"beta\", starts = list(shape1 = 1, shape2 = 4)) #> $Data #>                 X           Y OriginalOrder isEV    YDeviates #>   1: 0.0009548787 0.002899638            20   No  0.001944759 #>   2: 0.0026222465 0.006542140           122   No  0.003919893 #>   3: 0.0041999262 0.007116305           124   No  0.002916379 #>   4: 0.0057324381 0.007488806           119   No  0.001756368 #>   5: 0.0072360495 0.008381499             7   No  0.001145450 #>  ---                                                          #> 196: 0.5896978140 0.658553356           192   No  0.068855542 #> 197: 0.6125406443 0.680790719           171   No  0.068250075 #> 198: 0.6411187285 0.689096550           175   No  0.047977822 #> 199: 0.6804840872 0.694824897           181   No  0.014340810 #> 200: 0.7510216428 0.697959189           198   No -0.053062454 #>  #> $Distribution #> $Distribution$d #> function (x, shape1, shape2, ncp = 0, log = FALSE)  #> { #>     if (missing(ncp))  #>         .Call(C_dbeta, x, shape1, shape2, log) #>     else .Call(C_dnbeta, x, shape1, shape2, ncp, log) #> } #> <bytecode: 0x55bb90a8daa0> #> <environment: namespace:stats> #>  #> $Distribution$q #> function (p, shape1, shape2, ncp = 0, lower.tail = TRUE, log.p = FALSE)  #> { #>     if (missing(ncp))  #>         .Call(C_qbeta, p, shape1, shape2, lower.tail, log.p) #>     else .Call(C_qnbeta, p, shape1, shape2, ncp, lower.tail,  #>         log.p) #> } #> <bytecode: 0x55bb90a8e670> #> <environment: namespace:stats> #>  #> $Distribution$Name #> [1] \"Beta\" #>  #> $Distribution$fit #>      shape1       shape2   #>   1.09047254   4.43181099  #>  (0.09708525) (0.46533971) #>  #> $Distribution$LL #> 'log Lik.' 131.529 (df=2) #>  #>  #> $EVLimits #> [1] -Inf  Inf #>  #> $NOK #> [1] 200 #>  #> $distr #> [1] \"beta\" #>  #> $na.rm #> [1] TRUE #>  #> $extremevalues #> [1] \"no\" #>  #> $ev.perc #> [1] 0.005 #>  #> $use #> [1] \"complete.obs\" #>  #> $robust #> [1] FALSE #>  #> attr(,\"class\") #> [1] \"testDistribution\" testDistribution(d$Ychisq, \"chisq\", starts = list(df = 8)) #> $Data #>              X         Y OriginalOrder isEV   YDeviates #>   1:  1.020806  1.119129            75   No  0.09832363 #>   2:  1.409747  1.386369            54   No -0.02337731 #>   3:  1.647133  1.476380            78   No -0.17075244 #>   4:  1.829535  1.785484           149   No -0.04405142 #>   5:  1.981898  1.948253            56   No -0.03364471 #>  ---                                                    #> 196: 17.443427 19.520193            34   No  2.07676616 #> 197: 18.145695 19.541868           154   No  1.39617310 #> 198: 19.071980 20.585244            55   No  1.51326441 #> 199: 20.451772 20.984934           170   No  0.53316198 #> 200: 23.332634 24.064860            12   No  0.73222569 #>  #> $Distribution #> $Distribution$d #> function (x, df, ncp = 0, log = FALSE)  #> { #>     if (missing(ncp))  #>         .Call(C_dchisq, x, df, log) #>     else .Call(C_dnchisq, x, df, ncp, log) #> } #> <bytecode: 0x55bb9062b5f8> #> <environment: namespace:stats> #>  #> $Distribution$q #> function (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)  #> { #>     if (missing(ncp))  #>         .Call(C_qchisq, p, df, lower.tail, log.p) #>     else .Call(C_qnchisq, p, df, ncp, lower.tail, log.p) #> } #> <bytecode: 0x55bb9062c120> #> <environment: namespace:stats> #>  #> $Distribution$Name #> [1] \"Chi-squared\" #>  #> $Distribution$fit #>       df     #>   7.7424489  #>  (0.2605917) #>  #> $Distribution$LL #> 'log Lik.' -544.7285 (df=1) #>  #>  #> $EVLimits #> [1] -Inf  Inf #>  #> $NOK #> [1] 200 #>  #> $distr #> [1] \"chisq\" #>  #> $na.rm #> [1] TRUE #>  #> $extremevalues #> [1] \"no\" #>  #> $ev.perc #> [1] 0.005 #>  #> $use #> [1] \"complete.obs\" #>  #> $robust #> [1] FALSE #>  #> attr(,\"class\") #> [1] \"testDistribution\"  ## for chi-square distribution, extreme values only on ## the right tail testDistribution(d$Ychisq, \"chisq\", starts = list(df = 8),   extremevalues = \"empirical\", ev.perc = .1) #> $Data #>              X         Y OriginalOrder isEV   YDeviates #>   1:  1.020806  1.119129            75   No  0.09832363 #>   2:  1.409747  1.386369            54   No -0.02337731 #>   3:  1.647133  1.476380            78   No -0.17075244 #>   4:  1.829535  1.785484           149   No -0.04405142 #>   5:  1.981898  1.948253            56   No -0.03364471 #>  ---                                                    #> 196: 17.443427 19.520193            34  Yes  2.07676616 #> 197: 18.145695 19.541868           154  Yes  1.39617310 #> 198: 19.071980 20.585244            55  Yes  1.51326441 #> 199: 20.451772 20.984934           170  Yes  0.53316198 #> 200: 23.332634 24.064860            12  Yes  0.73222569 #>  #> $Distribution #> $Distribution$d #> function (x, df, ncp = 0, log = FALSE)  #> { #>     if (missing(ncp))  #>         .Call(C_dchisq, x, df, log) #>     else .Call(C_dnchisq, x, df, ncp, log) #> } #> <bytecode: 0x55bb9062b5f8> #> <environment: namespace:stats> #>  #> $Distribution$q #> function (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)  #> { #>     if (missing(ncp))  #>         .Call(C_qchisq, p, df, lower.tail, log.p) #>     else .Call(C_qnchisq, p, df, ncp, lower.tail, log.p) #> } #> <bytecode: 0x55bb9062c120> #> <environment: namespace:stats> #>  #> $Distribution$Name #> [1] \"Chi-squared\" #>  #> $Distribution$fit #>       df     #>   7.7424489  #>  (0.2605917) #>  #> $Distribution$LL #> 'log Lik.' -544.7285 (df=1) #>  #>  #> $EVLimits #>               90%  #>     -Inf 13.60881  #>  #> $NOK #> [1] 200 #>  #> $distr #> [1] \"chisq\" #>  #> $na.rm #> [1] TRUE #>  #> $extremevalues #> [1] \"empirical\" #>  #> $ev.perc #> [1] 0.1 #>  #> $use #> [1] \"complete.obs\" #>  #> $robust #> [1] FALSE #>  #> attr(,\"class\") #> [1] \"testDistribution\" testDistribution(d$Ychisq, \"chisq\", starts = list(df = 8),   extremevalues = \"theoretical\", ev.perc = .1) #> $Data #>              X         Y OriginalOrder isEV   YDeviates #>   1:  1.020806  1.119129            75   No  0.09832363 #>   2:  1.409747  1.386369            54   No -0.02337731 #>   3:  1.647133  1.476380            78   No -0.17075244 #>   4:  1.829535  1.785484           149   No -0.04405142 #>   5:  1.981898  1.948253            56   No -0.03364471 #>  ---                                                    #> 196: 17.443427 19.520193            34  Yes  2.07676616 #> 197: 18.145695 19.541868           154  Yes  1.39617310 #> 198: 19.071980 20.585244            55  Yes  1.51326441 #> 199: 20.451772 20.984934           170  Yes  0.53316198 #> 200: 23.332634 24.064860            12  Yes  0.73222569 #>  #> $Distribution #> $Distribution$d #> function (x, df, ncp = 0, log = FALSE)  #> { #>     if (missing(ncp))  #>         .Call(C_dchisq, x, df, log) #>     else .Call(C_dnchisq, x, df, ncp, log) #> } #> <bytecode: 0x55bb9062b5f8> #> <environment: namespace:stats> #>  #> $Distribution$q #> function (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)  #> { #>     if (missing(ncp))  #>         .Call(C_qchisq, p, df, lower.tail, log.p) #>     else .Call(C_qnchisq, p, df, ncp, lower.tail, log.p) #> } #> <bytecode: 0x55bb9062c120> #> <environment: namespace:stats> #>  #> $Distribution$Name #> [1] \"Chi-squared\" #>  #> $Distribution$fit #>       df     #>   7.7424489  #>  (0.2605917) #>  #> $Distribution$LL #> 'log Lik.' -544.7285 (df=1) #>  #>  #> $EVLimits #> [1]  0.00000 13.01761 #>  #> $NOK #> [1] 200 #>  #> $distr #> [1] \"chisq\" #>  #> $na.rm #> [1] TRUE #>  #> $extremevalues #> [1] \"theoretical\" #>  #> $ev.perc #> [1] 0.1 #>  #> $use #> [1] \"complete.obs\" #>  #> $robust #> [1] FALSE #>  #> attr(,\"class\") #> [1] \"testDistribution\"  if (FALSE) {  testDistribution(d$Yf, \"uniform\") testDistribution(d$Ypois, \"geometric\")  testDistribution(d$Yf, \"f\", starts = list(df1 = 5, df2 = 10)) testDistribution(d$Ygamma, \"gamma\") testDistribution(d$Ynbinom, \"poisson\") testDistribution(d$Ynbinom, \"nbinom\") testDistribution(d$Ypois, \"poisson\")  ## compare log likelihood of two different distributions testDistribution(d$Ygamma, \"normal\")$Distribution$LL testDistribution(d$Ygamma, \"gamma\")$Distribution$LL  testDistribution(d$Ynorm, \"normal\") testDistribution(c(d$Ynorm, 10, 1000), \"normal\",   extremevalues = \"theoretical\") testDistribution(c(d$Ynorm, 10, 1000), \"normal\",   extremevalues = \"theoretical\", robust = TRUE)  testDistribution(mtcars, \"mvnormal\")  ## for multivariate normal mahalanobis distance ## which follows a chi-square distribution, extreme values only on ## the right tail testDistribution(mtcars, \"mvnormal\", extremevalues = \"empirical\",   ev.perc = .1) testDistribution(mtcars, \"mvnormal\", extremevalues = \"theoretical\",   ev.perc = .1)  rm(d) ## cleanup }"},{"path":"https://joshuawiley.com/JWileymisc/reference/timeshift.html","id":null,"dir":"Reference","previous_headings":"","what":"Shift a time variable to have a new center (zero point) — timeshift","title":"Shift a time variable to have a new center (zero point) — timeshift","text":"Given vector, shift values new center, keeping minimum maximum.  Designed work time values minimum indicates time maximum (e.g., 24:00:00 00:00:00).","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/timeshift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shift a time variable to have a new center (zero point) — timeshift","text":"","code":"timeshift(x, center = 0, min = 0, max = 1, inverse = FALSE)"},{"path":"https://joshuawiley.com/JWileymisc/reference/timeshift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shift a time variable to have a new center (zero point) — timeshift","text":"x time scores shift center value (minimum maximum) center time scores. Defaults 0, effect. min theoretical minimum time scores. Defaults 0. max theoretical maximum time scores. Defaults 1. inverse logical value, whether ‘unshift’ time scores.  Defaults FALSE.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/timeshift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shift a time variable to have a new center (zero point) — timeshift","text":"vector shifted time scores, recentered specified.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/timeshift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shift a time variable to have a new center (zero point) — timeshift","text":"","code":"## example showing centering at 11am (i.e., 11am becomes new 0) plot((1:24)/24, timeshift((1:24)/24, 11/24))   ## example showing the inverse, note that 24/24 becomes 0 plot((1:24)/24, timeshift(timeshift((1:24)/24, 11/24), 11/24, inverse = TRUE))"},{"path":"https://joshuawiley.com/JWileymisc/reference/vainternal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal Visual Acuity Functions — vainternal","title":"Internal Visual Acuity Functions — vainternal","text":"function one several designed help convert measures visual acuity recorded typically recorded Snellen fractions (e.g., 20/20 sees 20 feet \"typically\" seen 20 feet. 20/40 sees 20 feet \"typically\" seen 40 feet, etc.) statistically usable data.  can also parse text data Counting Fingers (CF) Hand Motion (HM)  convert approximate logMAR values. internal function  meant called directly.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/vainternal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal Visual Acuity Functions — vainternal","text":"","code":"logmar(x, snell.numerator = 20, inverse = FALSE)  CFHM(x, zero)  snellen(snellenvalue, chart.values, chart.nletters)"},{"path":"https://joshuawiley.com/JWileymisc/reference/vainternal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal Visual Acuity Functions — vainternal","text":"x Character data form: “CF 10”, “HM 12”, “HM”, “CF”, “CF 2”, etc. converted logMAR values. snell.numerator numerator Snellen fraction. defaults 20 (common one). inverse inverse = FALSE default.  TRUE, logmar assume x logMAR value, calculate denominator Snellen fraction using snell.numerator numerator. zero “zero” logMAR value used CF HM value missing number.  May actual number simply NA snellenvalue observed snellen values chart.values chart snellen values chart.nletters number letters per chart line","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/vainternal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal Visual Acuity Functions — vainternal","text":"treats CF approximately 200 letters (per Holladay), CF 10 feet Snellen value \"equivalent\" 10/200. HM approximately 10 times worse, HM 10 feet approximately 10/2000.  conversion, rough equivalents passed logmar actually converted. functions responsible suitably parsing text passing numbers logmar. inverse = FALSE (default), logmar calculates \\(-log_{10}(\\frac{snell.numerator}{x})\\). TRUE, \\(\\frac{snell.numerator}{10^{-x}}\\). zero argument used specify \"zero\" logMAR value. particular, used distance information given (e.g., \"HM\" \"CF\" opposed \"CF 6\" \"HM 4\"). reasioning rational behind , see \"Details\" section VAConverter. snellen function, input character data numerator denominator separated '/'.  E.g., “20/20”, “20/40 + 3”.  handles simple Snellen values need interpolated given appropriate chart. logMAR calculations including interpolating partial lines. Given “20/25 + 3”, calculate logMAR 20/25 20/20 (next step since '+'), go 3/chart.nletters way two values.  Similarly “20/20 - 3”, go partway 20/25 20/30. Note depends lines letters per line actual chart used. chart.values chart.nletters contain lines number letters chart used. functions written deal specific style recording visual acuity study worked .  may may much use elsewhere.  CFHM intended typically called user directly. Generally, higher level function, (e.g., VAConverter) called.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/vainternal.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal Visual Acuity Functions — vainternal","text":"Jack T. Holladay (2004).  Visual acuity measurements.   Journal Cataract & Refractive Surgery, 30(2),   pp. 287--290. doi:10.1016/j.jcrs.2004.01.014","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/reference/vainternal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Internal Visual Acuity Functions — vainternal","text":"","code":"## logMAR value for \"perfect\" 20/20 vision JWileymisc:::logmar(x = 20) #> [1] 0  ## Go to and from logMAR value, should return \"20\" ## there may be slight error due to floating point arithmetic JWileymisc:::logmar(x = JWileymisc:::logmar(x = 20), inverse = TRUE) #> [1] 20  ## logMAR value for 20/40 vision JWileymisc:::logmar(40) #> [1] 0.30103 ## logMAR approximations, note \"HM\" is just the zero value JWileymisc:::CFHM(c(\"HM 20\", \"HM\", \"CF 20\", \"CF 12\", \"CF\"), zero = 3) #> [1] 2.000000 3.000000 1.000000 1.221849 3.000000 ## In cases where there is insufficient data, rather than choose ## an arbitrary value, you can may just use NA JWileymisc:::CFHM(c(\"HM 20\", \"HM\", \"CF 20\", \"CF 12\", \"CF\"), zero = NA) #> [1] 2.000000       NA 1.000000 1.221849       NA"},{"path":"https://joshuawiley.com/JWileymisc/reference/winsorizor.html","id":null,"dir":"Reference","previous_headings":"","what":"Winsorize at specified percentiles — winsorizor","title":"Winsorize at specified percentiles — winsorizor","text":"Simple function winsorizes data specified percentile.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/winsorizor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Winsorize at specified percentiles — winsorizor","text":"","code":"winsorizor(d, percentile, values, na.rm = TRUE)"},{"path":"https://joshuawiley.com/JWileymisc/reference/winsorizor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Winsorize at specified percentiles — winsorizor","text":"d vector, matrix, data frame, data table winsorized percentile percentile bounded [0, 1] winsorize data . data frame matrix provided data, length number columns, repeated . values values specified, use instead calculating percentiles. data frame columns named “low”, “high”. data frame matrix provided data, many rows values winsorize columns data. na.rm logical whether remove NAs.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/winsorizor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Winsorize at specified percentiles — winsorizor","text":"winsorized data. Attributes included list exact values   (variable, data frame matrix) used winsorize   lower upper ends.","code":""},{"path":"https://joshuawiley.com/JWileymisc/reference/winsorizor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Winsorize at specified percentiles — winsorizor","text":"","code":"dev.new(width = 10, height = 5) par(mfrow = c(1, 2)) hist(as.vector(eurodist), main = \"Eurodist\") hist(winsorizor(as.vector(eurodist), .05), main = \"Eurodist with lower and upper\\n5% winsorized\")  library(data.table) dat <- data.table(x = 1:5) dat[, y := scale(1:5)] #>    x          y #> 1: 1 -1.2649111 #> 2: 2 -0.6324555 #> 3: 3  0.0000000 #> 4: 4  0.6324555 #> 5: 5  1.2649111 winsorizor(dat$y, .01) #> Warning: Atomic type with no dimensions, coercing to a numeric vector. #> To remove this warning, try wrapping the data in as.numeric() or #> otherwise coercing to a vector prior to passing to winsorizor(). #> [1] -1.2396128 -0.6324555  0.0000000  0.6324555  1.2396128 #> attr(,\"winsorizedValues\") #>         low     high percentile #> 1 -1.239613 1.239613       0.01  ## make a copy of the data table winsorizor(dat, .01) #>       x          y #> 1: 1.04 -1.2396128 #> 2: 2.00 -0.6324555 #> 3: 3.00  0.0000000 #> 4: 4.00  0.6324555 #> 5: 4.96  1.2396128  winsorizor(mtcars, .01) #>       mpg cyl    disp     hp  drat      wt    qsec vs am gear carb #> 1  21.000   6 160.000 110.00 3.900 2.62000 16.4600  0  1    4 4.00 #> 2  21.000   6 160.000 110.00 3.900 2.87500 17.0200  0  1    4 4.00 #> 3  22.800   4 108.000  93.00 3.850 2.32000 18.6100  1  1    4 1.00 #> 4  21.400   6 258.000 110.00 3.080 3.21500 19.4400  1  0    3 1.00 #> 5  18.700   8 360.000 175.00 3.150 3.44000 17.0200  0  0    3 2.00 #> 6  18.100   6 225.000 105.00 2.760 3.46000 20.2200  1  0    3 1.00 #> 7  14.300   8 360.000 245.00 3.210 3.57000 15.8400  0  0    3 4.00 #> 8  24.400   4 146.700  62.00 3.690 3.19000 20.0000  1  0    4 2.00 #> 9  22.800   4 140.800  95.00 3.920 3.15000 22.0692  1  0    4 2.00 #> 10 19.200   6 167.600 123.00 3.920 3.44000 18.3000  1  0    4 4.00 #> 11 17.800   6 167.600 123.00 3.920 3.44000 18.9000  1  0    4 4.00 #> 12 16.400   8 275.800 180.00 3.070 4.07000 17.4000  0  0    3 3.00 #> 13 17.300   8 275.800 180.00 3.070 3.73000 17.6000  0  0    3 3.00 #> 14 15.200   8 275.800 180.00 3.070 3.78000 18.0000  0  0    3 3.00 #> 15 10.400   8 468.280 205.00 2.930 5.25000 17.9800  0  0    3 4.00 #> 16 10.400   8 460.000 215.00 3.000 5.39951 17.8200  0  0    3 4.00 #> 17 14.700   8 440.000 230.00 3.230 5.34500 17.4200  0  0    3 4.00 #> 18 32.400   4  78.700  66.00 4.080 2.20000 19.4700  1  1    4 1.00 #> 19 30.400   4  75.700  55.10 4.775 1.61500 18.5200  1  1    4 2.00 #> 20 33.435   4  72.526  65.00 4.220 1.83500 19.9000  1  1    4 1.00 #> 21 21.500   4 120.100  97.00 3.700 2.46500 20.0100  1  0    3 1.00 #> 22 15.500   8 318.000 150.00 2.760 3.52000 16.8700  0  0    3 2.00 #> 23 15.200   8 304.000 150.00 3.150 3.43500 17.3000  0  0    3 2.00 #> 24 13.300   8 350.000 245.00 3.730 3.84000 15.4100  0  0    3 4.00 #> 25 19.200   8 400.000 175.00 3.080 3.84500 17.0500  0  0    3 2.00 #> 26 27.300   4  79.000  66.00 4.080 1.93500 18.9000  1  1    4 1.00 #> 27 26.000   4 120.300  91.00 4.430 2.14000 16.7000  0  1    5 2.00 #> 28 30.400   4  95.100 113.00 3.770 1.54462 16.9000  1  1    5 2.00 #> 29 15.800   8 351.000 264.00 4.220 3.17000 14.5310  0  1    5 4.00 #> 30 19.700   6 145.000 175.00 3.620 2.77000 15.5000  0  1    5 6.00 #> 31 15.000   8 301.000 312.99 3.540 3.57000 14.6000  0  1    5 7.38 #> 32 21.400   4 121.000 109.00 4.110 2.78000 18.6000  1  1    4 2.00  winsorizor(matrix(1:9, 3), .01) #>      [,1] [,2] [,3] #> [1,] 1.02 4.02 7.02 #> [2,] 2.00 5.00 8.00 #> [3,] 2.98 5.98 8.98 #> attr(,\"winsorizedValues\") #>    low high percentile #> 1 1.02 2.98       0.01 #> 2 4.02 5.98       0.01 #> 3 7.02 8.98       0.01  rm(dat) # clean up"},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"bug-fixes-1-4-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"JWileymisc 1.4.1","text":"Updated code preparation .atomic(NULL) longer working. Updated address aes_string() deprecated","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-140","dir":"Changelog","previous_headings":"","what":"JWileymisc 1.4.0","title":"JWileymisc 1.4.0","text":"CRAN release: 2023-02-10","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"new-features-1-4-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"JWileymisc 1.4.0","text":".naz() new function testing counter part naz.omit(). Notably, .naz() naz.omit() also identify exclude non finite values now. new behavior.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"changes-1-4-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"JWileymisc 1.4.0","text":"egltable() error checks including variables missing values. Frequency (percent) results now shown clearly percent sign (%). corresponds changes backend egltable() facilitate tests descriptives calculated.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-130","dir":"Changelog","previous_headings":"","what":"JWileymisc 1.3.0","title":"JWileymisc 1.3.0","text":"CRAN release: 2022-05-10","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"new-features-1-3-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"JWileymisc 1.3.0","text":"diffCircular() calculates circular difference two vectors. saveRDSfst() saves RDS files using fst multithreaded compression. readRDSfst() reads RDS files using fst multithreaded decompression.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"bug-fixes-1-3-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"JWileymisc 1.3.0","text":"egltable() now correctly handles categorical variables grouping variable, categorical variable factor class. Fixes bug occur cells zero frequencies variables factors. winsorizor() properly check vector percentiles passed. fixed new test added prevent regression.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"changes-1-3-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"JWileymisc 1.3.0","text":"Now using testthat 3e preferably light/dark package website.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-120","dir":"Changelog","previous_headings":"","what":"JWileymisc 1.2.0","title":"JWileymisc 1.2.0","text":"CRAN release: 2020-08-31","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"bug-fixes-1-2-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"JWileymisc 1.2.0","text":"meanCircular() pi circumstances. corrected test cases added. SEMSummary() pairwise correlations based standardized pairwise covariance matrix, used standard deviation variable regardless pair. now fixed. Formula specified calls stat_smooth() reduce messages .","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"changes-1-2-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"JWileymisc 1.2.0","text":"corplot() uses color blind friendly palette defaults showing correlations p-values. Model diagnostics smarter linear regressions essentially discrete model predictions longer try run quantile regression examine homogeneity variance cases. Switched using ggpubr instead cowplot themes arranging multiple plots. Bumped minimum version R required. unit testing.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-111","dir":"Changelog","previous_headings":"","what":"JWileymisc 1.1.1","title":"JWileymisc 1.1.1","text":"CRAN release: 2020-04-28","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"bug-fixes-1-1-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"JWileymisc 1.1.1","text":"modelTest() now works correctly interaction terms categorical variables “--fly” transformations performed, log() etc. work new variables composite multiple variables created, e.g., (hp + wt), informative error message given. Added correct version requirements data.table DESCRIPTION dependencies.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-110","dir":"Changelog","previous_headings":"","what":"JWileymisc 1.1.0","title":"JWileymisc 1.1.0","text":"CRAN release: 2020-01-22","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"changes-1-1-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"JWileymisc 1.1.0","text":"Polished methods functions, including APAStyler() methods.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-101","dir":"Changelog","previous_headings":"","what":"JWileymisc 1.0.1","title":"JWileymisc 1.0.1","text":"CRAN release: 2019-12-11","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"bug-fixes-1-0-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"JWileymisc 1.0.1","text":"residualDiagnostics.lm() modelDiagnostics.lm return index extreme values based complete data used modelling, original input dataset. made difficult identify remove extreme values subsequent model runs. now corrected.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-100","dir":"Changelog","previous_headings":"","what":"JWileymisc 1.0.0","title":"JWileymisc 1.0.0","text":"CRAN release: 2019-11-22","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"JWileymisc 1.0.0","text":"version includes significant re-write package results many previous user-facing functions changing names arguments. likely break old code. re-write necessary help standardize functions arguments, make functions robust. Many functions now generics specific methods written. , functions previously bundled JWileymisc separated packages, including new extraoperators package, covering binary operators, package diagnostics mixed models. See new vignettes added package examples current practice using JWileymisc.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"new-features-1-0-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"JWileymisc 1.0.0","text":"egltable() added statistical tests paired data. continuous, parametric paired data, pseudo Cohen’s d calculated change scores.","code":""},{"path":[]},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"new-features-0-3-2","dir":"Changelog","previous_headings":"","what":"New Features","title":"JWileymisc 0.3.2","text":"omegaSEM() Function calculates coefficient omega measuring internal consistency reliability. Works two level models returns within level omega values. egltable() Function added effect sizes multiple groups compared including Cohen’s d two groups, eta-squared multiple groups, phi categorical variables.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"bug-fixes-0-3-2","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"JWileymisc 0.3.2","text":"testdistr() now finds extreme values right tail chi-square distribution. .detailedTestsVGLM() now identifies levels outcome correctly.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-031","dir":"Changelog","previous_headings":"","what":"JWileymisc 0.3.1","title":"JWileymisc 0.3.1","text":"CRAN release: 2018-09-15","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"changes-0-3-1","dir":"Changelog","previous_headings":"","what":"Changes","title":"JWileymisc 0.3.1","text":"detailedTests() now generic dispatches .detailedTestsLMER() .detailedTestsVGLM() provide detailed tests linear mixed effects models multinomial logistic regression models fit vglm(). ezMULTINOM() now deprecated favor new, generic detailedTests().","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"bug-fixes-0-3-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"JWileymisc 0.3.1","text":"testdistr() now creates appropriate plots discrete distributions including Poisson Negative Binomial. moments() now updated accomodate changes lavaan package (thanks Yves Rosseel) TukeyHSDgg() updated use emmeans package instead now defunct lsmeans package. formatLMER() returned lower confidence interval twice instead lower upper confidence interval. now fixed.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-030","dir":"Changelog","previous_headings":"","what":"JWileymisc 0.3.0","title":"JWileymisc 0.3.0","text":"CRAN release: 2018-08-26","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"JWileymisc 0.3.0","text":"R2LMER() simple function calculate marginal conditional variance accounted model estimated lmer(). compareLMER() function compare two models estimated lmer() include significance tests effect sizes estimates variance explained. detailedTests() function compute detailed tests model estimated lmer() including confidence intervals parameters, significance tests, possible, overall model fit, effect sizes model variable. formatLMER() function nicely format detailed model results, possibly multiple models. Requires results detailedTests() based lmer() models, moment. iccMixed() function calculate intraclass correlation coefficient using mixed effects models. Works either normally distributed outcomes binary outcomes, case latent variable estimate ICC computed. nEffective() Calculates effective sample size based number independent units, number observations per unit, intraclass correlation coefficient. acfByID() Calculates lagged autocorrelation variable ID variable returns data.table use, examination, summary, plotting meanDeviations() simple function calculate means mean deviations, useful creating within versions variable data.table .na() function added convert data missing (NA) preserving class/type data (useful data.table). meanDecompose() function added decompose multilevel repeated measures data means residuals. timeshift() function added center time variable new zero point. Useful times may start end standard 24 hour period (e.g., 11am 2am, technically fall different dates). intSigRegGraph() function added graph regions significance interactions linear models well mostly helper function, findSigRegions(). ezMULTINOM() new function added make running multinomial logistic regression easy R, along pairwise contrasts omnibus tests statistical significance. testdistr() function expanded cover multivariate normal data, old mvqq() function now deprecated. testdistr() includes optional robust estimates univariate multivariate normal data formatHtest() gains support pearson, kendal, spearman correlations cor.test() function logicals series support functions findings values particular range, %gele% values greater equal min less equal max well automatically subset data prefixed s, %sgele% %sin% etc.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"bug-fixes-0-3-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"JWileymisc 0.3.0","text":"winsorizor() now properly handles atomic data. Fixes issue variables data table atomic calling scale() function winsorizor() fail. egltable() now works data.tables","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-021","dir":"Changelog","previous_headings":"","what":"JWileymisc 0.2.1","title":"JWileymisc 0.2.1","text":"CRAN release: 2016-09-01","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"new-features-0-2-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"JWileymisc 0.2.1","text":"testdistr() function plot data different theoretical distributions using ggplot2. sort generalized qqnorm() allowing distributions besides normal distribution. winsorizor() Function moved pscore package. Sets values beyond specific quantiles empirical data specified quantiles. Can work vectors, data frames, matrices.","code":""},{"path":"https://joshuawiley.com/JWileymisc/news/index.html","id":"jwileymisc-020","dir":"Changelog","previous_headings":"","what":"JWileymisc 0.2.0","title":"JWileymisc 0.2.0","text":"CRAN release: 2016-08-24 Initial release CRAN.","code":""}]
